{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Starting a NASim Environment: https://networkattacksimulator.readthedocs.io/en/latest/tutorials/loading.html#environment-settings\n",
    "\n",
    "\n",
    "The three optional arguments control the environment modes:\n",
    "- fully_obs: The observability mode of environment, if True then uses fully observable mode, otherwise is partially observable (default=False)\n",
    "- flat_actions: If true then uses a flat action space, otherwise will uses a parameterised action space (default=True).\n",
    "- flat_obs: If true then uses a 1D observation space, otherwise uses a 2D observation space (default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n",
      "0.28.1\n",
      "3.1\n",
      "3.7.0\n",
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__) #updated to 1.23.4 > 1.18\n",
    "\n",
    "import gymnasium\n",
    "print(gymnasium.__version__) #updated to 0.28.1 > 0.17\n",
    "\n",
    "#pyYaml is version 6.0\n",
    "\n",
    "import networkx\n",
    "print(networkx.__version__) #updated to 2.8.7 > 2.4\n",
    "\n",
    "import prettytable\n",
    "print(prettytable.__version__) #updated to 3.7.0 > 0.7.2\n",
    "\n",
    "import matplotlib\n",
    "print(matplotlib.__version__) #updated to 3.7.1 (shown in console with pip show matplotlib) > 3.1.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASim Environment Load Reference\n",
    "\n",
    "nasim.make_benchmark(scenario_name, seed=None, fully_obs=False, flat_actions=True, flat_obs=True, render_mode=None): Make a new benchmark NASim environment\n",
    "\n",
    "- \n",
    "    - scenario_name (str): the name of the benchmark environment\n",
    "    - seed (int, optional): random seed to use to generate environment (default=None)\n",
    "    - fully_obs (bool, optional):  the observability mode of environment, if True then uses fully observable mode, otherwise partially observable (default=False)\n",
    "    - flat_actions (bool, optional): if true then uses a flat action space, otherwise will use parameterised action space (default=True).\n",
    "    - flat_obs (bool, optional): if true then uses a 1D observation space. If False will use a 2D observation space (default=True)\n",
    "    - render_mode (str, optional): The render mode to use for the environment.\n",
    "\n",
    "nasim.load(path, fully_obs=False, flat_actions=True, flat_obs=True, name=None, render_mode=None): Load NASim Environment from a .yaml source file\n",
    "\n",
    " -   \n",
    "    - path (str): path to the .yaml scenario file\n",
    "    - fully_obs (bool, optional): The observability mode of environment, if True then uses fully observable mode, otherwise partially observable (default=False)\n",
    "    - flat_actions (bool, optional): if true then uses a flat action space, otherwise will use parameterised action space (default=True).\n",
    "    - flat_obs (bool, optional): if true then uses a 1D observation space. If False will use a 2D observation space (default=True)\n",
    "    - name (str, optional): the scenarios name, if None name will be generated from path (default=None)\n",
    "    - render_mode (str, optional): The render mode to use for the environment.\n",
    "\n",
    "nasim.generate(): construct environment from atuo generated network\n",
    "\n",
    "-    \n",
    "    - num_hosts (int): number of hosts to include in network (minimum is 3)\n",
    "    - num_services (int): number of services to use in environment (minimum is 1)\n",
    "    - fully_obs (bool, optional): The observability mode of environment, if True then uses fully observable mode, otherwise partially observable (default=False)\n",
    "    - flat_actions (bool, optional): if true then uses a flat action space, otherwise will use parameterised action space (default=True).\n",
    "    - flat_obs (bool, optional): if true then uses a 1D observation space. If False will use a 2D observation space (default=True)\n",
    "    - render_mode (str, optional): The render mode to use for the environment.\n",
    "    - params (dict, optional): generator params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making an existing scenario\n",
    "\n",
    "import gymnasium\n",
    "\n",
    "import nasim\n",
    "env = nasim.make_benchmark(\"tiny\")\n",
    "#env1 = nasim.make_benchmark(\"tiny\", rendermode=\"human\") --> Couldn't get to work\n",
    "\n",
    "#Loading a scenario from a YAML file\n",
    "env2 = nasim.load(\"/Users/jacobalbright/Documents/GitHub/JacobAlbrightHumeCenterSummer2023/small.yaml\")\n",
    "\n",
    "#To generate a new environment with 5 hosts running a possible 3 services:\n",
    "env3 = nasim.generate(5, 3)\n",
    "\n",
    "# pass in some other parameters (say the number of possible operating systems) can be passed in as keyword arguments:\n",
    "env4 = nasim.generate(5, 3, num_os=3)\n",
    "\n",
    "env_opt = nasim.make_benchmark(\"tiny\", seed=None, fully_obs=False, flat_actions=True, flat_obs=True, render_mode=None)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting using OpenAI Gymnasium\n",
    "- always import gymnasium as gym\n",
    "\n",
    "- naming convention when using gymnasium.make(): ScenarioName[PO][2D][VA]-vX\n",
    "    - ScenarioName is the name of the benchmark scenario in Camel Casing\n",
    "    - [PO] is optional and included if environment is in partially observable mode, otherwise fully observable mode if not included.\n",
    "    - [2D] is optional and included if environment is to return 2D observations, otherwise the environment returns 1D observations.\n",
    "    - [VA] is optional and specifies the environment is to accept Vector actions (parametrised actions), if it is not included the environment expects integer (flat) actions.\n",
    "    - vX is the environment version. Currently (as of version 0.10.0) all environments are on v0 (ALWAYS v0???)\n",
    "\n",
    "Default: Tiny-v0 means the ‘tiny’ benchmark scenario in fully observable mode with flat action-space and flat observation space\n",
    "\n",
    "Alternate: MediumPO2DVA-v0 means the ‘medium’ benchmark scenario in partially observable mode with parametrised action-space and 2D observation-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:\n",
      "+---------+------------------+------------------+-----------------+\n",
      "| Success | Connection Error | Permission Error | Undefined Error |\n",
      "+---------+------------------+------------------+-----------------+\n",
      "|  False  |      False       |      False       |      False      |\n",
      "+---------+------------------+------------------+-----------------+\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+-------+--------+\n",
      "| Address | Compromised | Reachable | Discovered | Value | Discovery Value | Access | linux |  ssh  | tomcat |\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+-------+--------+\n",
      "|  (1, 0) |    False    |    True   |    True    |  0.0  |       0.0       |  0.0   | False | False | False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False | False | False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False | False | False  |\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+-------+--------+\n"
     ]
    }
   ],
   "source": [
    "#testing rendering\n",
    "\n",
    "import gymnasium as gym\n",
    "env5 = gym.make(\"nasim:Tiny-v0\")\n",
    "\n",
    "# to specify render mode\n",
    "env6 = gym.make(\"nasim:TinyPO-v0\", render_mode=\"human\")\n",
    "\n",
    "env6.reset()\n",
    "# render the environment\n",
    "# (if render_mode=\"human\" is not passed during initialization this will do nothing)\n",
    "env6.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:\n",
      "+---------+------------------+------------------+-----------------+\n",
      "| Success | Connection Error | Permission Error | Undefined Error |\n",
      "+---------+------------------+------------------+-----------------+\n",
      "|  False  |      False       |      False       |      False      |\n",
      "+---------+------------------+------------------+-----------------+\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+---------+-------+-------+-------+-------+-------+--------+---------+---------+\n",
      "| Address | Compromised | Reachable | Discovered | Value | Discovery Value | Access | linux | windows |  ssh  |  ftp  |  http | samba |  smtp | tomcat | daclsvc | schtask |\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+---------+-------+-------+-------+-------+-------+--------+---------+---------+\n",
      "|  (1, 0) |    False    |    True   |    True    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "|  (0, 0) |    False    |   False   |   False    |  0.0  |       0.0       |  0.0   | False |  False  | False | False | False | False | False | False  |  False  |  False  |\n",
      "+---------+-------------+-----------+------------+-------+-----------------+--------+-------+---------+-------+-------+-------+-------+-------+--------+---------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (17, 27)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#testing rendering for larger/more complex network\n",
    "# to specify render mode\n",
    "env7 = gym.make(\"nasim:MediumPO2DVA-v0\", render_mode=\"human\")\n",
    "\n",
    "env7.reset()\n",
    "# render the environment\n",
    "# (if render_mode=\"human\" is not passed during initialization this will do nothing)\n",
    "env7.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of actions can be retrieved from the environment action_space attribute:\n",
    "#flat_actions = true by default\n",
    "\n",
    "thisenv = nasim.make_benchmark(\"tiny\")\n",
    "    # When flat_actions=True\n",
    "num_actions = thisenv.action_space.n\n",
    "\n",
    "    # When flat_actions=False\n",
    "#nvec_actions = thisenv.action_space.nvec\n",
    "\n",
    "#The shape of the observations can be retrieved from the environment observation_space attribute\n",
    "obs_shape = thisenv.observation_space.shape\n",
    "\n",
    "#Getting initial observation and resetting the environment using reset() function\n",
    "#o, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Agent:\n",
    "\n",
    "agent = AnAgent(...)\n",
    "\n",
    "o, info = env.reset()\n",
    "total_reward = 0\n",
    "done = False\n",
    "step_limit_reached = False\n",
    "while not done and not step_limit_reached:\n",
    "    a = agent.choose_action(o)\n",
    "    o, r, done, step_limit_reached, info = env.step(a)\n",
    "    total_reward += r\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Total reward =\", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Attack Agents (in terminal):\n",
    "\n",
    "- Cd into JacobAlbrightHumeCenterSummer2023/NetworkAttackSimulator-master/nasim/agents and run python attack_agent.py scenario\n",
    "\n",
    "- Example run: python bruteforce_agent.py tiny\n",
    "\n",
    "Could not view agent policies of ql_agnet using \"python ql_agent.py tiny --render_eval\" --> throws error #15: Initializing libiomp5.dylib, but found libop.dylib already initialized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Agents:\n",
    "\n",
    "- keyboard_agent.py: An agent that is controlled by the user via terminal inputs.\n",
    "- random_agent.py: A random agent that selects an action randomly from all available actions at each time step.\n",
    "- bruteforce_agent.py: An agent that repeatedly cycles through all available actions in order.\n",
    "- ql_agent.py: A Tabular, epsilod-greedy Q-Learning reinforcement learning agent.\n",
    "- ql_replay_agent.py: A Tabular, epsilod-greedy Q-Learning reinforcement learning agent (same as above) that incorporates an experience replay.\n",
    "- dqn_agent.py: A Deep Q-Network reinforcement learning agent using experience replay and a target Q-Network."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
