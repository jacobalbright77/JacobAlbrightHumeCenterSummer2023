{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20f1931",
   "metadata": {},
   "source": [
    "## Initial Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38702355",
   "metadata": {},
   "source": [
    "This is all some intro code just to visualize some of the settings and get a baseline. You can run through it if you want to get familiar with what the scenario arguments, agents, and training looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5756d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = 'data.yaml'\n",
    "\n",
    "\n",
    "def writeToYAML():\n",
    "    with open(testfile, 'w') as f:\n",
    "        data = yaml.dump(curr_data, f, sort_keys=False, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "111fbc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_dict(dict_obj, indent = 0):\n",
    "    ''' Pretty Print nested dictionary with given indent level  \n",
    "    '''\n",
    "    # Iterate over all key-value pairs of dictionary\n",
    "    for key, value in dict_obj.items():\n",
    "        # If value is dict type, then print nested dict \n",
    "        if isinstance(value, dict):\n",
    "            print(' ' * indent, key, ':', '{')\n",
    "            print_nested_dict(value, indent + 4)\n",
    "            print(' ' * indent, '}')\n",
    "        else:\n",
    "            print(' ' * indent, key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a89b2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_args={\n",
    "    \"num_hosts\": 5,\n",
    "    \"num_services\": 3,\n",
    "    \"num_os\": 2,\n",
    "    \"num_processes\": 2,\n",
    "    \"num_exploits\": None,\n",
    "    \"num_privescs\": None,\n",
    "    \"r_sensitive\": 10,\n",
    "    \"r_user\": 10,\n",
    "    \"exploit_cost\": 1,\n",
    "    \"exploit_probs\": 1.0,\n",
    "    \"privesc_cost\": 1,\n",
    "    \"privesc_probs\": 1.0,\n",
    "    \"service_scan_cost\": 1,\n",
    "    \"os_scan_cost\": 1,\n",
    "    \"subnet_scan_cost\": 1,\n",
    "    \"process_scan_cost\": 1,\n",
    "    \"uniform\": False,\n",
    "    \"alpha_H\": 2.0,\n",
    "    \"alpha_V\": 2.0,\n",
    "    \"lambda_V\": 1.0,\n",
    "    \"restrictiveness\": 5,\n",
    "    \"random_goal\": False,\n",
    "    \"base_host_value\": 1,\n",
    "    \"host_discovery_value\": 1,\n",
    "    \"seed\": None,\n",
    "    \"name\": None,\n",
    "    \"step_limit\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5b27fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name : unreachable\n",
      "     Type : static\n",
      "     Subnets : 4\n",
      "     Hosts : 3\n",
      "     OS : 1\n",
      "     Services : 1\n",
      "     Processes : 1\n",
      "     Exploits : 1\n",
      "     PrivEscs : 1\n",
      "     Actions : 18\n",
      "     Observation Dims : (4, 14)\n",
      "     States : 576\n",
      "     Step Limit : 1000\n",
      "       subnets : [1, 1, 1, 1]\n",
      "       topology : [[1, 1, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1]]\n",
      "       os : ['linux']\n",
      "       services : ['ssh']\n",
      "       processes : ['tomcat']\n",
      "       sensitive_hosts : {\n",
      "           (2, 0) : 100\n",
      "           (3, 0) : 100\n",
      "       }\n",
      "       exploits : {\n",
      "           e_ssh : {\n",
      "               service : ssh\n",
      "               os : linux\n",
      "               prob : 0.8\n",
      "               cost : 1\n",
      "               access : 1\n",
      "           }\n",
      "       }\n",
      "       privilege_escalation : {\n",
      "           pe_tomcat : {\n",
      "               process : tomcat\n",
      "               os : linux\n",
      "               prob : 1.0\n",
      "               cost : 1\n",
      "               access : 2\n",
      "           }\n",
      "       }\n",
      "       os_scan_cost : 1\n",
      "       service_scan_cost : 1\n",
      "       subnet_scan_cost : 1\n",
      "       process_scan_cost : 1\n",
      "       firewall : {\n",
      "           (0, 1) : []\n",
      "           (1, 0) : []\n",
      "           (1, 2) : []\n",
      "           (2, 1) : []\n",
      "           (1, 3) : []\n",
      "           (3, 1) : []\n",
      "           (2, 3) : []\n",
      "           (3, 2) : []\n",
      "       }\n",
      "       host : {\n",
      "           (1, 0) : Host: {\n",
      "\taddress: (1, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: True\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t\t(3, 0): ['ssh']\n",
      "\t}\n",
      "           (2, 0) : Host: {\n",
      "\taddress: (2, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 100.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: True\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t\t(1, 0): ['ssh']\n",
      "\t}\n",
      "           (3, 0) : Host: {\n",
      "\taddress: (3, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 100.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: True\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "       }\n",
      "       step_limit : 1000\n"
     ]
    }
   ],
   "source": [
    "import nasim\n",
    "import json\n",
    "env = nasim.generate(**scenario_args)\n",
    "env = nasim.make_benchmark(\"huge-gen\")\n",
    "env = nasim.load(\"unreachable.yaml\")\n",
    "\n",
    "scenario_desc = env.scenario.get_description()\n",
    "scenario_dict = env.scenario.scenario_dict\n",
    "print_nested_dict(scenario_desc,4)\n",
    "print_nested_dict(scenario_dict,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b1f15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.get_minimum_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "991a0d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "No module named 'tensorboard'. (HINT: you can install tabular_q_learning_agent dependencies by running 'pip install nasim[dqn]'.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py:35\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=33'>34</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=34'>35</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=35'>36</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\n\u001b[1;32m      <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m LooseVersion\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnasim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mql_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularQLearningAgent\n\u001b[1;32m      3\u001b[0m ql_agent \u001b[38;5;241m=\u001b[39m TabularQLearningAgent(env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, training_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m)\n\u001b[1;32m      4\u001b[0m ql_agent\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py:38\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=35'>36</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=36'>37</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgymnasium\u001b[39;00m \u001b[39mimport\u001b[39;00m error\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=37'>38</a>\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=38'>39</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. (HINT: you can install tabular_q_learning_agent dependencies \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=39'>40</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby running \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install nasim[dqn]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=40'>41</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=43'>44</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTabularQFunction\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/ql_agent.py?line=44'>45</a>\u001b[0m     \u001b[39m\"\"\"Tabular Q-Function \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: No module named 'tensorboard'. (HINT: you can install tabular_q_learning_agent dependencies by running 'pip install nasim[dqn]'.)"
     ]
    }
   ],
   "source": [
    "from nasim.agents.ql_agent import TabularQLearningAgent\n",
    "\n",
    "ql_agent = TabularQLearningAgent(env, verbose=1, training_steps=50000)\n",
    "ql_agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b023e0",
   "metadata": {},
   "source": [
    "## Current Code \n",
    "Here is the main code to test/run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73c4bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial scenario arguments... we will be editing the number of hosts by marking actions involving them as invalid\n",
    "scenario_args={\n",
    "    \"num_hosts\": 5,\n",
    "    \"num_services\": 3,\n",
    "    \"num_os\": 2,\n",
    "    \"num_processes\": 2,\n",
    "    \"num_exploits\": None,\n",
    "    \"num_privescs\": None,\n",
    "    \"r_sensitive\": 10,\n",
    "    \"r_user\": 10,\n",
    "    \"exploit_cost\": 1,\n",
    "    \"exploit_probs\": 1.0,\n",
    "    \"privesc_cost\": 1,\n",
    "    \"privesc_probs\": 1.0,\n",
    "    \"service_scan_cost\": 1,\n",
    "    \"os_scan_cost\": 1,\n",
    "    \"subnet_scan_cost\": 1,\n",
    "    \"process_scan_cost\": 1,\n",
    "    \"uniform\": False,\n",
    "    \"alpha_H\": 2.0,\n",
    "    \"alpha_V\": 2.0,\n",
    "    \"lambda_V\": 1.0,\n",
    "    \"restrictiveness\": 5,\n",
    "    \"random_goal\": False,\n",
    "    \"base_host_value\": 1,\n",
    "    \"host_discovery_value\": 1,\n",
    "    \"seed\": None,\n",
    "    \"name\": None,\n",
    "    \"step_limit\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bbd02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Python user-defined exceptions\n",
    "class SensitiveHostRemovalException(Exception):\n",
    "    \"Raised when selected network host cannot be removed (sensitive host needs to remain in network)\"\n",
    "    pass\n",
    "\n",
    "class PublicHostRemovalException(Exception):\n",
    "    \"Raised when selected network host cannot be removed (public host to enter the network... specific to this configuration)\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c99801e",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "No module named 'tensorboard'. (HINT: you can install dqn_agent dependencies by running 'pip install nasim[dqn]'.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py:39\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=37'>38</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=38'>39</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=39'>40</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\n\u001b[1;32m      <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m LooseVersion\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnasim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Action\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnasim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdqn_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DQNAgent\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnasim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NASimEnv\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# User-defined Python method to check whether the selected blocked_host is valid to select\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py:41\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=38'>39</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=39'>40</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=40'>41</a>\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mDependencyNotInstalled(\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=41'>42</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m. (HINT: you can install dqn_agent dependencies by running \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=42'>43</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install nasim[dqn]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=43'>44</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=46'>47</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mReplayMemory\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/nasim/agents/dqn_agent.py?line=48'>49</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, capacity, s_dims, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: No module named 'tensorboard'. (HINT: you can install dqn_agent dependencies by running 'pip install nasim[dqn]'.)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries, including which methods will be redefined\n",
    "import nasim\n",
    "import random\n",
    "from nasim.envs.action import Action\n",
    "from nasim.agents.dqn_agent import DQNAgent\n",
    "from nasim.envs.environment import NASimEnv\n",
    "\n",
    "# User-defined Python method to check whether the selected blocked_host is valid to select\n",
    "def check_host_valid(self, blocked_host):\n",
    "    if blocked_host == -1:\n",
    "        return\n",
    "    elif self.env.network.address_space[blocked_host] in self.env.network.get_sensitive_hosts():\n",
    "        raise SensitiveHostRemovalException\n",
    "    elif blocked_host == 0:\n",
    "        raise PublicHostRemovalException\n",
    "    else:\n",
    "        return\n",
    "# Setting the method\n",
    "DQNAgent.check_host_valid = check_host_valid\n",
    "    \n",
    "# Redefining the DQNAgent run_train_episode method\n",
    "def run_train_episode(self, step_limit):\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "        max_host_index = len(self.env.network.host_num_map) - 1\n",
    "        \n",
    "        # Choosing random host index to be invalid... try/catch loop until valid host selected to block. Note: If -1, no host will be marked invalid\n",
    "        blocked_host = -1\n",
    "        if self.steps_done > 0:\n",
    "            while True:\n",
    "                try:\n",
    "                    blocked_host = random.randint(-1,max_host_index)\n",
    "                    self.check_host_valid(blocked_host)\n",
    "                    break\n",
    "                except SensitiveHostRemovalException:\n",
    "                    pass\n",
    "                except PublicHostRemovalException:\n",
    "                    pass\n",
    "                \n",
    "        o = self.env.reset()\n",
    "        \n",
    "        # If you wanted to see which host was blocked... used for the logging\n",
    "        print(\"Blocked host index:  \" + str(blocked_host))\n",
    "        \n",
    "        while not done and not env_step_limit_reached: #and steps < step_limit:\n",
    "            # Keep generating an action in the action space until it does not involve a blocked host\n",
    "            while True:\n",
    "                a = self.get_egreedy_action(o, self.get_epsilon())\n",
    "                \n",
    "                if blocked_host == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    action = self.env.action_space.get_action(a)\n",
    "                    target_host_index = self.env.network.host_num_map[action.target]\n",
    "                    if target_host_index != blocked_host:\n",
    "                        break\n",
    "                \n",
    "            next_o, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.replay.store(o, a, next_o, r, done)\n",
    "            self.steps_done += 1\n",
    "            loss, mean_v = self.optimize()\n",
    "            \n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "\n",
    "# Setting the method\n",
    "DQNAgent.run_train_episode = run_train_episode\n",
    "\n",
    "# Training function... redefined because it wasn't converging originally\n",
    "def train(self):\n",
    "    if self.verbose:\n",
    "        print(\"\\nStarting training\")\n",
    "\n",
    "    num_episodes = 0\n",
    "    training_steps_remaining = self.training_steps\n",
    "    og_env = self.env\n",
    "    \n",
    "    while self.steps_done < self.training_steps:\n",
    "        self.env = og_env\n",
    "        ep_results = self.run_train_episode(training_steps_remaining)\n",
    "        ep_return, ep_steps, goal = ep_results\n",
    "        num_episodes += 1\n",
    "        training_steps_remaining -= ep_steps\n",
    "\n",
    "        self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "        self.logger.add_scalar(\n",
    "            \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_return\", ep_return, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_steps\", ep_steps, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_goal_reached\", int(goal), self.steps_done\n",
    "        )\n",
    "\n",
    "        if num_episodes % 10 == 0 and self.verbose:\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                    f\"{self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "\n",
    "    self.logger.close()\n",
    "    if self.verbose:\n",
    "        print(\"Training complete\")\n",
    "        print(f\"\\nEpisode {num_episodes}:\")\n",
    "        print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "        print(f\"\\treturn = {ep_return}\")\n",
    "        print(f\"\\tgoal = {goal}\")\n",
    "# Set the method        \n",
    "DQNAgent.train = train\n",
    "\n",
    "# You can switch to a different benchmark if you want... like the scenario args posted or your own\n",
    "env = nasim.make_benchmark(\"small\")\n",
    "# Initializing and training agent\n",
    "dqn_agent = DQNAgent(env, verbose=1, training_steps=50000000)\n",
    "dqn_agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff038d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dqn_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdqn_agent\u001b[49m\u001b[38;5;241m.\u001b[39mrun_eval_episode(render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dqn_agent' is not defined"
     ]
    }
   ],
   "source": [
    "dqn_agent.run_eval_episode(render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a2bda",
   "metadata": {},
   "source": [
    "## Past Attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fb427",
   "metadata": {},
   "source": [
    "This was some code that didn't end up working if you wanted to see a previous attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "capacity = 10\n",
    "s_dims = (5,)\n",
    "s_buf = np.zeros((capacity, *s_dims), dtype=np.float32)\n",
    "#test_tuple.resize(test_tuple, [3,2])\n",
    "\n",
    "print(s_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06785b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nasim\n",
    "import random\n",
    "from nasim.agents.dqn_agent import DQNAgent\n",
    "\n",
    "def run_train_episode(self, step_limit):\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "        \n",
    "        o = self.env.reset()\n",
    "        \n",
    "        while not done and not env_step_limit_reached: #and steps < step_limit:\n",
    "            a = self.get_egreedy_action(o, self.get_epsilon())\n",
    "        \n",
    "            next_o, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.replay.store(o, a, next_o, r, done)\n",
    "            self.steps_done += 1\n",
    "            loss, mean_v = self.optimize()\n",
    "            \n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "    \n",
    "DQNAgent.run_train_episode = run_train_episode\n",
    "\n",
    "def train(self):\n",
    "    if self.verbose:\n",
    "        print(\"\\nStarting training\")\n",
    "\n",
    "    num_episodes = 0\n",
    "    training_steps_remaining = self.training_steps\n",
    "    max_hosts = (self.env.scenario.get_description())['Hosts']\n",
    "    max_obs_dim = self.env.observation_space.shape\n",
    "    \n",
    "    while self.steps_done < self.training_steps:\n",
    "        if self.steps_done > 0:\n",
    "            print(self.env.network.address_space)\n",
    "            print(self.env.network.host_num_map)\n",
    "            print(self.env.network.subnets)\n",
    "            print(self.env.network.topology)\n",
    "            print(self.env.network.firewall)\n",
    "            print(self.env.network.address_space)\n",
    "            print(self.env.network.address_space_bounds)\n",
    "            print(self.env.network.sensitive_addresses)\n",
    "            print(self.env.network.sensitive_hosts)\n",
    "\n",
    "            self.env.observation_space = prev_observation_space\n",
    "            self.num_actions = prev_num_actions\n",
    "            self.obs_dim = prev_obs_dim\n",
    "            self.replay = ReplayMemory(prev_replay_size,\n",
    "                                   #self.obs_dim,\n",
    "                                   #self.device)\n",
    "            \n",
    "            prev_observation_space = self.env.observation_space\n",
    "            prev_num_actions = self.num_actions\n",
    "            prev_obs_dim = self.obs_dim\n",
    "            prev_replay = self.replay\n",
    "            \n",
    "            scenario_args.update(num_hosts=random.randint(3,max_hosts))\n",
    "            \n",
    "            self.env =  nasim.generate(**scenario_args)\n",
    "            self.env.observation_space = prev_observation_space\n",
    "            self.num_actions = prev_num_actions\n",
    "            self.obs_dim = prev_obs_dim\n",
    "            self.replay = prev_replay\n",
    "            \n",
    "        ep_results = self.run_train_episode(training_steps_remaining)\n",
    "        ep_return, ep_steps, goal = ep_results\n",
    "        num_episodes += 1\n",
    "        training_steps_remaining -= ep_steps\n",
    "\n",
    "        self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "        self.logger.add_scalar(\n",
    "            \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_return\", ep_return, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_steps\", ep_steps, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_goal_reached\", int(goal), self.steps_done\n",
    "        )\n",
    "\n",
    "        if num_episodes % 10 == 0 and self.verbose:\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                    f\"{self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "\n",
    "    self.logger.close()\n",
    "    if self.verbose:\n",
    "        print(\"Training complete\")\n",
    "        print(f\"\\nEpisode {num_episodes}:\")\n",
    "        print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "        print(f\"\\treturn = {ep_return}\")\n",
    "        print(f\"\\tgoal = {goal}\")\n",
    "            \n",
    "DQNAgent.train = train\n",
    "\n",
    "print(scenario_args)\n",
    "env = nasim.generate(**scenario_args)\n",
    "dqn_agent = DQNAgent(env, verbose=1, training_steps=100000)\n",
    "dqn_agent.train()\n",
    "dqn_agent.run_eval_episode(render=args.render_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
