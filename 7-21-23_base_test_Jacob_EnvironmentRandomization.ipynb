{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1584eb",
   "metadata": {},
   "source": [
    "## 7/21: File used to test NaSim DQN Agent on custom network built with scenario args AND NaSim Small Network, Introduction of running average and printing values throughout training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b16ef",
   "metadata": {},
   "source": [
    "This is all some intro code just to visualize some of the settings and get a baseline. You can run through it if you want to get familiar with what the scenario arguments, agents, and training looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9940895",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = 'data.yaml'\n",
    "\n",
    "\n",
    "def writeToYAML():\n",
    "    with open(testfile, 'w') as f:\n",
    "        data = yaml.dump(curr_data, f, sort_keys=False, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae774da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_dict(dict_obj, indent = 0):\n",
    "    ''' Pretty Print nested dictionary with given indent level  \n",
    "    '''\n",
    "    # Iterate over all key-value pairs of dictionary\n",
    "    for key, value in dict_obj.items():\n",
    "        # If value is dict type, then print nested dict \n",
    "        if isinstance(value, dict):\n",
    "            print(' ' * indent, key, ':', '{')\n",
    "            print_nested_dict(value, indent + 4)\n",
    "            print(' ' * indent, '}')\n",
    "        else:\n",
    "            print(' ' * indent, key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543cb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_args={\n",
    "    \"num_hosts\": 5,         # Number of hosts in the network \n",
    "    \n",
    "    \"num_services\": 3,      # Number of services on the network (ssh, ftp, http)\n",
    "    \n",
    "    \"num_os\": 2,            # Number of operatings systems on the network (windows, linux, etc)\n",
    "    \n",
    "    \"num_processes\": 2,     # Number of processes on the network (tomcat, daclsvc, etc)\n",
    "    \n",
    "    \"num_exploits\": None,   # Number of exploits to use\n",
    "    \n",
    "    \"num_privescs\": None,   # Number of privilege escalation actions\n",
    "    \n",
    "    \"r_sensitive\": 10,      # Reward for sensitive subnet documents (default 10)\n",
    "    \n",
    "    \"r_user\": 10,           # Reward for user subnet documents      (default 10)\n",
    "    \n",
    "    \"exploit_cost\": 1,      # Cost to use an exploit (default 1)\n",
    "    \n",
    "    \"exploit_probs\": 1.0,   # Sucess probability of exploits (default 1.0)\n",
    "    \n",
    "    \"privesc_cost\": 1,      # Cost of privilege escalation action (default 1)\n",
    "    \n",
    "    \"privesc_probs\": 1.0,   # Sucess probability of privilege escalation action (default 1.0)\n",
    "    \n",
    "    \"service_scan_cost\": 1, # Cost for a service scan (default 1)\n",
    "    \n",
    "    \"os_scan_cost\": 1,      # Cost for an OS scan (default 1)\n",
    "    \n",
    "    \"subnet_scan_cost\": 1,  # Cost for a subnet scan (default 1)\n",
    "    \n",
    "    \"process_scan_cost\": 1, # Cost for a process scan (default 1)\n",
    "    \n",
    "    \"uniform\": False,       # Whether to use uniform distribution or correlaed host configuration (default false)\n",
    "    \n",
    "    \"alpha_H\": 2.0,         # Scaling or concentration parameter for controlling corelation between host configurations (default 2.0)\n",
    "    \n",
    "    \"alpha_V\": 2.0,         # Scaling or concentration parameter for controlling corelation between services across host configruations (default 2.0)\n",
    "    \n",
    "    \"lambda_V\": 1.0,        # Parameter for controlling average number of services running per host configuration (default 1.0)\n",
    "    \n",
    "    \"restrictiveness\": 5,   # Maximum number of services allowed to pass through firewalls between zones (default 5)\n",
    "    \n",
    "    \"random_goal\": False,   # Whether to randomly assign the goal user host or not (default False)\n",
    "    \n",
    "    \"base_host_value\": 1,   # Value of non sensitive hosts (default 1)\n",
    "    \n",
    "    \"host_discovery_value\": 1,  # Value of discovering a host for the first time (default 1)\n",
    "    \n",
    "    \"seed\": None,           # Random number generator seed (default None)\n",
    "    \n",
    "    \"name\": None,           # Name of the scenario, one will be generated if None (default None)\n",
    "    \n",
    "    \"step_limit\": None}     # Max number of steps permitted in a single episode, None means no limit (default None)\n",
    "\n",
    "#Scenario Generator Parameter List: https://networkattacksimulator.readthedocs.io/en/latest/reference/scenarios/generator.html#scenario-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d20271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario Description: \n",
      "     Name : small\n",
      "     Type : static\n",
      "     Subnets : 5\n",
      "     Hosts : 8\n",
      "     OS : 2\n",
      "     Services : 3\n",
      "     Processes : 2\n",
      "     Exploits : 3\n",
      "     PrivEscs : 2\n",
      "     Actions : 72\n",
      "     Observation Dims : (9, 23)\n",
      "     States : 24576\n",
      "     Step Limit : 1000\n",
      "\n",
      "Scenario Dictionary: \n",
      "       subnets : [1, 1, 1, 5, 1]\n",
      "       topology : [[1, 1, 0, 0, 0], [1, 1, 1, 1, 0], [0, 1, 1, 1, 0], [0, 1, 1, 1, 1], [0, 0, 0, 1, 1]]\n",
      "       os : ['linux', 'windows']\n",
      "       services : ['ssh', 'ftp', 'http']\n",
      "       processes : ['tomcat', 'daclsvc']\n",
      "       sensitive_hosts : {\n",
      "           (2, 0) : 100\n",
      "           (4, 0) : 100\n",
      "       }\n",
      "       exploits : {\n",
      "           e_ssh : {\n",
      "               service : ssh\n",
      "               os : linux\n",
      "               prob : 0.9\n",
      "               cost : 3\n",
      "               access : 1\n",
      "           }\n",
      "           e_ftp : {\n",
      "               service : ftp\n",
      "               os : windows\n",
      "               prob : 0.6\n",
      "               cost : 1\n",
      "               access : 1\n",
      "           }\n",
      "           e_http : {\n",
      "               service : http\n",
      "               os : None\n",
      "               prob : 0.9\n",
      "               cost : 2\n",
      "               access : 1\n",
      "           }\n",
      "       }\n",
      "       privilege_escalation : {\n",
      "           pe_tomcat : {\n",
      "               process : tomcat\n",
      "               os : linux\n",
      "               prob : 1.0\n",
      "               cost : 1\n",
      "               access : 2\n",
      "           }\n",
      "           pe_daclsvc : {\n",
      "               process : daclsvc\n",
      "               os : windows\n",
      "               prob : 1.0\n",
      "               cost : 1\n",
      "               access : 2\n",
      "           }\n",
      "       }\n",
      "       os_scan_cost : 1\n",
      "       service_scan_cost : 1\n",
      "       subnet_scan_cost : 1\n",
      "       process_scan_cost : 1\n",
      "       firewall : {\n",
      "           (0, 1) : ['http']\n",
      "           (1, 0) : []\n",
      "           (1, 2) : ['ssh']\n",
      "           (2, 1) : ['ssh']\n",
      "           (1, 3) : []\n",
      "           (3, 1) : ['ssh']\n",
      "           (2, 3) : ['http']\n",
      "           (3, 2) : ['ftp']\n",
      "           (3, 4) : ['ssh', 'ftp']\n",
      "           (4, 3) : ['ftp']\n",
      "       }\n",
      "       host : {\n",
      "           (1, 0) : Host: {\n",
      "\taddress: (1, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t\twindows: False\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: False\n",
      "\t\thttp: True\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: False\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (2, 0) : Host: {\n",
      "\taddress: (2, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 100.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t\twindows: False\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: True\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: True\n",
      "\t\tdaclsvc: False\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (3, 0) : Host: {\n",
      "\taddress: (3, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: False\n",
      "\t\twindows: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: False\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (3, 1) : Host: {\n",
      "\taddress: (3, 1)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: False\n",
      "\t\twindows: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: True\n",
      "\t\thttp: True\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (3, 2) : Host: {\n",
      "\taddress: (3, 2)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: False\n",
      "\t\twindows: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (3, 3) : Host: {\n",
      "\taddress: (3, 3)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: False\n",
      "\t\twindows: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: False\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (3, 4) : Host: {\n",
      "\taddress: (3, 4)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 0.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: False\n",
      "\t\twindows: True\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: False\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: False\n",
      "\t\tdaclsvc: True\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "           (4, 0) : Host: {\n",
      "\taddress: (4, 0)\n",
      "\tcompromised: False\n",
      "\treachable: False\n",
      "\tvalue: 100.0\n",
      "\taccess: 0\n",
      "\tOS: {\n",
      "\t\tlinux: True\n",
      "\t\twindows: False\n",
      "\t}\n",
      "\tservices: {\n",
      "\t\tssh: True\n",
      "\t\tftp: True\n",
      "\t\thttp: False\n",
      "\t}\n",
      "\tprocesses: {\n",
      "\t\ttomcat: True\n",
      "\t\tdaclsvc: False\n",
      "\t}\n",
      "\tfirewall: {\n",
      "\t}\n",
      "       }\n",
      "       step_limit : 1000\n"
     ]
    }
   ],
   "source": [
    "import nasim\n",
    "import json\n",
    "env = nasim.generate(**scenario_args)\n",
    "env = nasim.make_benchmark(\"huge-gen\")\n",
    "env = nasim.load(\"unreachable.yaml\")\n",
    "env2 = env = nasim.make_benchmark(\"small\")\n",
    "\n",
    "\n",
    "scenario_desc = env.scenario.get_description() #get_description found in scenario.py file under nasim->scenarios\n",
    "scenario_dict = env.scenario.scenario_dict\n",
    "#scenario_exploit_map = env.scenario.exploit_map # A nested dictionary for all exploits in scenario.\n",
    "#scenario_privesc_map = env.scenario.privesc_map # A nested dictionary for all privilege escalation actions in scenario.\n",
    "\n",
    "print(\"Scenario Description: \")\n",
    "print_nested_dict(scenario_desc,4)\n",
    "\n",
    "print(\"\\nScenario Dictionary: \")\n",
    "print_nested_dict(scenario_dict,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0faa4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.get_minimum_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea73154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--render_eval] [--lr LR]\n",
      "                             [-t TRAINING_STEPS] [--batch_size BATCH_SIZE]\n",
      "                             [--seed SEED] [--replay_size REPLAY_SIZE]\n",
      "                             [--final_epsilon FINAL_EPSILON]\n",
      "                             [--init_epsilon INIT_EPSILON]\n",
      "                             [-e EXPLORATION_STEPS] [--gamma GAMMA] [--quite]\n",
      "                             env_name\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/nasim/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    " \"\"\"An example Tabular, epsilon greedy Q-Learning Agent.\n",
    "\n",
    "This agent does not use an Experience replay (see the 'ql_replay_agent.py')\n",
    "\n",
    "It uses pytorch 1.5+ tensorboard library for logging (HINT: these dependencies\n",
    "can be installed by running pip install nasim[dqn])\n",
    "\n",
    "To run 'tiny' benchmark scenario with default settings, run the following from\n",
    "the nasim/agents dir:\n",
    "\n",
    "$ python ql_agent.py tiny\n",
    "\n",
    "To see detailed results using tensorboard:\n",
    "\n",
    "$ tensorboard --logdir runs/\n",
    "\n",
    "To see available hyperparameters:\n",
    "\n",
    "$ python ql_agent.py --help\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "This is by no means a state of the art implementation of Tabular Q-Learning.\n",
    "It is designed to be an example implementation that can be used as a reference\n",
    "for building your own agents and for simple experimental comparisons.\n",
    "\"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import nasim\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError as e:\n",
    "    from gymnasium import error\n",
    "    raise error.DependencyNotInstalled(\n",
    "        f\"{e}. (HINT: you can install tabular_q_learning_agent dependencies \"\n",
    "        \"by running 'pip install nasim[dqn]'.)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TabularQFunction:\n",
    "    \"\"\"Tabular Q-Function \"\"\"\n",
    "\n",
    "    def __init__(self, num_actions):\n",
    "        self.q_func = dict()\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = str(x.astype(int))\n",
    "        if x not in self.q_func:\n",
    "            self.q_func[x] = np.zeros(self.num_actions, dtype=np.float32)\n",
    "        return self.q_func[x]\n",
    "\n",
    "    def forward_batch(self, x_batch):\n",
    "        return np.asarray([self.forward(x) for x in x_batch])\n",
    "\n",
    "    def update_batch(self, s_batch, a_batch, delta_batch):\n",
    "        for s, a, delta in zip(s_batch, a_batch, delta_batch):\n",
    "            q_vals = self.forward(s)\n",
    "            q_vals[a] += delta\n",
    "\n",
    "    def update(self, s, a, delta):\n",
    "        q_vals = self.forward(s)\n",
    "        q_vals[a] += delta\n",
    "\n",
    "    def get_action(self, x):\n",
    "        return int(self.forward(x).argmax())\n",
    "\n",
    "    def display(self):\n",
    "        pprint(self.q_func)\n",
    "\n",
    "\n",
    "class TabularQLearningAgent:\n",
    "    \"\"\"A Tabular. epsilon greedy Q-Learning Agent using Experience Replay \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 env,\n",
    "                 seed=None,\n",
    "                 lr=0.001,\n",
    "                 training_steps=10000,\n",
    "                 final_epsilon=0.05,\n",
    "                 exploration_steps=10000,\n",
    "                 gamma=0.99,\n",
    "                 verbose=True,\n",
    "                 **kwargs):\n",
    "\n",
    "        # This implementation only works for flat actions\n",
    "        assert env.flat_actions\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            print(\"\\nRunning Tabular Q-Learning with config:\")\n",
    "            pprint(locals())\n",
    "\n",
    "        # set seeds\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        # envirnment setup\n",
    "        self.env = env\n",
    "\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        self.obs_dim = self.env.observation_space.shape\n",
    "\n",
    "        # logger setup\n",
    "        self.logger = SummaryWriter()\n",
    "\n",
    "        # Training related attributes\n",
    "        self.lr = lr\n",
    "        self.exploration_steps = exploration_steps\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.epsilon_schedule = np.linspace(\n",
    "            1.0, self.final_epsilon, self.exploration_steps\n",
    "        )\n",
    "        self.discount = gamma\n",
    "        self.training_steps = training_steps\n",
    "        self.steps_done = 0\n",
    "\n",
    "        # Q-Function\n",
    "        self.qfunc = TabularQFunction(self.num_actions)\n",
    "\n",
    "    def get_epsilon(self):\n",
    "        if self.steps_done < self.exploration_steps:\n",
    "            return self.epsilon_schedule[self.steps_done]\n",
    "        return self.final_epsilon\n",
    "\n",
    "    def get_egreedy_action(self, o, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            return self.qfunc.get_action(o)\n",
    "        return random.randint(0, self.num_actions-1)\n",
    "\n",
    "    def optimize(self, s, a, next_s, r, done):\n",
    "        # get q_val for state and action performed in that state\n",
    "        q_vals_raw = self.qfunc.forward(s)\n",
    "        q_val = q_vals_raw[a]\n",
    "\n",
    "        # get target q val = max val of next state\n",
    "        target_q_val = self.qfunc.forward(next_s).max()\n",
    "        target = r + self.discount * (1-done) * target_q_val\n",
    "\n",
    "        # calculate error and update\n",
    "        td_error = target - q_val\n",
    "        td_delta = self.lr * td_error\n",
    "\n",
    "        # optimize the model\n",
    "        self.qfunc.update(s, a, td_delta)\n",
    "\n",
    "        s_value = q_vals_raw.max()\n",
    "        return td_error, s_value\n",
    "\n",
    "    def train(self):\n",
    "        if self.verbose:\n",
    "            print(\"\\nStarting training\")\n",
    "\n",
    "        num_episodes = 0\n",
    "        training_steps_remaining = self.training_steps\n",
    "\n",
    "        while self.steps_done < self.training_steps:\n",
    "            ep_results = self.run_train_episode(training_steps_remaining)\n",
    "            ep_return, ep_steps, goal = ep_results\n",
    "            num_episodes += 1\n",
    "            training_steps_remaining -= ep_steps\n",
    "\n",
    "            self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "            self.logger.add_scalar(\n",
    "                \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_return\", ep_return, self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_steps\", ep_steps, self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_goal_reached\", int(goal), self.steps_done\n",
    "            )\n",
    "\n",
    "            if num_episodes % 10 == 0 and self.verbose:\n",
    "                print(f\"\\nEpisode {num_episodes}:\")\n",
    "                print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                      f\"{self.training_steps}\")\n",
    "                print(f\"\\treturn = {ep_return}\")\n",
    "                print(f\"\\tgoal = {goal}\")\n",
    "\n",
    "        self.logger.close()\n",
    "        if self.verbose:\n",
    "            print(\"Training complete\")\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "\n",
    "    def run_train_episode(self, step_limit):\n",
    "        s, _ = self.env.reset()\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "\n",
    "        while not done and not env_step_limit_reached and steps < step_limit:\n",
    "            a = self.get_egreedy_action(s, self.get_epsilon())\n",
    "\n",
    "            next_s, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.steps_done += 1\n",
    "            td_error, s_value = self.optimize(s, a, next_s, r, done)\n",
    "            self.logger.add_scalar(\"td_error\", td_error, self.steps_done)\n",
    "            self.logger.add_scalar(\"s_value\", s_value, self.steps_done)\n",
    "\n",
    "            s = next_s\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "\n",
    "    def run_eval_episode(self,\n",
    "                         env=None,\n",
    "                         render=False,\n",
    "                         eval_epsilon=0.05,\n",
    "                         render_mode=\"human\"):\n",
    "        if env is None:\n",
    "            env = self.env\n",
    "\n",
    "        original_render_mode = env.render_mode\n",
    "        env.render_mode = render_mode\n",
    "\n",
    "        s, _ = env.reset()\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "\n",
    "        line_break = \"=\"*60\n",
    "        if render:\n",
    "            print(\"\\n\" + line_break)\n",
    "            print(f\"Running EVALUATION using epsilon = {eval_epsilon:.4f}\")\n",
    "            print(line_break)\n",
    "            env.render()\n",
    "            input(\"Initial state. Press enter to continue..\")\n",
    "\n",
    "        while not done and not env_step_limit_reached:\n",
    "            a = self.get_egreedy_action(s, eval_epsilon)\n",
    "            next_s, r, done, env_step_limit_reached, _ = env.step(a)\n",
    "            s = next_s\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                print(\"\\n\" + line_break)\n",
    "                print(f\"Step {steps}\")\n",
    "                print(line_break)\n",
    "                print(f\"Action Performed = {env.action_space.get_action(a)}\")\n",
    "                env.render()\n",
    "                print(f\"Reward = {r}\")\n",
    "                print(f\"Done = {done}\")\n",
    "                print(f\"Step limit reached = {env_step_limit_reached}\")\n",
    "                input(\"Press enter to continue..\")\n",
    "\n",
    "                if done or env_step_limit_reached:\n",
    "                    print(\"\\n\" + line_break)\n",
    "                    print(\"EPISODE FINISHED\")\n",
    "                    print(line_break)\n",
    "                    print(f\"Goal reached = {env.goal_reached()}\")\n",
    "                    print(f\"Total steps = {steps}\")\n",
    "                    print(f\"Total reward = {episode_return}\")\n",
    "\n",
    "        env.render_mode = original_render_mode\n",
    "        return episode_return, steps, env.goal_reached()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"env_name\", type=str, help=\"benchmark scenario name\")\n",
    "    parser.add_argument(\"--render_eval\", action=\"store_true\",\n",
    "                        help=\"Renders final policy\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001,\n",
    "                        help=\"Learning rate (default=0.001)\")\n",
    "    parser.add_argument(\"-t\", \"--training_steps\", type=int, default=10000,\n",
    "                        help=\"training steps (default=10000)\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
    "                        help=\"(default=32)\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0,\n",
    "                        help=\"(default=0)\")\n",
    "    parser.add_argument(\"--replay_size\", type=int, default=100000,\n",
    "                        help=\"(default=100000)\")\n",
    "    parser.add_argument(\"--final_epsilon\", type=float, default=0.05,\n",
    "                        help=\"(default=0.05)\")\n",
    "    parser.add_argument(\"--init_epsilon\", type=float, default=1.0,\n",
    "                        help=\"(default=1.0)\")\n",
    "    parser.add_argument(\"-e\", \"--exploration_steps\", type=int, default=10000,\n",
    "                        help=\"(default=10000)\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "                        help=\"(default=0.99)\")\n",
    "    parser.add_argument(\"--quite\", action=\"store_false\",\n",
    "                        help=\"Run in Quite mode\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    env = nasim.make_benchmark(\n",
    "        args.env_name,\n",
    "        args.seed,\n",
    "        fully_obs=True,\n",
    "        flat_actions=True,\n",
    "        flat_obs=True\n",
    "    )\n",
    "    ql_agent = TabularQLearningAgent(\n",
    "        env, verbose=args.quite, **vars(args)\n",
    "    )\n",
    "    #ql_agent.train()\n",
    "    #ql_agent.run_eval_episode(render=args.render_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16271108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Tabular Q-Learning with config:\n",
      "{'env': <nasim.envs.environment.NASimEnv object at 0x7f0bc6879c60>,\n",
      " 'exploration_steps': 10000,\n",
      " 'final_epsilon': 0.05,\n",
      " 'gamma': 0.99,\n",
      " 'kwargs': {},\n",
      " 'lr': 0.001,\n",
      " 'seed': None,\n",
      " 'self': <__main__.TabularQLearningAgent object at 0x7f0b2c276080>,\n",
      " 'training_steps': 500,\n",
      " 'verbose': 1}\n",
      "\n",
      "Starting training\n",
      "Training complete\n",
      "\n",
      "Episode 2:\n",
      "\tsteps done = 500 / 500\n",
      "\treturn = -339.0\n",
      "\tgoal = False\n"
     ]
    }
   ],
   "source": [
    "#NOW USING AGENT ABOVE INSTEAD OF IMPORTING AGENT:\n",
    "#USED TO BE: from nasim.agents.ql_agent import TabularQLearningAgent\n",
    "\n",
    "ql_agent = TabularQLearningAgent(env2, verbose=1, training_steps=500)\n",
    "training_outputs = ql_agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7f94f",
   "metadata": {},
   "source": [
    "## Current Code \n",
    "Here is the main code to test/run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial scenario arguments... we will be editing the number of hosts by marking actions involving them as invalid\n",
    "scenario_args2={\n",
    "    \"num_hosts\": 5,         # Number of hosts in the network \n",
    "    \n",
    "    \"num_services\": 3,      # Number of services on the network (ssh, ftp, http)\n",
    "    \n",
    "    \"num_os\": 2,            # Number of operatings systems on the network (windows, linux, etc)\n",
    "    \n",
    "    \"num_processes\": 2,     # Number of processes on the network (tomcat, daclsvc, etc)\n",
    "    \n",
    "    \"num_exploits\": None,   # Number of exploits to use\n",
    "    \n",
    "    \"num_privescs\": None,   # Number of privilege escalation actions\n",
    "    \n",
    "    \"r_sensitive\": 10,      # Reward for sensitive subnet documents (default 10)\n",
    "    \n",
    "    \"r_user\": 10,           # Reward for user subnet documents      (default 10)\n",
    "    \n",
    "    \"exploit_cost\": 1,      # Cost to use an exploit (default 1)\n",
    "    \n",
    "    \"exploit_probs\": 1.0,   # Sucess probability of exploits (default 1.0)\n",
    "    \n",
    "    \"privesc_cost\": 1,      # Cost of privilege escalation action (default 1)\n",
    "    \n",
    "    \"privesc_probs\": 1.0,   # Sucess probability of privilege escalation action (default 1.0)\n",
    "    \n",
    "    \"service_scan_cost\": 1, # Cost for a service scan (default 1)\n",
    "    \n",
    "    \"os_scan_cost\": 1,      # Cost for an OS scan (default 1)\n",
    "    \n",
    "    \"subnet_scan_cost\": 1,  # Cost for a subnet scan (default 1)\n",
    "    \n",
    "    \"process_scan_cost\": 1, # Cost for a process scan (default 1)\n",
    "    \n",
    "    \"uniform\": False,       # Whether to use uniform distribution or correlaed host configuration (default false)\n",
    "    \n",
    "    \"alpha_H\": 2.0,         # Scaling or concentration parameter for controlling corelation between host configurations (default 2.0)\n",
    "    \n",
    "    \"alpha_V\": 2.0,         # Scaling or concentration parameter for controlling corelation between services across host configruations (default 2.0)\n",
    "    \n",
    "    \"lambda_V\": 1.0,        # Parameter for controlling average number of services running per host configuration (default 1.0)\n",
    "    \n",
    "    \"restrictiveness\": 5,   # Maximum number of services allowed to pass through firewalls between zones (default 5)\n",
    "    \n",
    "    \"random_goal\": False,   # Whether to randomly assign the goal user host or not (default False)\n",
    "    \n",
    "    \"base_host_value\": 1,   # Value of non sensitive hosts (default 1)\n",
    "    \n",
    "    \"host_discovery_value\": 1,  # Value of discovering a host for the first time (default 1)\n",
    "    \n",
    "    \"seed\": None,           # Random number generator seed (default None)\n",
    "    \n",
    "    \"name\": None,           # Name of the scenario, one will be generated if None (default None)\n",
    "    \n",
    "    \"step_limit\": None}     # Max number of steps permitted in a single episode, None means no limit (default None)\n",
    "\n",
    "#Scenario Generator Parameter List: https://networkattacksimulator.readthedocs.io/en/latest/reference/scenarios/generator.html#scenario-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ec55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Python user-defined exceptions\n",
    "class SensitiveHostRemovalException(Exception):\n",
    "    \"Raised when selected network host cannot be removed (sensitive host needs to remain in network)\"\n",
    "    pass\n",
    "\n",
    "class PublicHostRemovalException(Exception):\n",
    "    \"Raised when selected network host cannot be removed (public host to enter the network... specific to this configuration)\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005a4500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--render_eval] [-o]\n",
      "                             [--hidden_sizes [HIDDEN_SIZES ...]] [--lr LR]\n",
      "                             [-t TRAINING_STEPS] [--batch_size BATCH_SIZE]\n",
      "                             [--target_update_freq TARGET_UPDATE_FREQ]\n",
      "                             [--seed SEED] [--replay_size REPLAY_SIZE]\n",
      "                             [--final_epsilon FINAL_EPSILON]\n",
      "                             [--init_epsilon INIT_EPSILON]\n",
      "                             [--exploration_steps EXPLORATION_STEPS]\n",
      "                             [--gamma GAMMA] [--quite]\n",
      "                             env_name\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/nasim/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# DEFAULT DQN AGENT AS CONTROL\n",
    "\n",
    "\"\"\"An example DQN Agent.\n",
    "\n",
    "It uses pytorch 1.5+ and tensorboard libraries (HINT: these dependencies can\n",
    "be installed by running pip install nasim[dqn])\n",
    "\n",
    "To run 'tiny' benchmark scenario with default settings, run the following from\n",
    "the nasim/agents dir:\n",
    "\n",
    "$ python dqn_agent.py tiny\n",
    "\n",
    "To see detailed results using tensorboard:\n",
    "\n",
    "$ tensorboard --logdir runs/\n",
    "\n",
    "To see available hyperparameters:\n",
    "\n",
    "$ python dqn_agent.py --help\n",
    "\n",
    "Notes\n",
    "-----\n",
    "\n",
    "This is by no means a state of the art implementation of DQN, but is designed\n",
    "to be an example implementation that can be used as a reference for building\n",
    "your own agents.\n",
    "\"\"\"\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "from gymnasium import error\n",
    "import numpy as np\n",
    "\n",
    "import nasim\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError as e:\n",
    "    raise error.DependencyNotInstalled(\n",
    "        f\"{e}. (HINT: you can install dqn_agent dependencies by running \"\n",
    "        \"'pip install nasim[dqn]'.)\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity, s_dims, device=\"cpu\"):\n",
    "        self.capacity = capacity\n",
    "        self.device = device\n",
    "        self.s_buf = np.zeros((capacity, *s_dims), dtype=np.float32)\n",
    "        self.a_buf = np.zeros((capacity, 1), dtype=np.int64)\n",
    "        self.next_s_buf = np.zeros((capacity, *s_dims), dtype=np.float32)\n",
    "        self.r_buf = np.zeros(capacity, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(capacity, dtype=np.float32)\n",
    "        self.ptr, self.size = 0, 0\n",
    "\n",
    "    def store(self, s, a, next_s, r, done):\n",
    "        self.s_buf[self.ptr] = s\n",
    "        self.a_buf[self.ptr] = a\n",
    "        self.next_s_buf[self.ptr] = next_s\n",
    "        self.r_buf[self.ptr] = r\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.capacity\n",
    "        self.size = min(self.size+1, self.capacity)\n",
    "\n",
    "    def sample_batch(self, batch_size):\n",
    "        sample_idxs = np.random.choice(self.size, batch_size)\n",
    "        batch = [self.s_buf[sample_idxs],\n",
    "                 self.a_buf[sample_idxs],\n",
    "                 self.next_s_buf[sample_idxs],\n",
    "                 self.r_buf[sample_idxs],\n",
    "                 self.done_buf[sample_idxs]]\n",
    "        return [torch.from_numpy(buf).to(self.device) for buf in batch]\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    \"\"\"A simple Deep Q-Network \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, layers, num_actions):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_dim[0], layers[0])])\n",
    "        for l in range(1, len(layers)):\n",
    "            self.layers.append(nn.Linear(layers[l-1], layers[l]))\n",
    "        self.out = nn.Linear(layers[-1], num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    def save_DQN(self, file_path):\n",
    "        torch.save(self.state_dict(), file_path)\n",
    "\n",
    "    def load_DQN(self, file_path):\n",
    "        self.load_state_dict(torch.load(file_path))\n",
    "\n",
    "    def get_action(self, x):\n",
    "        with torch.no_grad():\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.view(1, -1)\n",
    "            return self.forward(x).max(1)[1]\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    \"\"\"A simple Deep Q-Network Agent \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 env,\n",
    "                 seed=None,\n",
    "                 lr=0.001,\n",
    "                 training_steps=20000,\n",
    "                 batch_size=32,\n",
    "                 replay_size=10000,\n",
    "                 final_epsilon=0.05,\n",
    "                 exploration_steps=10000,\n",
    "                 gamma=0.99,\n",
    "                 hidden_sizes=[64, 64],\n",
    "                 target_update_freq=1000,\n",
    "                 verbose=True,\n",
    "                 **kwargs):\n",
    "\n",
    "        # This DQN implementation only works for flat actions\n",
    "        assert env.flat_actions\n",
    "        self.verbose = verbose\n",
    "        if self.verbose:\n",
    "            print(f\"\\nRunning DQN with config:\")\n",
    "            pprint(locals())\n",
    "\n",
    "        # set seeds\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "        # environment setup\n",
    "        self.env = env\n",
    "\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        self.obs_dim = self.env.observation_space.shape\n",
    "\n",
    "        # logger setup\n",
    "        self.logger = SummaryWriter()\n",
    "\n",
    "        # Training related attributes\n",
    "        self.lr = lr\n",
    "        self.exploration_steps = exploration_steps\n",
    "        self.final_epsilon = final_epsilon\n",
    "        self.epsilon_schedule = np.linspace(1.0,\n",
    "                                            self.final_epsilon,\n",
    "                                            self.exploration_steps)\n",
    "        self.batch_size = batch_size\n",
    "        self.discount = gamma\n",
    "        self.training_steps = training_steps\n",
    "        self.steps_done = 0\n",
    "\n",
    "        # Neural Network related attributes\n",
    "        self.device = torch.device(\"cuda\"\n",
    "                                   if torch.cuda.is_available()\n",
    "                                   else \"cpu\")\n",
    "        self.dqn = DQN(self.obs_dim,\n",
    "                       hidden_sizes,\n",
    "                       self.num_actions).to(self.device)\n",
    "        if self.verbose:\n",
    "            print(f\"\\nUsing Neural Network running on device={self.device}:\")\n",
    "            print(self.dqn)\n",
    "\n",
    "        self.target_dqn = DQN(self.obs_dim,\n",
    "                              hidden_sizes,\n",
    "                              self.num_actions).to(self.device)\n",
    "        self.target_update_freq = target_update_freq\n",
    "\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(), lr=self.lr)\n",
    "        self.loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "        # replay setup\n",
    "        self.replay = ReplayMemory(replay_size,\n",
    "                                   self.obs_dim,\n",
    "                                   self.device)\n",
    "\n",
    "    def save(self, save_path):\n",
    "        self.dqn.save_DQN(save_path)\n",
    "\n",
    "    def load(self, load_path):\n",
    "        self.dqn.load_DQN(load_path)\n",
    "\n",
    "    def get_epsilon(self):\n",
    "        if self.steps_done < self.exploration_steps:\n",
    "            return self.epsilon_schedule[self.steps_done]\n",
    "        return self.final_epsilon\n",
    "\n",
    "    def get_egreedy_action(self, o, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            o = torch.from_numpy(o).float().to(self.device)\n",
    "            return self.dqn.get_action(o).cpu().item()\n",
    "        return random.randint(0, self.num_actions-1)\n",
    "\n",
    "    def optimize(self):\n",
    "        batch = self.replay.sample_batch(self.batch_size)\n",
    "        s_batch, a_batch, next_s_batch, r_batch, d_batch = batch\n",
    "\n",
    "        # get q_vals for each state and the action performed in that state\n",
    "        q_vals_raw = self.dqn(s_batch)\n",
    "        q_vals = q_vals_raw.gather(1, a_batch).squeeze()\n",
    "\n",
    "        # get target q val = max val of next state\n",
    "        with torch.no_grad():\n",
    "            target_q_val_raw = self.target_dqn(next_s_batch)\n",
    "            target_q_val = target_q_val_raw.max(1)[0]\n",
    "            target = r_batch + self.discount*(1-d_batch)*target_q_val\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.loss_fn(q_vals, target)\n",
    "\n",
    "        # optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.steps_done % self.target_update_freq == 0:\n",
    "            self.target_dqn.load_state_dict(self.dqn.state_dict())\n",
    "\n",
    "        q_vals_max = q_vals_raw.max(1)[0]\n",
    "        mean_v = q_vals_max.mean().item()\n",
    "        return loss.item(), mean_v\n",
    "\n",
    "    def train(self):\n",
    "        if self.verbose:\n",
    "            print(\"\\nStarting training\")\n",
    "\n",
    "        num_episodes = 0\n",
    "        training_steps_remaining = self.training_steps\n",
    "        \n",
    "        elems_to_avg = []\n",
    "        all_avgs = []\n",
    "\n",
    "        while self.steps_done < self.training_steps:\n",
    "            ep_results = self.run_train_episode(training_steps_remaining)\n",
    "            ep_return, ep_steps, goal = ep_results #ep_return, ep_steps, and goal equal ep_results\n",
    "            num_episodes += 1\n",
    "            training_steps_remaining -= ep_steps\n",
    "\n",
    "            self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "            self.logger.add_scalar(\n",
    "                \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_return\", ep_return, self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_steps\", ep_steps, self.steps_done\n",
    "            )\n",
    "            self.logger.add_scalar(\n",
    "                \"episode_goal_reached\", int(goal), self.steps_done\n",
    "            )\n",
    "\n",
    "            if num_episodes % 10 == 0 and self.verbose:\n",
    "                print(f\"\\nEpisode {num_episodes}:\")\n",
    "                print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                      f\"{self.training_steps}\")\n",
    "                print(f\"\\treturn = {ep_return}\")\n",
    "                print(f\"\\tgoal = {goal}\")\n",
    "                print(f\"\\t\")\n",
    "            \n",
    "                elems_to_avg.append(ep_return) #Jacob edit\n",
    "        \n",
    "            if num_episodes % 50 == 0 and self.verbose:\n",
    "                avg = (sum(elems_to_avg) / len(elems_to_avg))\n",
    "                all_avgs.append(avg)\n",
    "\n",
    "                print(f\"\\t\")\n",
    "                print(f\"\\tRunning_Average = {avg}\")\n",
    "                print(f\"\\t\")\n",
    "                \n",
    "\n",
    "        self.logger.close()\n",
    "        if self.verbose:\n",
    "            print(\"Training complete\")\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "            \n",
    "            print(f\"\\t\")\n",
    "            print(\"Running_Average List:\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(all_avgs)):\n",
    "                print(\"Episode \" + str((i+1)*50), end=\": \")\n",
    "                print(all_avgs[i])\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(elems_to_avg)):\n",
    "                print(\"Episode \" + str((i+1)*10), end=\": \")\n",
    "                print(elems_to_avg[i])\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(elems_to_avg)):\n",
    "                print(elems_to_avg[i])\n",
    "            print(f\"\\t\")\n",
    "\n",
    "    def run_train_episode(self, step_limit):\n",
    "        o, _ = self.env.reset()\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "\n",
    "        while not done and not env_step_limit_reached and steps < step_limit:\n",
    "            a = self.get_egreedy_action(o, self.get_epsilon())\n",
    "\n",
    "            next_o, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.replay.store(o, a, next_o, r, done)\n",
    "            self.steps_done += 1\n",
    "            loss, mean_v = self.optimize()\n",
    "            self.logger.add_scalar(\"loss\", loss, self.steps_done)\n",
    "            self.logger.add_scalar(\"mean_v\", mean_v, self.steps_done)\n",
    "\n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "\n",
    "    def run_eval_episode(self,\n",
    "                         env=None,\n",
    "                         render=False,\n",
    "                         eval_epsilon=0.05,\n",
    "                         render_mode=\"human\"):\n",
    "        if env is None:\n",
    "            env = self.env\n",
    "\n",
    "        original_render_mode = env.render_mode\n",
    "        env.render_mode = render_mode\n",
    "\n",
    "        o, _ = env.reset()\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "\n",
    "        line_break = \"=\"*60\n",
    "        if render:\n",
    "            print(\"\\n\" + line_break)\n",
    "            print(f\"Running EVALUATION using epsilon = {eval_epsilon:.4f}\")\n",
    "            print(line_break)\n",
    "            env.render()\n",
    "            input(\"Initial state. Press enter to continue..\")\n",
    "\n",
    "        while not done and not env_step_limit_reached:\n",
    "            a = self.get_egreedy_action(o, eval_epsilon)\n",
    "            next_o, r, done, env_step_limit_reached, _ = env.step(a)\n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                print(\"\\n\" + line_break)\n",
    "                print(f\"Step {steps}\")\n",
    "                print(line_break)\n",
    "                print(f\"Action Performed = {env.action_space.get_action(a)}\")\n",
    "                env.render()\n",
    "                print(f\"Reward = {r}\")\n",
    "                print(f\"Done = {done}\")\n",
    "                print(f\"Step limit reached = {env_step_limit_reached}\")\n",
    "                input(\"Press enter to continue..\")\n",
    "\n",
    "                if done or env_step_limit_reached:\n",
    "                    print(\"\\n\" + line_break)\n",
    "                    print(\"EPISODE FINISHED\")\n",
    "                    print(line_break)\n",
    "                    print(f\"Goal reached = {env.goal_reached()}\")\n",
    "                    print(f\"Total steps = {steps}\")\n",
    "                    print(f\"Total reward = {episode_return}\")\n",
    "\n",
    "        env.render_mode = original_render_mode\n",
    "        return episode_return, steps, env.goal_reached()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"env_name\", type=str, help=\"benchmark scenario name\")\n",
    "    parser.add_argument(\"--render_eval\", action=\"store_true\",\n",
    "                        help=\"Renders final policy\")\n",
    "    parser.add_argument(\"-o\", \"--partially_obs\", action=\"store_true\",\n",
    "                        help=\"Partially Observable Mode\")\n",
    "    parser.add_argument(\"--hidden_sizes\", type=int, nargs=\"*\",\n",
    "                        default=[64, 64],\n",
    "                        help=\"(default=[64. 64])\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001,\n",
    "                        help=\"Learning rate (default=0.001)\")\n",
    "    parser.add_argument(\"-t\", \"--training_steps\", type=int, default=20000,\n",
    "                        help=\"training steps (default=20000)\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
    "                        help=\"(default=32)\")\n",
    "    parser.add_argument(\"--target_update_freq\", type=int, default=1000,\n",
    "                        help=\"(default=1000)\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=0,\n",
    "                        help=\"(default=0)\")\n",
    "    parser.add_argument(\"--replay_size\", type=int, default=100000,\n",
    "                        help=\"(default=100000)\")\n",
    "    parser.add_argument(\"--final_epsilon\", type=float, default=0.05,\n",
    "                        help=\"(default=0.05)\")\n",
    "    parser.add_argument(\"--init_epsilon\", type=float, default=1.0,\n",
    "                        help=\"(default=1.0)\")\n",
    "    parser.add_argument(\"--exploration_steps\", type=int, default=10000,\n",
    "                        help=\"(default=10000)\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "                        help=\"(default=0.99)\")\n",
    "    parser.add_argument(\"--quite\", action=\"store_false\",\n",
    "                        help=\"Run in Quite mode\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    env = nasim.make_benchmark(args.env_name,\n",
    "                               args.seed,\n",
    "                               fully_obs=not args.partially_obs,\n",
    "                               flat_actions=True,\n",
    "                               flat_obs=True)\n",
    "    dqn_agent = DQNAgent(env, verbose=args.quite, **vars(args))\n",
    "    dqn_agent.train()\n",
    "    dqn_agent.run_eval_episode(render=args.render_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d209f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DQN with config:\n",
      "{'batch_size': 32,\n",
      " 'env': <nasim.envs.environment.NASimEnv object at 0x7fcf4c57e8f0>,\n",
      " 'exploration_steps': 10000,\n",
      " 'final_epsilon': 0.05,\n",
      " 'gamma': 0.99,\n",
      " 'hidden_sizes': [64, 64],\n",
      " 'kwargs': {},\n",
      " 'lr': 0.001,\n",
      " 'replay_size': 10000,\n",
      " 'seed': None,\n",
      " 'self': <__main__.DQNAgent object at 0x7fcf4c57d540>,\n",
      " 'target_update_freq': 1000,\n",
      " 'training_steps': 3000000,\n",
      " 'verbose': 1}\n",
      "\n",
      "Using Neural Network running on device=cuda:\n",
      "DQN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=207, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=72, bias=True)\n",
      ")\n",
      "\n",
      "Starting training\n",
      "\n",
      "Episode 10:\n",
      "\tsteps done = 7626 / 3000000\n",
      "\treturn = -999.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 20:\n",
      "\tsteps done = 17626 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 30:\n",
      "\tsteps done = 27626 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 40:\n",
      "\tsteps done = 37626 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 50:\n",
      "\tsteps done = 47626 / 3000000\n",
      "\treturn = -1031.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1016.6\n",
      "\t\n",
      "\n",
      "Episode 60:\n",
      "\tsteps done = 57626 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 70:\n",
      "\tsteps done = 67626 / 3000000\n",
      "\treturn = -1032.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 80:\n",
      "\tsteps done = 77626 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 90:\n",
      "\tsteps done = 87626 / 3000000\n",
      "\treturn = -924.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 100:\n",
      "\tsteps done = 97626 / 3000000\n",
      "\treturn = -1005.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1007.6\n",
      "\t\n",
      "\n",
      "Episode 110:\n",
      "\tsteps done = 107626 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 120:\n",
      "\tsteps done = 117626 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 130:\n",
      "\tsteps done = 127626 / 3000000\n",
      "\treturn = -1034.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 140:\n",
      "\tsteps done = 137626 / 3000000\n",
      "\treturn = -1025.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 150:\n",
      "\tsteps done = 147626 / 3000000\n",
      "\treturn = -927.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1006.0\n",
      "\t\n",
      "\n",
      "Episode 160:\n",
      "\tsteps done = 157626 / 3000000\n",
      "\treturn = -934.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 170:\n",
      "\tsteps done = 167626 / 3000000\n",
      "\treturn = -924.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 180:\n",
      "\tsteps done = 177626 / 3000000\n",
      "\treturn = -922.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 190:\n",
      "\tsteps done = 187626 / 3000000\n",
      "\treturn = -1100.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 200:\n",
      "\tsteps done = 197626 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -999.8\n",
      "\t\n",
      "\n",
      "Episode 210:\n",
      "\tsteps done = 207626 / 3000000\n",
      "\treturn = -930.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 220:\n",
      "\tsteps done = 217626 / 3000000\n",
      "\treturn = -1039.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 230:\n",
      "\tsteps done = 227626 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 240:\n",
      "\tsteps done = 237626 / 3000000\n",
      "\treturn = -1061.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 250:\n",
      "\tsteps done = 247626 / 3000000\n",
      "\treturn = -1021.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1002.24\n",
      "\t\n",
      "\n",
      "Episode 260:\n",
      "\tsteps done = 257626 / 3000000\n",
      "\treturn = -981.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 270:\n",
      "\tsteps done = 267626 / 3000000\n",
      "\treturn = -1021.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 280:\n",
      "\tsteps done = 277626 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 290:\n",
      "\tsteps done = 287626 / 3000000\n",
      "\treturn = -922.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 300:\n",
      "\tsteps done = 297626 / 3000000\n",
      "\treturn = -1007.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -999.9666666666667\n",
      "\t\n",
      "\n",
      "Episode 310:\n",
      "\tsteps done = 307626 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 320:\n",
      "\tsteps done = 317626 / 3000000\n",
      "\treturn = -1007.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 330:\n",
      "\tsteps done = 327626 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 340:\n",
      "\tsteps done = 337626 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 350:\n",
      "\tsteps done = 347626 / 3000000\n",
      "\treturn = -1032.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1002.3428571428572\n",
      "\t\n",
      "\n",
      "Episode 360:\n",
      "\tsteps done = 357626 / 3000000\n",
      "\treturn = -1035.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 370:\n",
      "\tsteps done = 367626 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 380:\n",
      "\tsteps done = 377626 / 3000000\n",
      "\treturn = -1047.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 390:\n",
      "\tsteps done = 387626 / 3000000\n",
      "\treturn = -2468.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 400:\n",
      "\tsteps done = 397626 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1041.95\n",
      "\t\n",
      "\n",
      "Episode 410:\n",
      "\tsteps done = 407626 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 420:\n",
      "\tsteps done = 417626 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 430:\n",
      "\tsteps done = 427626 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 440:\n",
      "\tsteps done = 437626 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 450:\n",
      "\tsteps done = 447626 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1039.4888888888888\n",
      "\t\n",
      "\n",
      "Episode 460:\n",
      "\tsteps done = 457626 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 470:\n",
      "\tsteps done = 467626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 480:\n",
      "\tsteps done = 477626 / 3000000\n",
      "\treturn = -1037.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 490:\n",
      "\tsteps done = 487626 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 500:\n",
      "\tsteps done = 497626 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1037.46\n",
      "\t\n",
      "\n",
      "Episode 510:\n",
      "\tsteps done = 507626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 520:\n",
      "\tsteps done = 517626 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 530:\n",
      "\tsteps done = 527626 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 540:\n",
      "\tsteps done = 537626 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 550:\n",
      "\tsteps done = 547626 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1035.7818181818182\n",
      "\t\n",
      "\n",
      "Episode 560:\n",
      "\tsteps done = 557626 / 3000000\n",
      "\treturn = -1039.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 570:\n",
      "\tsteps done = 567626 / 3000000\n",
      "\treturn = -1053.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 580:\n",
      "\tsteps done = 577626 / 3000000\n",
      "\treturn = -1052.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 590:\n",
      "\tsteps done = 587626 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 600:\n",
      "\tsteps done = 597626 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1035.85\n",
      "\t\n",
      "\n",
      "Episode 610:\n",
      "\tsteps done = 607626 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 620:\n",
      "\tsteps done = 617626 / 3000000\n",
      "\treturn = -1053.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 630:\n",
      "\tsteps done = 627626 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 640:\n",
      "\tsteps done = 637626 / 3000000\n",
      "\treturn = -1031.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 650:\n",
      "\tsteps done = 647626 / 3000000\n",
      "\treturn = -1038.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1035.6307692307691\n",
      "\t\n",
      "\n",
      "Episode 660:\n",
      "\tsteps done = 657626 / 3000000\n",
      "\treturn = -1072.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 670:\n",
      "\tsteps done = 667626 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 680:\n",
      "\tsteps done = 677626 / 3000000\n",
      "\treturn = -937.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 690:\n",
      "\tsteps done = 687626 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 700:\n",
      "\tsteps done = 697626 / 3000000\n",
      "\treturn = -951.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1033.142857142857\n",
      "\t\n",
      "\n",
      "Episode 710:\n",
      "\tsteps done = 707626 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 720:\n",
      "\tsteps done = 717626 / 3000000\n",
      "\treturn = -1054.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 730:\n",
      "\tsteps done = 727626 / 3000000\n",
      "\treturn = -1083.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 740:\n",
      "\tsteps done = 737626 / 3000000\n",
      "\treturn = -1098.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 750:\n",
      "\tsteps done = 747626 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1034.56\n",
      "\t\n",
      "\n",
      "Episode 760:\n",
      "\tsteps done = 757626 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 770:\n",
      "\tsteps done = 767626 / 3000000\n",
      "\treturn = -1045.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 780:\n",
      "\tsteps done = 777626 / 3000000\n",
      "\treturn = -1059.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 790:\n",
      "\tsteps done = 787626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 800:\n",
      "\tsteps done = 797626 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1034.425\n",
      "\t\n",
      "\n",
      "Episode 810:\n",
      "\tsteps done = 807626 / 3000000\n",
      "\treturn = -1036.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 820:\n",
      "\tsteps done = 817626 / 3000000\n",
      "\treturn = -1033.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 830:\n",
      "\tsteps done = 827626 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 840:\n",
      "\tsteps done = 837626 / 3000000\n",
      "\treturn = -1038.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 850:\n",
      "\tsteps done = 847626 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1033.870588235294\n",
      "\t\n",
      "\n",
      "Episode 860:\n",
      "\tsteps done = 857626 / 3000000\n",
      "\treturn = -1008.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 870:\n",
      "\tsteps done = 867626 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 880:\n",
      "\tsteps done = 877626 / 3000000\n",
      "\treturn = -1040.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 890:\n",
      "\tsteps done = 887626 / 3000000\n",
      "\treturn = -1025.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 900:\n",
      "\tsteps done = 897626 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1033.4\n",
      "\t\n",
      "\n",
      "Episode 910:\n",
      "\tsteps done = 907626 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 920:\n",
      "\tsteps done = 917626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 930:\n",
      "\tsteps done = 927626 / 3000000\n",
      "\treturn = -913.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 940:\n",
      "\tsteps done = 937626 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 950:\n",
      "\tsteps done = 947626 / 3000000\n",
      "\treturn = -1099.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1032.2631578947369\n",
      "\t\n",
      "\n",
      "Episode 960:\n",
      "\tsteps done = 957626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 970:\n",
      "\tsteps done = 967626 / 3000000\n",
      "\treturn = -1054.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 980:\n",
      "\tsteps done = 977626 / 3000000\n",
      "\treturn = -923.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 990:\n",
      "\tsteps done = 987626 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1000:\n",
      "\tsteps done = 997626 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1031.03\n",
      "\t\n",
      "\n",
      "Episode 1010:\n",
      "\tsteps done = 1007626 / 3000000\n",
      "\treturn = -1052.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1020:\n",
      "\tsteps done = 1017626 / 3000000\n",
      "\treturn = -1032.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1030:\n",
      "\tsteps done = 1027626 / 3000000\n",
      "\treturn = -1078.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1040:\n",
      "\tsteps done = 1037626 / 3000000\n",
      "\treturn = -1046.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1050:\n",
      "\tsteps done = 1047626 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1031.7047619047619\n",
      "\t\n",
      "\n",
      "Episode 1060:\n",
      "\tsteps done = 1057626 / 3000000\n",
      "\treturn = -924.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1070:\n",
      "\tsteps done = 1067626 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1080:\n",
      "\tsteps done = 1077626 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1090:\n",
      "\tsteps done = 1087626 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1100:\n",
      "\tsteps done = 1097626 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1030.3\n",
      "\t\n",
      "\n",
      "Episode 1110:\n",
      "\tsteps done = 1107626 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1120:\n",
      "\tsteps done = 1117626 / 3000000\n",
      "\treturn = -918.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1130:\n",
      "\tsteps done = 1127626 / 3000000\n",
      "\treturn = -1037.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1140:\n",
      "\tsteps done = 1137626 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1150:\n",
      "\tsteps done = 1147626 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1029.0521739130436\n",
      "\t\n",
      "\n",
      "Episode 1160:\n",
      "\tsteps done = 1157626 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1170:\n",
      "\tsteps done = 1167318 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1180:\n",
      "\tsteps done = 1177318 / 3000000\n",
      "\treturn = -1025.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1190:\n",
      "\tsteps done = 1187318 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1200:\n",
      "\tsteps done = 1197318 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1028.7416666666666\n",
      "\t\n",
      "\n",
      "Episode 1210:\n",
      "\tsteps done = 1207318 / 3000000\n",
      "\treturn = -1034.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1220:\n",
      "\tsteps done = 1217318 / 3000000\n",
      "\treturn = -1043.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1230:\n",
      "\tsteps done = 1227318 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1240:\n",
      "\tsteps done = 1237318 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1250:\n",
      "\tsteps done = 1247318 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1028.616\n",
      "\t\n",
      "\n",
      "Episode 1260:\n",
      "\tsteps done = 1257318 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1270:\n",
      "\tsteps done = 1267318 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1280:\n",
      "\tsteps done = 1277318 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1290:\n",
      "\tsteps done = 1287318 / 3000000\n",
      "\treturn = -1025.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1300:\n",
      "\tsteps done = 1297318 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1028.253846153846\n",
      "\t\n",
      "\n",
      "Episode 1310:\n",
      "\tsteps done = 1307318 / 3000000\n",
      "\treturn = -1030.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1320:\n",
      "\tsteps done = 1317318 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1330:\n",
      "\tsteps done = 1327272 / 3000000\n",
      "\treturn = -914.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1340:\n",
      "\tsteps done = 1337272 / 3000000\n",
      "\treturn = -1055.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1350:\n",
      "\tsteps done = 1347272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1027.4962962962964\n",
      "\t\n",
      "\n",
      "Episode 1360:\n",
      "\tsteps done = 1357272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1370:\n",
      "\tsteps done = 1367272 / 3000000\n",
      "\treturn = -926.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1380:\n",
      "\tsteps done = 1377272 / 3000000\n",
      "\treturn = -1068.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1390:\n",
      "\tsteps done = 1387272 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1400:\n",
      "\tsteps done = 1397272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.8285714285714\n",
      "\t\n",
      "\n",
      "Episode 1410:\n",
      "\tsteps done = 1407272 / 3000000\n",
      "\treturn = -1021.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1420:\n",
      "\tsteps done = 1417272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1430:\n",
      "\tsteps done = 1427272 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1440:\n",
      "\tsteps done = 1437272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1450:\n",
      "\tsteps done = 1447272 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.558620689655\n",
      "\t\n",
      "\n",
      "Episode 1460:\n",
      "\tsteps done = 1457272 / 3000000\n",
      "\treturn = -1025.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1470:\n",
      "\tsteps done = 1467272 / 3000000\n",
      "\treturn = -1252.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1480:\n",
      "\tsteps done = 1477272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1490:\n",
      "\tsteps done = 1487272 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1500:\n",
      "\tsteps done = 1497272 / 3000000\n",
      "\treturn = -1027.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1027.8666666666666\n",
      "\t\n",
      "\n",
      "Episode 1510:\n",
      "\tsteps done = 1507272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1520:\n",
      "\tsteps done = 1517272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1530:\n",
      "\tsteps done = 1527272 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1540:\n",
      "\tsteps done = 1537272 / 3000000\n",
      "\treturn = -927.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1550:\n",
      "\tsteps done = 1547272 / 3000000\n",
      "\treturn = -1042.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1027.1548387096775\n",
      "\t\n",
      "\n",
      "Episode 1560:\n",
      "\tsteps done = 1557272 / 3000000\n",
      "\treturn = -920.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1570:\n",
      "\tsteps done = 1567272 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1580:\n",
      "\tsteps done = 1577272 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1590:\n",
      "\tsteps done = 1587272 / 3000000\n",
      "\treturn = -916.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1600:\n",
      "\tsteps done = 1597272 / 3000000\n",
      "\treturn = -913.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.05\n",
      "\t\n",
      "\n",
      "Episode 1610:\n",
      "\tsteps done = 1607272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1620:\n",
      "\tsteps done = 1617272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1630:\n",
      "\tsteps done = 1627272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1640:\n",
      "\tsteps done = 1637272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1650:\n",
      "\tsteps done = 1647272 / 3000000\n",
      "\treturn = -1008.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.6242424242423\n",
      "\t\n",
      "\n",
      "Episode 1660:\n",
      "\tsteps done = 1657272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1670:\n",
      "\tsteps done = 1667272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1680:\n",
      "\tsteps done = 1677272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1690:\n",
      "\tsteps done = 1687272 / 3000000\n",
      "\treturn = -935.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1700:\n",
      "\tsteps done = 1697272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1023.9\n",
      "\t\n",
      "\n",
      "Episode 1710:\n",
      "\tsteps done = 1707272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1720:\n",
      "\tsteps done = 1717272 / 3000000\n",
      "\treturn = -1047.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1730:\n",
      "\tsteps done = 1727272 / 3000000\n",
      "\treturn = -1451.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1740:\n",
      "\tsteps done = 1737272 / 3000000\n",
      "\treturn = -1021.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1750:\n",
      "\tsteps done = 1747272 / 3000000\n",
      "\treturn = -1032.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.462857142857\n",
      "\t\n",
      "\n",
      "Episode 1760:\n",
      "\tsteps done = 1757272 / 3000000\n",
      "\treturn = -989.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1770:\n",
      "\tsteps done = 1767272 / 3000000\n",
      "\treturn = -1038.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1780:\n",
      "\tsteps done = 1777272 / 3000000\n",
      "\treturn = -1042.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1790:\n",
      "\tsteps done = 1787272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1800:\n",
      "\tsteps done = 1797272 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.2388888888888\n",
      "\t\n",
      "\n",
      "Episode 1810:\n",
      "\tsteps done = 1807272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1820:\n",
      "\tsteps done = 1817272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1830:\n",
      "\tsteps done = 1827272 / 3000000\n",
      "\treturn = -1006.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1840:\n",
      "\tsteps done = 1837272 / 3000000\n",
      "\treturn = -1038.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1850:\n",
      "\tsteps done = 1847272 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.9783783783785\n",
      "\t\n",
      "\n",
      "Episode 1860:\n",
      "\tsteps done = 1857272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1870:\n",
      "\tsteps done = 1867272 / 3000000\n",
      "\treturn = -1117.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1880:\n",
      "\tsteps done = 1877272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1890:\n",
      "\tsteps done = 1887272 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1900:\n",
      "\tsteps done = 1897272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.3105263157895\n",
      "\t\n",
      "\n",
      "Episode 1910:\n",
      "\tsteps done = 1907272 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1920:\n",
      "\tsteps done = 1917272 / 3000000\n",
      "\treturn = -932.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1930:\n",
      "\tsteps done = 1927272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1940:\n",
      "\tsteps done = 1937272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1950:\n",
      "\tsteps done = 1947272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.6102564102564\n",
      "\t\n",
      "\n",
      "Episode 1960:\n",
      "\tsteps done = 1957272 / 3000000\n",
      "\treturn = -1033.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1970:\n",
      "\tsteps done = 1967272 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1980:\n",
      "\tsteps done = 1977272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 1990:\n",
      "\tsteps done = 1987272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2000:\n",
      "\tsteps done = 1997272 / 3000000\n",
      "\treturn = -1042.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.57\n",
      "\t\n",
      "\n",
      "Episode 2010:\n",
      "\tsteps done = 2007272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2020:\n",
      "\tsteps done = 2017272 / 3000000\n",
      "\treturn = -1023.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2030:\n",
      "\tsteps done = 2027272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2040:\n",
      "\tsteps done = 2037272 / 3000000\n",
      "\treturn = -1104.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2050:\n",
      "\tsteps done = 2047272 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.760975609756\n",
      "\t\n",
      "\n",
      "Episode 2060:\n",
      "\tsteps done = 2057272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2070:\n",
      "\tsteps done = 2067272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2080:\n",
      "\tsteps done = 2077272 / 3000000\n",
      "\treturn = -922.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2090:\n",
      "\tsteps done = 2087272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2100:\n",
      "\tsteps done = 2097272 / 3000000\n",
      "\treturn = -1004.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.0\n",
      "\t\n",
      "\n",
      "Episode 2110:\n",
      "\tsteps done = 2107272 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2120:\n",
      "\tsteps done = 2117272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2130:\n",
      "\tsteps done = 2127272 / 3000000\n",
      "\treturn = -1050.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2140:\n",
      "\tsteps done = 2137272 / 3000000\n",
      "\treturn = -1088.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2150:\n",
      "\tsteps done = 2147272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.3581395348838\n",
      "\t\n",
      "\n",
      "Episode 2160:\n",
      "\tsteps done = 2157272 / 3000000\n",
      "\treturn = -924.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2170:\n",
      "\tsteps done = 2167272 / 3000000\n",
      "\treturn = -1122.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2180:\n",
      "\tsteps done = 2177272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2190:\n",
      "\tsteps done = 2187272 / 3000000\n",
      "\treturn = -1033.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2200:\n",
      "\tsteps done = 2197272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.2772727272727\n",
      "\t\n",
      "\n",
      "Episode 2210:\n",
      "\tsteps done = 2207272 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2220:\n",
      "\tsteps done = 2217272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2230:\n",
      "\tsteps done = 2227272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2240:\n",
      "\tsteps done = 2237272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2250:\n",
      "\tsteps done = 2247272 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.0977777777778\n",
      "\t\n",
      "\n",
      "Episode 2260:\n",
      "\tsteps done = 2257272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2270:\n",
      "\tsteps done = 2267272 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2280:\n",
      "\tsteps done = 2277272 / 3000000\n",
      "\treturn = -1090.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2290:\n",
      "\tsteps done = 2287272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2300:\n",
      "\tsteps done = 2297272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.2\n",
      "\t\n",
      "\n",
      "Episode 2310:\n",
      "\tsteps done = 2307272 / 3000000\n",
      "\treturn = -1106.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2320:\n",
      "\tsteps done = 2317272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2330:\n",
      "\tsteps done = 2327272 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2340:\n",
      "\tsteps done = 2337272 / 3000000\n",
      "\treturn = -926.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2350:\n",
      "\tsteps done = 2347272 / 3000000\n",
      "\treturn = -919.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.595744680851\n",
      "\t\n",
      "\n",
      "Episode 2360:\n",
      "\tsteps done = 2357272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2370:\n",
      "\tsteps done = 2367272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2380:\n",
      "\tsteps done = 2377272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2390:\n",
      "\tsteps done = 2387272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2400:\n",
      "\tsteps done = 2397272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.3833333333334\n",
      "\t\n",
      "\n",
      "Episode 2410:\n",
      "\tsteps done = 2407272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2420:\n",
      "\tsteps done = 2417272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2430:\n",
      "\tsteps done = 2427272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2440:\n",
      "\tsteps done = 2437272 / 3000000\n",
      "\treturn = -1052.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2450:\n",
      "\tsteps done = 2447272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.3469387755101\n",
      "\t\n",
      "\n",
      "Episode 2460:\n",
      "\tsteps done = 2457272 / 3000000\n",
      "\treturn = -1118.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2470:\n",
      "\tsteps done = 2467272 / 3000000\n",
      "\treturn = -1023.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2480:\n",
      "\tsteps done = 2477272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2490:\n",
      "\tsteps done = 2487272 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2500:\n",
      "\tsteps done = 2497272 / 3000000\n",
      "\treturn = -1004.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.612\n",
      "\t\n",
      "\n",
      "Episode 2510:\n",
      "\tsteps done = 2507272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2520:\n",
      "\tsteps done = 2517272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2530:\n",
      "\tsteps done = 2527272 / 3000000\n",
      "\treturn = -1023.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2540:\n",
      "\tsteps done = 2537272 / 3000000\n",
      "\treturn = -1043.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2550:\n",
      "\tsteps done = 2547272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.5294117647059\n",
      "\t\n",
      "\n",
      "Episode 2560:\n",
      "\tsteps done = 2557272 / 3000000\n",
      "\treturn = -1010.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2570:\n",
      "\tsteps done = 2567272 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2580:\n",
      "\tsteps done = 2577272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2590:\n",
      "\tsteps done = 2587272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2600:\n",
      "\tsteps done = 2597272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.35\n",
      "\t\n",
      "\n",
      "Episode 2610:\n",
      "\tsteps done = 2607272 / 3000000\n",
      "\treturn = -1024.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2620:\n",
      "\tsteps done = 2617272 / 3000000\n",
      "\treturn = -1008.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2630:\n",
      "\tsteps done = 2627272 / 3000000\n",
      "\treturn = -1006.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2640:\n",
      "\tsteps done = 2637272 / 3000000\n",
      "\treturn = -1028.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2650:\n",
      "\tsteps done = 2647272 / 3000000\n",
      "\treturn = -1029.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.2490566037736\n",
      "\t\n",
      "\n",
      "Episode 2660:\n",
      "\tsteps done = 2657272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2670:\n",
      "\tsteps done = 2667272 / 3000000\n",
      "\treturn = -1019.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2680:\n",
      "\tsteps done = 2677272 / 3000000\n",
      "\treturn = -1020.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2690:\n",
      "\tsteps done = 2687272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2700:\n",
      "\tsteps done = 2697272 / 3000000\n",
      "\treturn = -1526.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.0222222222221\n",
      "\t\n",
      "\n",
      "Episode 2710:\n",
      "\tsteps done = 2707272 / 3000000\n",
      "\treturn = -1022.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2720:\n",
      "\tsteps done = 2717272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2730:\n",
      "\tsteps done = 2727272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2740:\n",
      "\tsteps done = 2737272 / 3000000\n",
      "\treturn = -1026.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2750:\n",
      "\tsteps done = 2747272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.8763636363637\n",
      "\t\n",
      "\n",
      "Episode 2760:\n",
      "\tsteps done = 2757272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2770:\n",
      "\tsteps done = 2767272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2780:\n",
      "\tsteps done = 2777272 / 3000000\n",
      "\treturn = -1137.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2790:\n",
      "\tsteps done = 2787272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2800:\n",
      "\tsteps done = 2797272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1026.1107142857143\n",
      "\t\n",
      "\n",
      "Episode 2810:\n",
      "\tsteps done = 2807272 / 3000000\n",
      "\treturn = -1011.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2820:\n",
      "\tsteps done = 2817272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2830:\n",
      "\tsteps done = 2827272 / 3000000\n",
      "\treturn = -1008.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2840:\n",
      "\tsteps done = 2837272 / 3000000\n",
      "\treturn = -1016.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2850:\n",
      "\tsteps done = 2847272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.8842105263159\n",
      "\t\n",
      "\n",
      "Episode 2860:\n",
      "\tsteps done = 2857272 / 3000000\n",
      "\treturn = -1021.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2870:\n",
      "\tsteps done = 2867272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2880:\n",
      "\tsteps done = 2877272 / 3000000\n",
      "\treturn = -1008.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2890:\n",
      "\tsteps done = 2887272 / 3000000\n",
      "\treturn = -921.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2900:\n",
      "\tsteps done = 2897272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.3586206896553\n",
      "\t\n",
      "\n",
      "Episode 2910:\n",
      "\tsteps done = 2907272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2920:\n",
      "\tsteps done = 2917272 / 3000000\n",
      "\treturn = -1009.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2930:\n",
      "\tsteps done = 2927272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2940:\n",
      "\tsteps done = 2937272 / 3000000\n",
      "\treturn = -1017.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2950:\n",
      "\tsteps done = 2947272 / 3000000\n",
      "\treturn = -1018.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1025.1864406779662\n",
      "\t\n",
      "\n",
      "Episode 2960:\n",
      "\tsteps done = 2957272 / 3000000\n",
      "\treturn = -1015.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2970:\n",
      "\tsteps done = 2967272 / 3000000\n",
      "\treturn = -1014.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2980:\n",
      "\tsteps done = 2977272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 2990:\n",
      "\tsteps done = 2987272 / 3000000\n",
      "\treturn = -1012.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\n",
      "Episode 3000:\n",
      "\tsteps done = 2997272 / 3000000\n",
      "\treturn = -1013.0\n",
      "\tgoal = False\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -1024.99\n",
      "\t\n",
      "Training complete\n",
      "\n",
      "Episode 3003:\n",
      "\tsteps done = 3000000 / 3000000\n",
      "\treturn = -740.0\n",
      "\tgoal = False\n",
      "\t\n",
      "Running_Average List:\n",
      "\t\n",
      "Episode 50: -1016.6\n",
      "Episode 100: -1007.6\n",
      "Episode 150: -1006.0\n",
      "Episode 200: -999.8\n",
      "Episode 250: -1002.24\n",
      "Episode 300: -999.9666666666667\n",
      "Episode 350: -1002.3428571428572\n",
      "Episode 400: -1041.95\n",
      "Episode 450: -1039.4888888888888\n",
      "Episode 500: -1037.46\n",
      "Episode 550: -1035.7818181818182\n",
      "Episode 600: -1035.85\n",
      "Episode 650: -1035.6307692307691\n",
      "Episode 700: -1033.142857142857\n",
      "Episode 750: -1034.56\n",
      "Episode 800: -1034.425\n",
      "Episode 850: -1033.870588235294\n",
      "Episode 900: -1033.4\n",
      "Episode 950: -1032.2631578947369\n",
      "Episode 1000: -1031.03\n",
      "Episode 1050: -1031.7047619047619\n",
      "Episode 1100: -1030.3\n",
      "Episode 1150: -1029.0521739130436\n",
      "Episode 1200: -1028.7416666666666\n",
      "Episode 1250: -1028.616\n",
      "Episode 1300: -1028.253846153846\n",
      "Episode 1350: -1027.4962962962964\n",
      "Episode 1400: -1026.8285714285714\n",
      "Episode 1450: -1026.558620689655\n",
      "Episode 1500: -1027.8666666666666\n",
      "Episode 1550: -1027.1548387096775\n",
      "Episode 1600: -1025.05\n",
      "Episode 1650: -1024.6242424242423\n",
      "Episode 1700: -1023.9\n",
      "Episode 1750: -1026.462857142857\n",
      "Episode 1800: -1026.2388888888888\n",
      "Episode 1850: -1025.9783783783785\n",
      "Episode 1900: -1026.3105263157895\n",
      "Episode 1950: -1025.6102564102564\n",
      "Episode 2000: -1025.57\n",
      "Episode 2050: -1025.760975609756\n",
      "Episode 2100: -1025.0\n",
      "Episode 2150: -1025.3581395348838\n",
      "Episode 2200: -1025.2772727272727\n",
      "Episode 2250: -1025.0977777777778\n",
      "Episode 2300: -1025.2\n",
      "Episode 2350: -1024.595744680851\n",
      "Episode 2400: -1024.3833333333334\n",
      "Episode 2450: -1024.3469387755101\n",
      "Episode 2500: -1024.612\n",
      "Episode 2550: -1024.5294117647059\n",
      "Episode 2600: -1024.35\n",
      "Episode 2650: -1024.2490566037736\n",
      "Episode 2700: -1026.0222222222221\n",
      "Episode 2750: -1025.8763636363637\n",
      "Episode 2800: -1026.1107142857143\n",
      "Episode 2850: -1025.8842105263159\n",
      "Episode 2900: -1025.3586206896553\n",
      "Episode 2950: -1025.1864406779662\n",
      "Episode 3000: -1024.99\n",
      "\t\n",
      "Episode 10: -999.0\n",
      "Episode 20: -1017.0\n",
      "Episode 30: -1017.0\n",
      "Episode 40: -1019.0\n",
      "Episode 50: -1031.0\n",
      "Episode 60: -1010.0\n",
      "Episode 70: -1032.0\n",
      "Episode 80: -1022.0\n",
      "Episode 90: -924.0\n",
      "Episode 100: -1005.0\n",
      "Episode 110: -1010.0\n",
      "Episode 120: -1018.0\n",
      "Episode 130: -1034.0\n",
      "Episode 140: -1025.0\n",
      "Episode 150: -927.0\n",
      "Episode 160: -934.0\n",
      "Episode 170: -924.0\n",
      "Episode 180: -922.0\n",
      "Episode 190: -1100.0\n",
      "Episode 200: -1026.0\n",
      "Episode 210: -930.0\n",
      "Episode 220: -1039.0\n",
      "Episode 230: -1009.0\n",
      "Episode 240: -1061.0\n",
      "Episode 250: -1021.0\n",
      "Episode 260: -981.0\n",
      "Episode 270: -1021.0\n",
      "Episode 280: -1012.0\n",
      "Episode 290: -922.0\n",
      "Episode 300: -1007.0\n",
      "Episode 310: -1019.0\n",
      "Episode 320: -1007.0\n",
      "Episode 330: -1015.0\n",
      "Episode 340: -1010.0\n",
      "Episode 350: -1032.0\n",
      "Episode 360: -1035.0\n",
      "Episode 370: -1027.0\n",
      "Episode 380: -1047.0\n",
      "Episode 390: -2468.0\n",
      "Episode 400: -1019.0\n",
      "Episode 410: -1010.0\n",
      "Episode 420: -1027.0\n",
      "Episode 430: -1020.0\n",
      "Episode 440: -1020.0\n",
      "Episode 450: -1022.0\n",
      "Episode 460: -1011.0\n",
      "Episode 470: -1016.0\n",
      "Episode 480: -1037.0\n",
      "Episode 490: -1015.0\n",
      "Episode 500: -1017.0\n",
      "Episode 510: -1016.0\n",
      "Episode 520: -1026.0\n",
      "Episode 530: -1020.0\n",
      "Episode 540: -1011.0\n",
      "Episode 550: -1022.0\n",
      "Episode 560: -1039.0\n",
      "Episode 570: -1053.0\n",
      "Episode 580: -1052.0\n",
      "Episode 590: -1015.0\n",
      "Episode 600: -1024.0\n",
      "Episode 610: -1024.0\n",
      "Episode 620: -1053.0\n",
      "Episode 630: -1019.0\n",
      "Episode 640: -1031.0\n",
      "Episode 650: -1038.0\n",
      "Episode 660: -1072.0\n",
      "Episode 670: -1024.0\n",
      "Episode 680: -937.0\n",
      "Episode 690: -1020.0\n",
      "Episode 700: -951.0\n",
      "Episode 710: -1010.0\n",
      "Episode 720: -1054.0\n",
      "Episode 730: -1083.0\n",
      "Episode 740: -1098.0\n",
      "Episode 750: -1027.0\n",
      "Episode 760: -1015.0\n",
      "Episode 770: -1045.0\n",
      "Episode 780: -1059.0\n",
      "Episode 790: -1016.0\n",
      "Episode 800: -1027.0\n",
      "Episode 810: -1036.0\n",
      "Episode 820: -1033.0\n",
      "Episode 830: -1009.0\n",
      "Episode 840: -1038.0\n",
      "Episode 850: -1009.0\n",
      "Episode 860: -1008.0\n",
      "Episode 870: -1028.0\n",
      "Episode 880: -1040.0\n",
      "Episode 890: -1025.0\n",
      "Episode 900: -1026.0\n",
      "Episode 910: -1017.0\n",
      "Episode 920: -1016.0\n",
      "Episode 930: -913.0\n",
      "Episode 940: -1014.0\n",
      "Episode 950: -1099.0\n",
      "Episode 960: -1016.0\n",
      "Episode 970: -1054.0\n",
      "Episode 980: -923.0\n",
      "Episode 990: -1019.0\n",
      "Episode 1000: -1026.0\n",
      "Episode 1010: -1052.0\n",
      "Episode 1020: -1032.0\n",
      "Episode 1030: -1078.0\n",
      "Episode 1040: -1046.0\n",
      "Episode 1050: -1018.0\n",
      "Episode 1060: -924.0\n",
      "Episode 1070: -1026.0\n",
      "Episode 1080: -1020.0\n",
      "Episode 1090: -1018.0\n",
      "Episode 1100: -1016.0\n",
      "Episode 1110: -1017.0\n",
      "Episode 1120: -918.0\n",
      "Episode 1130: -1037.0\n",
      "Episode 1140: -1014.0\n",
      "Episode 1150: -1022.0\n",
      "Episode 1160: -1024.0\n",
      "Episode 1170: -1017.0\n",
      "Episode 1180: -1025.0\n",
      "Episode 1190: -1018.0\n",
      "Episode 1200: -1024.0\n",
      "Episode 1210: -1034.0\n",
      "Episode 1220: -1043.0\n",
      "Episode 1230: -1015.0\n",
      "Episode 1240: -1020.0\n",
      "Episode 1250: -1016.0\n",
      "Episode 1260: -1028.0\n",
      "Episode 1270: -1012.0\n",
      "Episode 1280: -1017.0\n",
      "Episode 1290: -1025.0\n",
      "Episode 1300: -1014.0\n",
      "Episode 1310: -1030.0\n",
      "Episode 1320: -1022.0\n",
      "Episode 1330: -914.0\n",
      "Episode 1340: -1055.0\n",
      "Episode 1350: -1018.0\n",
      "Episode 1360: -1009.0\n",
      "Episode 1370: -926.0\n",
      "Episode 1380: -1068.0\n",
      "Episode 1390: -1027.0\n",
      "Episode 1400: -1014.0\n",
      "Episode 1410: -1021.0\n",
      "Episode 1420: -1013.0\n",
      "Episode 1430: -1024.0\n",
      "Episode 1440: -1011.0\n",
      "Episode 1450: -1026.0\n",
      "Episode 1460: -1025.0\n",
      "Episode 1470: -1252.0\n",
      "Episode 1480: -1015.0\n",
      "Episode 1490: -1010.0\n",
      "Episode 1500: -1027.0\n",
      "Episode 1510: -1019.0\n",
      "Episode 1520: -1017.0\n",
      "Episode 1530: -1024.0\n",
      "Episode 1540: -927.0\n",
      "Episode 1550: -1042.0\n",
      "Episode 1560: -920.0\n",
      "Episode 1570: -1024.0\n",
      "Episode 1580: -1026.0\n",
      "Episode 1590: -916.0\n",
      "Episode 1600: -913.0\n",
      "Episode 1610: -1016.0\n",
      "Episode 1620: -1013.0\n",
      "Episode 1630: -1009.0\n",
      "Episode 1640: -1009.0\n",
      "Episode 1650: -1008.0\n",
      "Episode 1660: -1015.0\n",
      "Episode 1670: -1017.0\n",
      "Episode 1680: -1018.0\n",
      "Episode 1690: -935.0\n",
      "Episode 1700: -1015.0\n",
      "Episode 1710: -1017.0\n",
      "Episode 1720: -1047.0\n",
      "Episode 1730: -1451.0\n",
      "Episode 1740: -1021.0\n",
      "Episode 1750: -1032.0\n",
      "Episode 1760: -989.0\n",
      "Episode 1770: -1038.0\n",
      "Episode 1780: -1042.0\n",
      "Episode 1790: -1011.0\n",
      "Episode 1800: -1012.0\n",
      "Episode 1810: -1018.0\n",
      "Episode 1820: -1009.0\n",
      "Episode 1830: -1006.0\n",
      "Episode 1840: -1038.0\n",
      "Episode 1850: -1012.0\n",
      "Episode 1860: -1019.0\n",
      "Episode 1870: -1117.0\n",
      "Episode 1880: -1019.0\n",
      "Episode 1890: -1020.0\n",
      "Episode 1900: -1018.0\n",
      "Episode 1910: -1012.0\n",
      "Episode 1920: -932.0\n",
      "Episode 1930: -1017.0\n",
      "Episode 1940: -1015.0\n",
      "Episode 1950: -1019.0\n",
      "Episode 1960: -1033.0\n",
      "Episode 1970: -1010.0\n",
      "Episode 1980: -1017.0\n",
      "Episode 1990: -1018.0\n",
      "Episode 2000: -1042.0\n",
      "Episode 2010: -1014.0\n",
      "Episode 2020: -1023.0\n",
      "Episode 2030: -1016.0\n",
      "Episode 2040: -1104.0\n",
      "Episode 2050: -1010.0\n",
      "Episode 2060: -1015.0\n",
      "Episode 2070: -1015.0\n",
      "Episode 2080: -922.0\n",
      "Episode 2090: -1013.0\n",
      "Episode 2100: -1004.0\n",
      "Episode 2110: -1028.0\n",
      "Episode 2120: -1017.0\n",
      "Episode 2130: -1050.0\n",
      "Episode 2140: -1088.0\n",
      "Episode 2150: -1019.0\n",
      "Episode 2160: -924.0\n",
      "Episode 2170: -1122.0\n",
      "Episode 2180: -1013.0\n",
      "Episode 2190: -1033.0\n",
      "Episode 2200: -1017.0\n",
      "Episode 2210: -1020.0\n",
      "Episode 2220: -1014.0\n",
      "Episode 2230: -1013.0\n",
      "Episode 2240: -1017.0\n",
      "Episode 2250: -1022.0\n",
      "Episode 2260: -1013.0\n",
      "Episode 2270: -1010.0\n",
      "Episode 2280: -1090.0\n",
      "Episode 2290: -1019.0\n",
      "Episode 2300: -1017.0\n",
      "Episode 2310: -1106.0\n",
      "Episode 2320: -1009.0\n",
      "Episode 2330: -1024.0\n",
      "Episode 2340: -926.0\n",
      "Episode 2350: -919.0\n",
      "Episode 2360: -1013.0\n",
      "Episode 2370: -1013.0\n",
      "Episode 2380: -1014.0\n",
      "Episode 2390: -1017.0\n",
      "Episode 2400: -1015.0\n",
      "Episode 2410: -1014.0\n",
      "Episode 2420: -1015.0\n",
      "Episode 2430: -1016.0\n",
      "Episode 2440: -1052.0\n",
      "Episode 2450: -1016.0\n",
      "Episode 2460: -1118.0\n",
      "Episode 2470: -1023.0\n",
      "Episode 2480: -1015.0\n",
      "Episode 2490: -1028.0\n",
      "Episode 2500: -1004.0\n",
      "Episode 2510: -1016.0\n",
      "Episode 2520: -1011.0\n",
      "Episode 2530: -1023.0\n",
      "Episode 2540: -1043.0\n",
      "Episode 2550: -1009.0\n",
      "Episode 2560: -1010.0\n",
      "Episode 2570: -1028.0\n",
      "Episode 2580: -1011.0\n",
      "Episode 2590: -1011.0\n",
      "Episode 2600: -1016.0\n",
      "Episode 2610: -1024.0\n",
      "Episode 2620: -1008.0\n",
      "Episode 2630: -1006.0\n",
      "Episode 2640: -1028.0\n",
      "Episode 2650: -1029.0\n",
      "Episode 2660: -1017.0\n",
      "Episode 2670: -1019.0\n",
      "Episode 2680: -1020.0\n",
      "Episode 2690: -1018.0\n",
      "Episode 2700: -1526.0\n",
      "Episode 2710: -1022.0\n",
      "Episode 2720: -1014.0\n",
      "Episode 2730: -1017.0\n",
      "Episode 2740: -1026.0\n",
      "Episode 2750: -1011.0\n",
      "Episode 2760: -1018.0\n",
      "Episode 2770: -1011.0\n",
      "Episode 2780: -1137.0\n",
      "Episode 2790: -1014.0\n",
      "Episode 2800: -1015.0\n",
      "Episode 2810: -1011.0\n",
      "Episode 2820: -1016.0\n",
      "Episode 2830: -1008.0\n",
      "Episode 2840: -1016.0\n",
      "Episode 2850: -1015.0\n",
      "Episode 2860: -1021.0\n",
      "Episode 2870: -1014.0\n",
      "Episode 2880: -1008.0\n",
      "Episode 2890: -921.0\n",
      "Episode 2900: -1013.0\n",
      "Episode 2910: -1014.0\n",
      "Episode 2920: -1009.0\n",
      "Episode 2930: -1018.0\n",
      "Episode 2940: -1017.0\n",
      "Episode 2950: -1018.0\n",
      "Episode 2960: -1015.0\n",
      "Episode 2970: -1014.0\n",
      "Episode 2980: -1013.0\n",
      "Episode 2990: -1012.0\n",
      "Episode 3000: -1013.0\n",
      "\t\n",
      "-999.0\n",
      "-1017.0\n",
      "-1017.0\n",
      "-1019.0\n",
      "-1031.0\n",
      "-1010.0\n",
      "-1032.0\n",
      "-1022.0\n",
      "-924.0\n",
      "-1005.0\n",
      "-1010.0\n",
      "-1018.0\n",
      "-1034.0\n",
      "-1025.0\n",
      "-927.0\n",
      "-934.0\n",
      "-924.0\n",
      "-922.0\n",
      "-1100.0\n",
      "-1026.0\n",
      "-930.0\n",
      "-1039.0\n",
      "-1009.0\n",
      "-1061.0\n",
      "-1021.0\n",
      "-981.0\n",
      "-1021.0\n",
      "-1012.0\n",
      "-922.0\n",
      "-1007.0\n",
      "-1019.0\n",
      "-1007.0\n",
      "-1015.0\n",
      "-1010.0\n",
      "-1032.0\n",
      "-1035.0\n",
      "-1027.0\n",
      "-1047.0\n",
      "-2468.0\n",
      "-1019.0\n",
      "-1010.0\n",
      "-1027.0\n",
      "-1020.0\n",
      "-1020.0\n",
      "-1022.0\n",
      "-1011.0\n",
      "-1016.0\n",
      "-1037.0\n",
      "-1015.0\n",
      "-1017.0\n",
      "-1016.0\n",
      "-1026.0\n",
      "-1020.0\n",
      "-1011.0\n",
      "-1022.0\n",
      "-1039.0\n",
      "-1053.0\n",
      "-1052.0\n",
      "-1015.0\n",
      "-1024.0\n",
      "-1024.0\n",
      "-1053.0\n",
      "-1019.0\n",
      "-1031.0\n",
      "-1038.0\n",
      "-1072.0\n",
      "-1024.0\n",
      "-937.0\n",
      "-1020.0\n",
      "-951.0\n",
      "-1010.0\n",
      "-1054.0\n",
      "-1083.0\n",
      "-1098.0\n",
      "-1027.0\n",
      "-1015.0\n",
      "-1045.0\n",
      "-1059.0\n",
      "-1016.0\n",
      "-1027.0\n",
      "-1036.0\n",
      "-1033.0\n",
      "-1009.0\n",
      "-1038.0\n",
      "-1009.0\n",
      "-1008.0\n",
      "-1028.0\n",
      "-1040.0\n",
      "-1025.0\n",
      "-1026.0\n",
      "-1017.0\n",
      "-1016.0\n",
      "-913.0\n",
      "-1014.0\n",
      "-1099.0\n",
      "-1016.0\n",
      "-1054.0\n",
      "-923.0\n",
      "-1019.0\n",
      "-1026.0\n",
      "-1052.0\n",
      "-1032.0\n",
      "-1078.0\n",
      "-1046.0\n",
      "-1018.0\n",
      "-924.0\n",
      "-1026.0\n",
      "-1020.0\n",
      "-1018.0\n",
      "-1016.0\n",
      "-1017.0\n",
      "-918.0\n",
      "-1037.0\n",
      "-1014.0\n",
      "-1022.0\n",
      "-1024.0\n",
      "-1017.0\n",
      "-1025.0\n",
      "-1018.0\n",
      "-1024.0\n",
      "-1034.0\n",
      "-1043.0\n",
      "-1015.0\n",
      "-1020.0\n",
      "-1016.0\n",
      "-1028.0\n",
      "-1012.0\n",
      "-1017.0\n",
      "-1025.0\n",
      "-1014.0\n",
      "-1030.0\n",
      "-1022.0\n",
      "-914.0\n",
      "-1055.0\n",
      "-1018.0\n",
      "-1009.0\n",
      "-926.0\n",
      "-1068.0\n",
      "-1027.0\n",
      "-1014.0\n",
      "-1021.0\n",
      "-1013.0\n",
      "-1024.0\n",
      "-1011.0\n",
      "-1026.0\n",
      "-1025.0\n",
      "-1252.0\n",
      "-1015.0\n",
      "-1010.0\n",
      "-1027.0\n",
      "-1019.0\n",
      "-1017.0\n",
      "-1024.0\n",
      "-927.0\n",
      "-1042.0\n",
      "-920.0\n",
      "-1024.0\n",
      "-1026.0\n",
      "-916.0\n",
      "-913.0\n",
      "-1016.0\n",
      "-1013.0\n",
      "-1009.0\n",
      "-1009.0\n",
      "-1008.0\n",
      "-1015.0\n",
      "-1017.0\n",
      "-1018.0\n",
      "-935.0\n",
      "-1015.0\n",
      "-1017.0\n",
      "-1047.0\n",
      "-1451.0\n",
      "-1021.0\n",
      "-1032.0\n",
      "-989.0\n",
      "-1038.0\n",
      "-1042.0\n",
      "-1011.0\n",
      "-1012.0\n",
      "-1018.0\n",
      "-1009.0\n",
      "-1006.0\n",
      "-1038.0\n",
      "-1012.0\n",
      "-1019.0\n",
      "-1117.0\n",
      "-1019.0\n",
      "-1020.0\n",
      "-1018.0\n",
      "-1012.0\n",
      "-932.0\n",
      "-1017.0\n",
      "-1015.0\n",
      "-1019.0\n",
      "-1033.0\n",
      "-1010.0\n",
      "-1017.0\n",
      "-1018.0\n",
      "-1042.0\n",
      "-1014.0\n",
      "-1023.0\n",
      "-1016.0\n",
      "-1104.0\n",
      "-1010.0\n",
      "-1015.0\n",
      "-1015.0\n",
      "-922.0\n",
      "-1013.0\n",
      "-1004.0\n",
      "-1028.0\n",
      "-1017.0\n",
      "-1050.0\n",
      "-1088.0\n",
      "-1019.0\n",
      "-924.0\n",
      "-1122.0\n",
      "-1013.0\n",
      "-1033.0\n",
      "-1017.0\n",
      "-1020.0\n",
      "-1014.0\n",
      "-1013.0\n",
      "-1017.0\n",
      "-1022.0\n",
      "-1013.0\n",
      "-1010.0\n",
      "-1090.0\n",
      "-1019.0\n",
      "-1017.0\n",
      "-1106.0\n",
      "-1009.0\n",
      "-1024.0\n",
      "-926.0\n",
      "-919.0\n",
      "-1013.0\n",
      "-1013.0\n",
      "-1014.0\n",
      "-1017.0\n",
      "-1015.0\n",
      "-1014.0\n",
      "-1015.0\n",
      "-1016.0\n",
      "-1052.0\n",
      "-1016.0\n",
      "-1118.0\n",
      "-1023.0\n",
      "-1015.0\n",
      "-1028.0\n",
      "-1004.0\n",
      "-1016.0\n",
      "-1011.0\n",
      "-1023.0\n",
      "-1043.0\n",
      "-1009.0\n",
      "-1010.0\n",
      "-1028.0\n",
      "-1011.0\n",
      "-1011.0\n",
      "-1016.0\n",
      "-1024.0\n",
      "-1008.0\n",
      "-1006.0\n",
      "-1028.0\n",
      "-1029.0\n",
      "-1017.0\n",
      "-1019.0\n",
      "-1020.0\n",
      "-1018.0\n",
      "-1526.0\n",
      "-1022.0\n",
      "-1014.0\n",
      "-1017.0\n",
      "-1026.0\n",
      "-1011.0\n",
      "-1018.0\n",
      "-1011.0\n",
      "-1137.0\n",
      "-1014.0\n",
      "-1015.0\n",
      "-1011.0\n",
      "-1016.0\n",
      "-1008.0\n",
      "-1016.0\n",
      "-1015.0\n",
      "-1021.0\n",
      "-1014.0\n",
      "-1008.0\n",
      "-921.0\n",
      "-1013.0\n",
      "-1014.0\n",
      "-1009.0\n",
      "-1018.0\n",
      "-1017.0\n",
      "-1018.0\n",
      "-1015.0\n",
      "-1014.0\n",
      "-1013.0\n",
      "-1012.0\n",
      "-1013.0\n",
      "\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1008.0, 1000, False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOW USING AGENT ABOVE INSTEAD OF IMPORTANT AGENT:\n",
    "#USED TO BE: from nasim.agents.ql_agent import TabularQLearningAgent\n",
    "\n",
    "env3 = nasim.generate(**scenario_args2)\n",
    "env4 = nasim.make_benchmark(\"small\")\n",
    "baseline_dqn_agent = DQNAgent(env4, verbose=1, training_steps=3000000)\n",
    "baseline_dqn_agent.train()\n",
    "baseline_dqn_agent.run_eval_episode(render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6765de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DQN with config:\n",
      "{'batch_size': 32,\n",
      " 'env': <nasim.envs.environment.NASimEnv object at 0x7fbfd0557280>,\n",
      " 'exploration_steps': 10000,\n",
      " 'final_epsilon': 0.05,\n",
      " 'gamma': 0.99,\n",
      " 'hidden_sizes': [64, 64],\n",
      " 'kwargs': {},\n",
      " 'lr': 0.001,\n",
      " 'replay_size': 10000,\n",
      " 'seed': None,\n",
      " 'self': <__main__.DQNAgent object at 0x7fbfd0557610>,\n",
      " 'target_update_freq': 1000,\n",
      " 'training_steps': 500000,\n",
      " 'verbose': 1}\n",
      "\n",
      "Using Neural Network running on device=cuda:\n",
      "DQN(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=120, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (out): Linear(in_features=64, out_features=45, bias=True)\n",
      ")\n",
      "\n",
      "Starting training\n",
      "\n",
      "Episode 10:\n",
      "\tsteps done = 2070 / 500000\n",
      "\treturn = -301.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 20:\n",
      "\tsteps done = 4255 / 500000\n",
      "\treturn = -33.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 30:\n",
      "\tsteps done = 6230 / 500000\n",
      "\treturn = -124.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 40:\n",
      "\tsteps done = 8861 / 500000\n",
      "\treturn = -650.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 50:\n",
      "\tsteps done = 10011 / 500000\n",
      "\treturn = -69.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -235.4\n",
      "\t\n",
      "\n",
      "Episode 60:\n",
      "\tsteps done = 11978 / 500000\n",
      "\treturn = -927.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 70:\n",
      "\tsteps done = 12183 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 80:\n",
      "\tsteps done = 12244 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 90:\n",
      "\tsteps done = 12312 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 100:\n",
      "\tsteps done = 12415 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -203.7\n",
      "\t\n",
      "\n",
      "Episode 110:\n",
      "\tsteps done = 12489 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 120:\n",
      "\tsteps done = 12549 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 130:\n",
      "\tsteps done = 12621 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 140:\n",
      "\tsteps done = 12687 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 150:\n",
      "\tsteps done = 12754 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -129.8\n",
      "\t\n",
      "\n",
      "Episode 160:\n",
      "\tsteps done = 12821 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 170:\n",
      "\tsteps done = 12889 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 180:\n",
      "\tsteps done = 12950 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 190:\n",
      "\tsteps done = 13024 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 200:\n",
      "\tsteps done = 13093 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -93.15\n",
      "\t\n",
      "\n",
      "Episode 210:\n",
      "\tsteps done = 13162 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 220:\n",
      "\tsteps done = 13235 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 230:\n",
      "\tsteps done = 13301 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 240:\n",
      "\tsteps done = 13367 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 250:\n",
      "\tsteps done = 13444 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -71.2\n",
      "\t\n",
      "\n",
      "Episode 260:\n",
      "\tsteps done = 13515 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 270:\n",
      "\tsteps done = 13581 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 280:\n",
      "\tsteps done = 13650 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 290:\n",
      "\tsteps done = 13717 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 300:\n",
      "\tsteps done = 13793 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -56.4\n",
      "\t\n",
      "\n",
      "Episode 310:\n",
      "\tsteps done = 13860 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 320:\n",
      "\tsteps done = 13926 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 330:\n",
      "\tsteps done = 13988 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 340:\n",
      "\tsteps done = 15915 / 500000\n",
      "\treturn = -697.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 350:\n",
      "\tsteps done = 24037 / 500000\n",
      "\treturn = -637.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -84.97142857142858\n",
      "\t\n",
      "\n",
      "Episode 360:\n",
      "\tsteps done = 28172 / 500000\n",
      "\treturn = -141.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 370:\n",
      "\tsteps done = 28991 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 380:\n",
      "\tsteps done = 29081 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 390:\n",
      "\tsteps done = 29375 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 400:\n",
      "\tsteps done = 29438 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -76.075\n",
      "\t\n",
      "\n",
      "Episode 410:\n",
      "\tsteps done = 29502 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 420:\n",
      "\tsteps done = 29600 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 430:\n",
      "\tsteps done = 29793 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 440:\n",
      "\tsteps done = 29937 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 450:\n",
      "\tsteps done = 30194 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -65.64444444444445\n",
      "\t\n",
      "\n",
      "Episode 460:\n",
      "\tsteps done = 30257 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 470:\n",
      "\tsteps done = 30536 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 480:\n",
      "\tsteps done = 30606 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 490:\n",
      "\tsteps done = 31699 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 500:\n",
      "\tsteps done = 31822 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -57.28\n",
      "\t\n",
      "\n",
      "Episode 510:\n",
      "\tsteps done = 32006 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 520:\n",
      "\tsteps done = 32573 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 530:\n",
      "\tsteps done = 32685 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 540:\n",
      "\tsteps done = 32755 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 550:\n",
      "\tsteps done = 32844 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -50.54545454545455\n",
      "\t\n",
      "\n",
      "Episode 560:\n",
      "\tsteps done = 32938 / 500000\n",
      "\treturn = -4.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 570:\n",
      "\tsteps done = 33023 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 580:\n",
      "\tsteps done = 42930 / 500000\n",
      "\treturn = -2295.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 590:\n",
      "\tsteps done = 47286 / 500000\n",
      "\treturn = -175.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 600:\n",
      "\tsteps done = 48188 / 500000\n",
      "\treturn = -3.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -87.33333333333333\n",
      "\t\n",
      "\n",
      "Episode 610:\n",
      "\tsteps done = 48447 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 620:\n",
      "\tsteps done = 48600 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 630:\n",
      "\tsteps done = 48671 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 640:\n",
      "\tsteps done = 48759 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 650:\n",
      "\tsteps done = 48831 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -79.23076923076923\n",
      "\t\n",
      "\n",
      "Episode 660:\n",
      "\tsteps done = 48982 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 670:\n",
      "\tsteps done = 51388 / 500000\n",
      "\treturn = 4.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 680:\n",
      "\tsteps done = 54010 / 500000\n",
      "\treturn = -348.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 690:\n",
      "\tsteps done = 54187 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 700:\n",
      "\tsteps done = 54248 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -77.72857142857143\n",
      "\t\n",
      "\n",
      "Episode 710:\n",
      "\tsteps done = 54313 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 720:\n",
      "\tsteps done = 54385 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 730:\n",
      "\tsteps done = 54461 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 740:\n",
      "\tsteps done = 54533 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 750:\n",
      "\tsteps done = 54618 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -71.37333333333333\n",
      "\t\n",
      "\n",
      "Episode 760:\n",
      "\tsteps done = 54691 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 770:\n",
      "\tsteps done = 54754 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 780:\n",
      "\tsteps done = 54816 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 790:\n",
      "\tsteps done = 54880 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 800:\n",
      "\tsteps done = 54941 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -65.7875\n",
      "\t\n",
      "\n",
      "Episode 810:\n",
      "\tsteps done = 55001 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 820:\n",
      "\tsteps done = 55120 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 830:\n",
      "\tsteps done = 55203 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 840:\n",
      "\tsteps done = 55277 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 850:\n",
      "\tsteps done = 57409 / 500000\n",
      "\treturn = -115.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -62.44705882352941\n",
      "\t\n",
      "\n",
      "Episode 860:\n",
      "\tsteps done = 68872 / 500000\n",
      "\treturn = -929.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 870:\n",
      "\tsteps done = 75414 / 500000\n",
      "\treturn = -277.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 880:\n",
      "\tsteps done = 76897 / 500000\n",
      "\treturn = -22.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 890:\n",
      "\tsteps done = 81869 / 500000\n",
      "\treturn = -1077.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 900:\n",
      "\tsteps done = 89624 / 500000\n",
      "\treturn = -475.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -89.86666666666666\n",
      "\t\n",
      "\n",
      "Episode 910:\n",
      "\tsteps done = 89945 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 920:\n",
      "\tsteps done = 94022 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 930:\n",
      "\tsteps done = 94508 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 940:\n",
      "\tsteps done = 94672 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 950:\n",
      "\tsteps done = 94755 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -84.2421052631579\n",
      "\t\n",
      "\n",
      "Episode 960:\n",
      "\tsteps done = 94862 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 970:\n",
      "\tsteps done = 94979 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 980:\n",
      "\tsteps done = 95070 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 990:\n",
      "\tsteps done = 99736 / 500000\n",
      "\treturn = -2639.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1000:\n",
      "\tsteps done = 109056 / 500000\n",
      "\treturn = -47.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -106.44\n",
      "\t\n",
      "\n",
      "Episode 1010:\n",
      "\tsteps done = 109931 / 500000\n",
      "\treturn = -81.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1020:\n",
      "\tsteps done = 112309 / 500000\n",
      "\treturn = -12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1030:\n",
      "\tsteps done = 112554 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1040:\n",
      "\tsteps done = 112803 / 500000\n",
      "\treturn = 9.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1050:\n",
      "\tsteps done = 113206 / 500000\n",
      "\treturn = -11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -102.11428571428571\n",
      "\t\n",
      "\n",
      "Episode 1060:\n",
      "\tsteps done = 113343 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1070:\n",
      "\tsteps done = 113437 / 500000\n",
      "\treturn = 10.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1080:\n",
      "\tsteps done = 113698 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1090:\n",
      "\tsteps done = 113791 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1100:\n",
      "\tsteps done = 113893 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -96.77272727272727\n",
      "\t\n",
      "\n",
      "Episode 1110:\n",
      "\tsteps done = 114016 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1120:\n",
      "\tsteps done = 114431 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1130:\n",
      "\tsteps done = 114615 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1140:\n",
      "\tsteps done = 114727 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1150:\n",
      "\tsteps done = 114831 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -91.89565217391305\n",
      "\t\n",
      "\n",
      "Episode 1160:\n",
      "\tsteps done = 115663 / 500000\n",
      "\treturn = -603.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1170:\n",
      "\tsteps done = 122617 / 500000\n",
      "\treturn = -230.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1180:\n",
      "\tsteps done = 126437 / 500000\n",
      "\treturn = -32.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1190:\n",
      "\tsteps done = 126905 / 500000\n",
      "\treturn = 2.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1200:\n",
      "\tsteps done = 128182 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -95.11666666666666\n",
      "\t\n",
      "\n",
      "Episode 1210:\n",
      "\tsteps done = 128351 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1220:\n",
      "\tsteps done = 132386 / 500000\n",
      "\treturn = 11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1230:\n",
      "\tsteps done = 132460 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1240:\n",
      "\tsteps done = 132536 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1250:\n",
      "\tsteps done = 132622 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -90.704\n",
      "\t\n",
      "\n",
      "Episode 1260:\n",
      "\tsteps done = 132697 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1270:\n",
      "\tsteps done = 132772 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1280:\n",
      "\tsteps done = 132856 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1290:\n",
      "\tsteps done = 132996 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1300:\n",
      "\tsteps done = 133202 / 500000\n",
      "\treturn = -25.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -86.85384615384615\n",
      "\t\n",
      "\n",
      "Episode 1310:\n",
      "\tsteps done = 133298 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1320:\n",
      "\tsteps done = 133390 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1330:\n",
      "\tsteps done = 133495 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1340:\n",
      "\tsteps done = 133584 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1350:\n",
      "\tsteps done = 133664 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -83.0\n",
      "\t\n",
      "\n",
      "Episode 1360:\n",
      "\tsteps done = 133739 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1370:\n",
      "\tsteps done = 133815 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1380:\n",
      "\tsteps done = 133900 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1390:\n",
      "\tsteps done = 133986 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1400:\n",
      "\tsteps done = 144081 / 500000\n",
      "\treturn = -1624.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -91.15714285714286\n",
      "\t\n",
      "\n",
      "Episode 1410:\n",
      "\tsteps done = 150258 / 500000\n",
      "\treturn = -113.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1420:\n",
      "\tsteps done = 154495 / 500000\n",
      "\treturn = -197.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1430:\n",
      "\tsteps done = 157369 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1440:\n",
      "\tsteps done = 157734 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1450:\n",
      "\tsteps done = 158474 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -89.81379310344828\n",
      "\t\n",
      "\n",
      "Episode 1460:\n",
      "\tsteps done = 158959 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1470:\n",
      "\tsteps done = 160261 / 500000\n",
      "\treturn = -203.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1480:\n",
      "\tsteps done = 160885 / 500000\n",
      "\treturn = -55.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1490:\n",
      "\tsteps done = 161477 / 500000\n",
      "\treturn = -13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1500:\n",
      "\tsteps done = 166635 / 500000\n",
      "\treturn = -51.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -88.84666666666666\n",
      "\t\n",
      "\n",
      "Episode 1510:\n",
      "\tsteps done = 169021 / 500000\n",
      "\treturn = -1127.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1520:\n",
      "\tsteps done = 170359 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1530:\n",
      "\tsteps done = 170442 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1540:\n",
      "\tsteps done = 170885 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1550:\n",
      "\tsteps done = 171059 / 500000\n",
      "\treturn = -25.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -93.09032258064516\n",
      "\t\n",
      "\n",
      "Episode 1560:\n",
      "\tsteps done = 171218 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1570:\n",
      "\tsteps done = 171310 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1580:\n",
      "\tsteps done = 171458 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1590:\n",
      "\tsteps done = 171573 / 500000\n",
      "\treturn = 9.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1600:\n",
      "\tsteps done = 171648 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -89.69375\n",
      "\t\n",
      "\n",
      "Episode 1610:\n",
      "\tsteps done = 171744 / 500000\n",
      "\treturn = 8.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1620:\n",
      "\tsteps done = 171836 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1630:\n",
      "\tsteps done = 171932 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1640:\n",
      "\tsteps done = 171999 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1650:\n",
      "\tsteps done = 172061 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -86.4969696969697\n",
      "\t\n",
      "\n",
      "Episode 1660:\n",
      "\tsteps done = 172122 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1670:\n",
      "\tsteps done = 172192 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1680:\n",
      "\tsteps done = 172256 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1690:\n",
      "\tsteps done = 172321 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1700:\n",
      "\tsteps done = 172387 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -83.4235294117647\n",
      "\t\n",
      "\n",
      "Episode 1710:\n",
      "\tsteps done = 172453 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1720:\n",
      "\tsteps done = 172517 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1730:\n",
      "\tsteps done = 172586 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1740:\n",
      "\tsteps done = 172654 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1750:\n",
      "\tsteps done = 172722 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -80.56\n",
      "\t\n",
      "\n",
      "Episode 1760:\n",
      "\tsteps done = 172801 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1770:\n",
      "\tsteps done = 172866 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1780:\n",
      "\tsteps done = 172935 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1790:\n",
      "\tsteps done = 173003 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1800:\n",
      "\tsteps done = 173121 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -77.83333333333333\n",
      "\t\n",
      "\n",
      "Episode 1810:\n",
      "\tsteps done = 180537 / 500000\n",
      "\treturn = -528.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1820:\n",
      "\tsteps done = 185133 / 500000\n",
      "\treturn = -67.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1830:\n",
      "\tsteps done = 186017 / 500000\n",
      "\treturn = -264.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1840:\n",
      "\tsteps done = 187796 / 500000\n",
      "\treturn = -352.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1850:\n",
      "\tsteps done = 189141 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -82.17837837837838\n",
      "\t\n",
      "\n",
      "Episode 1860:\n",
      "\tsteps done = 189209 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1870:\n",
      "\tsteps done = 189289 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1880:\n",
      "\tsteps done = 189359 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1890:\n",
      "\tsteps done = 189425 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1900:\n",
      "\tsteps done = 189503 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -79.5421052631579\n",
      "\t\n",
      "\n",
      "Episode 1910:\n",
      "\tsteps done = 189580 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1920:\n",
      "\tsteps done = 189667 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1930:\n",
      "\tsteps done = 189727 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1940:\n",
      "\tsteps done = 189798 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1950:\n",
      "\tsteps done = 189862 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -77.04615384615384\n",
      "\t\n",
      "\n",
      "Episode 1960:\n",
      "\tsteps done = 189925 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1970:\n",
      "\tsteps done = 189996 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1980:\n",
      "\tsteps done = 195431 / 500000\n",
      "\treturn = -213.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 1990:\n",
      "\tsteps done = 201771 / 500000\n",
      "\treturn = -10.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2000:\n",
      "\tsteps done = 203967 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -75.97\n",
      "\t\n",
      "\n",
      "Episode 2010:\n",
      "\tsteps done = 204669 / 500000\n",
      "\treturn = -203.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2020:\n",
      "\tsteps done = 205010 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2030:\n",
      "\tsteps done = 206082 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2040:\n",
      "\tsteps done = 206158 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2050:\n",
      "\tsteps done = 206243 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -74.78536585365853\n",
      "\t\n",
      "\n",
      "Episode 2060:\n",
      "\tsteps done = 206326 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2070:\n",
      "\tsteps done = 206386 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2080:\n",
      "\tsteps done = 206453 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2090:\n",
      "\tsteps done = 206520 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2100:\n",
      "\tsteps done = 206582 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -72.5952380952381\n",
      "\t\n",
      "\n",
      "Episode 2110:\n",
      "\tsteps done = 206644 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2120:\n",
      "\tsteps done = 206708 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2130:\n",
      "\tsteps done = 206777 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2140:\n",
      "\tsteps done = 206847 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2150:\n",
      "\tsteps done = 206918 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -70.48837209302326\n",
      "\t\n",
      "\n",
      "Episode 2160:\n",
      "\tsteps done = 206996 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2170:\n",
      "\tsteps done = 207071 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2180:\n",
      "\tsteps done = 207154 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2190:\n",
      "\tsteps done = 207295 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2200:\n",
      "\tsteps done = 207384 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -68.5409090909091\n",
      "\t\n",
      "\n",
      "Episode 2210:\n",
      "\tsteps done = 207458 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2220:\n",
      "\tsteps done = 207963 / 500000\n",
      "\treturn = -75.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2230:\n",
      "\tsteps done = 208058 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2240:\n",
      "\tsteps done = 208601 / 500000\n",
      "\treturn = -7.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2250:\n",
      "\tsteps done = 209001 / 500000\n",
      "\treturn = -125.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -67.78222222222222\n",
      "\t\n",
      "\n",
      "Episode 2260:\n",
      "\tsteps done = 218886 / 500000\n",
      "\treturn = -1182.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2270:\n",
      "\tsteps done = 224410 / 500000\n",
      "\treturn = -19.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2280:\n",
      "\tsteps done = 226846 / 500000\n",
      "\treturn = -538.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2290:\n",
      "\tsteps done = 228709 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2300:\n",
      "\tsteps done = 233313 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -73.71739130434783\n",
      "\t\n",
      "\n",
      "Episode 2310:\n",
      "\tsteps done = 233460 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2320:\n",
      "\tsteps done = 233601 / 500000\n",
      "\treturn = 5.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2330:\n",
      "\tsteps done = 233670 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2340:\n",
      "\tsteps done = 233755 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2350:\n",
      "\tsteps done = 233824 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -71.83829787234042\n",
      "\t\n",
      "\n",
      "Episode 2360:\n",
      "\tsteps done = 233887 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2370:\n",
      "\tsteps done = 233963 / 500000\n",
      "\treturn = 4.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2380:\n",
      "\tsteps done = 234043 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2390:\n",
      "\tsteps done = 234232 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2400:\n",
      "\tsteps done = 234549 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -70.04583333333333\n",
      "\t\n",
      "\n",
      "Episode 2410:\n",
      "\tsteps done = 234718 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2420:\n",
      "\tsteps done = 234929 / 500000\n",
      "\treturn = -74.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2430:\n",
      "\tsteps done = 239217 / 500000\n",
      "\treturn = -179.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2440:\n",
      "\tsteps done = 246889 / 500000\n",
      "\treturn = 1.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2450:\n",
      "\tsteps done = 247759 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -69.51020408163265\n",
      "\t\n",
      "\n",
      "Episode 2460:\n",
      "\tsteps done = 249250 / 500000\n",
      "\treturn = -1133.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2470:\n",
      "\tsteps done = 249311 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2480:\n",
      "\tsteps done = 249430 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2490:\n",
      "\tsteps done = 249495 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2500:\n",
      "\tsteps done = 251161 / 500000\n",
      "\treturn = -32.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -72.564\n",
      "\t\n",
      "\n",
      "Episode 2510:\n",
      "\tsteps done = 253085 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2520:\n",
      "\tsteps done = 254038 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2530:\n",
      "\tsteps done = 254116 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2540:\n",
      "\tsteps done = 255035 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2550:\n",
      "\tsteps done = 255105 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -70.83921568627451\n",
      "\t\n",
      "\n",
      "Episode 2560:\n",
      "\tsteps done = 255191 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2570:\n",
      "\tsteps done = 257614 / 500000\n",
      "\treturn = -13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2580:\n",
      "\tsteps done = 257742 / 500000\n",
      "\treturn = 10.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2590:\n",
      "\tsteps done = 258751 / 500000\n",
      "\treturn = -44.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2600:\n",
      "\tsteps done = 259838 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -69.53461538461538\n",
      "\t\n",
      "\n",
      "Episode 2610:\n",
      "\tsteps done = 259998 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2620:\n",
      "\tsteps done = 260153 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2630:\n",
      "\tsteps done = 260221 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2640:\n",
      "\tsteps done = 260302 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2650:\n",
      "\tsteps done = 260375 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -67.90943396226415\n",
      "\t\n",
      "\n",
      "Episode 2660:\n",
      "\tsteps done = 260438 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2670:\n",
      "\tsteps done = 260507 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2680:\n",
      "\tsteps done = 260578 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2690:\n",
      "\tsteps done = 260646 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2700:\n",
      "\tsteps done = 260738 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -66.32222222222222\n",
      "\t\n",
      "\n",
      "Episode 2710:\n",
      "\tsteps done = 260799 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2720:\n",
      "\tsteps done = 260877 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2730:\n",
      "\tsteps done = 260940 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2740:\n",
      "\tsteps done = 261007 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2750:\n",
      "\tsteps done = 261117 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -64.78909090909092\n",
      "\t\n",
      "\n",
      "Episode 2760:\n",
      "\tsteps done = 261208 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2770:\n",
      "\tsteps done = 261287 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2780:\n",
      "\tsteps done = 261359 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2790:\n",
      "\tsteps done = 261441 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2800:\n",
      "\tsteps done = 261513 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -63.31785714285714\n",
      "\t\n",
      "\n",
      "Episode 2810:\n",
      "\tsteps done = 261612 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2820:\n",
      "\tsteps done = 261707 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2830:\n",
      "\tsteps done = 261804 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2840:\n",
      "\tsteps done = 261898 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2850:\n",
      "\tsteps done = 261991 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -61.93684210526316\n",
      "\t\n",
      "\n",
      "Episode 2860:\n",
      "\tsteps done = 272401 / 500000\n",
      "\treturn = -171.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2870:\n",
      "\tsteps done = 277985 / 500000\n",
      "\treturn = -44.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2880:\n",
      "\tsteps done = 278525 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2890:\n",
      "\tsteps done = 279339 / 500000\n",
      "\treturn = -28.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2900:\n",
      "\tsteps done = 279467 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -61.59310344827586\n",
      "\t\n",
      "\n",
      "Episode 2910:\n",
      "\tsteps done = 279561 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2920:\n",
      "\tsteps done = 279641 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2930:\n",
      "\tsteps done = 282047 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2940:\n",
      "\tsteps done = 282131 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2950:\n",
      "\tsteps done = 282209 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -60.26101694915254\n",
      "\t\n",
      "\n",
      "Episode 2960:\n",
      "\tsteps done = 282285 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2970:\n",
      "\tsteps done = 282367 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2980:\n",
      "\tsteps done = 282450 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 2990:\n",
      "\tsteps done = 282531 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3000:\n",
      "\tsteps done = 282611 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -58.96333333333333\n",
      "\t\n",
      "\n",
      "Episode 3010:\n",
      "\tsteps done = 282688 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3020:\n",
      "\tsteps done = 282765 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3030:\n",
      "\tsteps done = 282918 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3040:\n",
      "\tsteps done = 282994 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3050:\n",
      "\tsteps done = 283066 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -57.71147540983606\n",
      "\t\n",
      "\n",
      "Episode 3060:\n",
      "\tsteps done = 283153 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3070:\n",
      "\tsteps done = 283229 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3080:\n",
      "\tsteps done = 283308 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3090:\n",
      "\tsteps done = 283390 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3100:\n",
      "\tsteps done = 283480 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -56.49032258064516\n",
      "\t\n",
      "\n",
      "Episode 3110:\n",
      "\tsteps done = 283567 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3120:\n",
      "\tsteps done = 283645 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3130:\n",
      "\tsteps done = 283717 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3140:\n",
      "\tsteps done = 283794 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3150:\n",
      "\tsteps done = 283875 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -55.317460317460316\n",
      "\t\n",
      "\n",
      "Episode 3160:\n",
      "\tsteps done = 283954 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3170:\n",
      "\tsteps done = 284032 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3180:\n",
      "\tsteps done = 284114 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3190:\n",
      "\tsteps done = 284191 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3200:\n",
      "\tsteps done = 284274 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -54.190625\n",
      "\t\n",
      "\n",
      "Episode 3210:\n",
      "\tsteps done = 284350 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3220:\n",
      "\tsteps done = 284429 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3230:\n",
      "\tsteps done = 284511 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3240:\n",
      "\tsteps done = 284586 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3250:\n",
      "\tsteps done = 284666 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -53.08307692307692\n",
      "\t\n",
      "\n",
      "Episode 3260:\n",
      "\tsteps done = 284743 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3270:\n",
      "\tsteps done = 284818 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3280:\n",
      "\tsteps done = 284893 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3290:\n",
      "\tsteps done = 284970 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3300:\n",
      "\tsteps done = 294659 / 500000\n",
      "\treturn = -1238.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -55.81212121212121\n",
      "\t\n",
      "\n",
      "Episode 3310:\n",
      "\tsteps done = 301477 / 500000\n",
      "\treturn = -55.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3320:\n",
      "\tsteps done = 302438 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3330:\n",
      "\tsteps done = 302530 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3340:\n",
      "\tsteps done = 303377 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3350:\n",
      "\tsteps done = 303478 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -54.961194029850745\n",
      "\t\n",
      "\n",
      "Episode 3360:\n",
      "\tsteps done = 307520 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3370:\n",
      "\tsteps done = 310014 / 500000\n",
      "\treturn = -508.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3380:\n",
      "\tsteps done = 310379 / 500000\n",
      "\treturn = -73.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3390:\n",
      "\tsteps done = 310614 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3400:\n",
      "\tsteps done = 310800 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -55.720588235294116\n",
      "\t\n",
      "\n",
      "Episode 3410:\n",
      "\tsteps done = 310884 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3420:\n",
      "\tsteps done = 310969 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3430:\n",
      "\tsteps done = 311057 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3440:\n",
      "\tsteps done = 311214 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3450:\n",
      "\tsteps done = 311297 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -54.666666666666664\n",
      "\t\n",
      "\n",
      "Episode 3460:\n",
      "\tsteps done = 311422 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3470:\n",
      "\tsteps done = 311518 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3480:\n",
      "\tsteps done = 311599 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3490:\n",
      "\tsteps done = 311692 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3500:\n",
      "\tsteps done = 311802 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -53.64857142857143\n",
      "\t\n",
      "\n",
      "Episode 3510:\n",
      "\tsteps done = 311904 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3520:\n",
      "\tsteps done = 311989 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3530:\n",
      "\tsteps done = 315232 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3540:\n",
      "\tsteps done = 319100 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3550:\n",
      "\tsteps done = 319176 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -52.653521126760566\n",
      "\t\n",
      "\n",
      "Episode 3560:\n",
      "\tsteps done = 319317 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3570:\n",
      "\tsteps done = 319395 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3580:\n",
      "\tsteps done = 319500 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3590:\n",
      "\tsteps done = 319584 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3600:\n",
      "\tsteps done = 319665 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -51.68888888888889\n",
      "\t\n",
      "\n",
      "Episode 3610:\n",
      "\tsteps done = 319737 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3620:\n",
      "\tsteps done = 319938 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3630:\n",
      "\tsteps done = 320014 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3640:\n",
      "\tsteps done = 320330 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3650:\n",
      "\tsteps done = 320503 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -50.74794520547945\n",
      "\t\n",
      "\n",
      "Episode 3660:\n",
      "\tsteps done = 320589 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3670:\n",
      "\tsteps done = 320680 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3680:\n",
      "\tsteps done = 320761 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3690:\n",
      "\tsteps done = 320835 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3700:\n",
      "\tsteps done = 322097 / 500000\n",
      "\treturn = -1115.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -52.891891891891895\n",
      "\t\n",
      "\n",
      "Episode 3710:\n",
      "\tsteps done = 323528 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3720:\n",
      "\tsteps done = 323844 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3730:\n",
      "\tsteps done = 323919 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3740:\n",
      "\tsteps done = 328261 / 500000\n",
      "\treturn = -200.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3750:\n",
      "\tsteps done = 332296 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -52.536\n",
      "\t\n",
      "\n",
      "Episode 3760:\n",
      "\tsteps done = 332650 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3770:\n",
      "\tsteps done = 332756 / 500000\n",
      "\treturn = 1.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3780:\n",
      "\tsteps done = 332827 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3790:\n",
      "\tsteps done = 333097 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3800:\n",
      "\tsteps done = 333172 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -51.66842105263158\n",
      "\t\n",
      "\n",
      "Episode 3810:\n",
      "\tsteps done = 333245 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3820:\n",
      "\tsteps done = 333320 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3830:\n",
      "\tsteps done = 333460 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3840:\n",
      "\tsteps done = 333679 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3850:\n",
      "\tsteps done = 333755 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -50.763636363636365\n",
      "\t\n",
      "\n",
      "Episode 3860:\n",
      "\tsteps done = 333911 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3870:\n",
      "\tsteps done = 333988 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3880:\n",
      "\tsteps done = 334084 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3890:\n",
      "\tsteps done = 334185 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3900:\n",
      "\tsteps done = 334259 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -49.88974358974359\n",
      "\t\n",
      "\n",
      "Episode 3910:\n",
      "\tsteps done = 334331 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3920:\n",
      "\tsteps done = 334407 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3930:\n",
      "\tsteps done = 334486 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3940:\n",
      "\tsteps done = 334562 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3950:\n",
      "\tsteps done = 334634 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -49.03037974683544\n",
      "\t\n",
      "\n",
      "Episode 3960:\n",
      "\tsteps done = 334713 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3970:\n",
      "\tsteps done = 334790 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3980:\n",
      "\tsteps done = 334871 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 3990:\n",
      "\tsteps done = 334946 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4000:\n",
      "\tsteps done = 335107 / 500000\n",
      "\treturn = -68.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -48.4075\n",
      "\t\n",
      "\n",
      "Episode 4010:\n",
      "\tsteps done = 335177 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4020:\n",
      "\tsteps done = 335259 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4030:\n",
      "\tsteps done = 335332 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4040:\n",
      "\tsteps done = 335416 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4050:\n",
      "\tsteps done = 335491 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -47.58765432098765\n",
      "\t\n",
      "\n",
      "Episode 4060:\n",
      "\tsteps done = 335575 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4070:\n",
      "\tsteps done = 335649 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4080:\n",
      "\tsteps done = 335776 / 500000\n",
      "\treturn = -30.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4090:\n",
      "\tsteps done = 335875 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4100:\n",
      "\tsteps done = 335965 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -46.90731707317073\n",
      "\t\n",
      "\n",
      "Episode 4110:\n",
      "\tsteps done = 340334 / 500000\n",
      "\treturn = -187.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4120:\n",
      "\tsteps done = 345026 / 500000\n",
      "\treturn = -413.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4130:\n",
      "\tsteps done = 347522 / 500000\n",
      "\treturn = -186.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4140:\n",
      "\tsteps done = 348302 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4150:\n",
      "\tsteps done = 348557 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -48.15421686746988\n",
      "\t\n",
      "\n",
      "Episode 4160:\n",
      "\tsteps done = 349008 / 500000\n",
      "\treturn = -269.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4170:\n",
      "\tsteps done = 350122 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4180:\n",
      "\tsteps done = 350220 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4190:\n",
      "\tsteps done = 350315 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4200:\n",
      "\tsteps done = 350398 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -48.07142857142857\n",
      "\t\n",
      "\n",
      "Episode 4210:\n",
      "\tsteps done = 350475 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4220:\n",
      "\tsteps done = 350547 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4230:\n",
      "\tsteps done = 350631 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4240:\n",
      "\tsteps done = 350710 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4250:\n",
      "\tsteps done = 350793 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -47.29882352941176\n",
      "\t\n",
      "\n",
      "Episode 4260:\n",
      "\tsteps done = 350879 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4270:\n",
      "\tsteps done = 350950 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4280:\n",
      "\tsteps done = 351022 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4290:\n",
      "\tsteps done = 351094 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4300:\n",
      "\tsteps done = 351174 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -46.54883720930233\n",
      "\t\n",
      "\n",
      "Episode 4310:\n",
      "\tsteps done = 351248 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4320:\n",
      "\tsteps done = 351321 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4330:\n",
      "\tsteps done = 351407 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4340:\n",
      "\tsteps done = 351483 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4350:\n",
      "\tsteps done = 351560 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -45.81609195402299\n",
      "\t\n",
      "\n",
      "Episode 4360:\n",
      "\tsteps done = 351635 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4370:\n",
      "\tsteps done = 351710 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4380:\n",
      "\tsteps done = 351787 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4390:\n",
      "\tsteps done = 351864 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4400:\n",
      "\tsteps done = 351948 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -45.095454545454544\n",
      "\t\n",
      "\n",
      "Episode 4410:\n",
      "\tsteps done = 352056 / 500000\n",
      "\treturn = -15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4420:\n",
      "\tsteps done = 352159 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4430:\n",
      "\tsteps done = 352233 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4440:\n",
      "\tsteps done = 352310 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4450:\n",
      "\tsteps done = 352382 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -44.46067415730337\n",
      "\t\n",
      "\n",
      "Episode 4460:\n",
      "\tsteps done = 352469 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4470:\n",
      "\tsteps done = 352543 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4480:\n",
      "\tsteps done = 352654 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4490:\n",
      "\tsteps done = 352725 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4500:\n",
      "\tsteps done = 352800 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -43.78888888888889\n",
      "\t\n",
      "\n",
      "Episode 4510:\n",
      "\tsteps done = 352872 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4520:\n",
      "\tsteps done = 352936 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4530:\n",
      "\tsteps done = 353009 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4540:\n",
      "\tsteps done = 358876 / 500000\n",
      "\treturn = -217.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4550:\n",
      "\tsteps done = 365447 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -43.63076923076923\n",
      "\t\n",
      "\n",
      "Episode 4560:\n",
      "\tsteps done = 365659 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4570:\n",
      "\tsteps done = 365821 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4580:\n",
      "\tsteps done = 365938 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4590:\n",
      "\tsteps done = 366471 / 500000\n",
      "\treturn = 7.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4600:\n",
      "\tsteps done = 368106 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -42.99782608695652\n",
      "\t\n",
      "\n",
      "Episode 4610:\n",
      "\tsteps done = 368191 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4620:\n",
      "\tsteps done = 368268 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4630:\n",
      "\tsteps done = 368344 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4640:\n",
      "\tsteps done = 368421 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4650:\n",
      "\tsteps done = 368494 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -42.348387096774196\n",
      "\t\n",
      "\n",
      "Episode 4660:\n",
      "\tsteps done = 368566 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4670:\n",
      "\tsteps done = 368643 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4680:\n",
      "\tsteps done = 368717 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4690:\n",
      "\tsteps done = 368795 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4700:\n",
      "\tsteps done = 368870 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.706382978723404\n",
      "\t\n",
      "\n",
      "Episode 4710:\n",
      "\tsteps done = 368950 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4720:\n",
      "\tsteps done = 369027 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4730:\n",
      "\tsteps done = 369100 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4740:\n",
      "\tsteps done = 369181 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4750:\n",
      "\tsteps done = 369254 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.090526315789475\n",
      "\t\n",
      "\n",
      "Episode 4760:\n",
      "\tsteps done = 369884 / 500000\n",
      "\treturn = -34.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4770:\n",
      "\tsteps done = 371348 / 500000\n",
      "\treturn = -48.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4780:\n",
      "\tsteps done = 371819 / 500000\n",
      "\treturn = -264.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4790:\n",
      "\tsteps done = 372600 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4800:\n",
      "\tsteps done = 372683 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.3125\n",
      "\t\n",
      "\n",
      "Episode 4810:\n",
      "\tsteps done = 372789 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4820:\n",
      "\tsteps done = 372894 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4830:\n",
      "\tsteps done = 372996 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4840:\n",
      "\tsteps done = 373064 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4850:\n",
      "\tsteps done = 373185 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -40.70721649484536\n",
      "\t\n",
      "\n",
      "Episode 4860:\n",
      "\tsteps done = 373311 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4870:\n",
      "\tsteps done = 373382 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4880:\n",
      "\tsteps done = 373469 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4890:\n",
      "\tsteps done = 373605 / 500000\n",
      "\treturn = 11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4900:\n",
      "\tsteps done = 373727 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -40.138775510204084\n",
      "\t\n",
      "\n",
      "Episode 4910:\n",
      "\tsteps done = 373821 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4920:\n",
      "\tsteps done = 373914 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4930:\n",
      "\tsteps done = 373989 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4940:\n",
      "\tsteps done = 379375 / 500000\n",
      "\treturn = -705.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4950:\n",
      "\tsteps done = 389032 / 500000\n",
      "\treturn = -653.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -42.385858585858585\n",
      "\t\n",
      "\n",
      "Episode 4960:\n",
      "\tsteps done = 389149 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4970:\n",
      "\tsteps done = 389219 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4980:\n",
      "\tsteps done = 389292 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 4990:\n",
      "\tsteps done = 389390 / 500000\n",
      "\treturn = -5.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5000:\n",
      "\tsteps done = 389467 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.836\n",
      "\t\n",
      "\n",
      "Episode 5010:\n",
      "\tsteps done = 389541 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5020:\n",
      "\tsteps done = 389617 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5030:\n",
      "\tsteps done = 389690 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5040:\n",
      "\tsteps done = 389758 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5050:\n",
      "\tsteps done = 389821 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.25148514851485\n",
      "\t\n",
      "\n",
      "Episode 5060:\n",
      "\tsteps done = 389896 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5070:\n",
      "\tsteps done = 390192 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5080:\n",
      "\tsteps done = 390469 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5090:\n",
      "\tsteps done = 397833 / 500000\n",
      "\treturn = -382.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5100:\n",
      "\tsteps done = 402126 / 500000\n",
      "\treturn = -79.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.654901960784315\n",
      "\t\n",
      "\n",
      "Episode 5110:\n",
      "\tsteps done = 402548 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5120:\n",
      "\tsteps done = 402665 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5130:\n",
      "\tsteps done = 403632 / 500000\n",
      "\treturn = 1.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5140:\n",
      "\tsteps done = 403876 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5150:\n",
      "\tsteps done = 405070 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -41.12427184466019\n",
      "\t\n",
      "\n",
      "Episode 5160:\n",
      "\tsteps done = 405152 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5170:\n",
      "\tsteps done = 405222 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5180:\n",
      "\tsteps done = 405284 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5190:\n",
      "\tsteps done = 405354 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5200:\n",
      "\tsteps done = 405429 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -40.56346153846154\n",
      "\t\n",
      "\n",
      "Episode 5210:\n",
      "\tsteps done = 405491 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5220:\n",
      "\tsteps done = 405567 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5230:\n",
      "\tsteps done = 405631 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5240:\n",
      "\tsteps done = 405697 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5250:\n",
      "\tsteps done = 405760 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -40.011428571428574\n",
      "\t\n",
      "\n",
      "Episode 5260:\n",
      "\tsteps done = 405826 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5270:\n",
      "\tsteps done = 405890 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5280:\n",
      "\tsteps done = 405973 / 500000\n",
      "\treturn = 2.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5290:\n",
      "\tsteps done = 406048 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5300:\n",
      "\tsteps done = 406114 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -39.50566037735849\n",
      "\t\n",
      "\n",
      "Episode 5310:\n",
      "\tsteps done = 406174 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5320:\n",
      "\tsteps done = 406240 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5330:\n",
      "\tsteps done = 406310 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5340:\n",
      "\tsteps done = 406376 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5350:\n",
      "\tsteps done = 406442 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.97943925233645\n",
      "\t\n",
      "\n",
      "Episode 5360:\n",
      "\tsteps done = 406513 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5370:\n",
      "\tsteps done = 406578 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5380:\n",
      "\tsteps done = 406638 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5390:\n",
      "\tsteps done = 406702 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5400:\n",
      "\tsteps done = 406768 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.455555555555556\n",
      "\t\n",
      "\n",
      "Episode 5410:\n",
      "\tsteps done = 406847 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5420:\n",
      "\tsteps done = 406910 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5430:\n",
      "\tsteps done = 406982 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5440:\n",
      "\tsteps done = 407045 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5450:\n",
      "\tsteps done = 407106 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.944954128440365\n",
      "\t\n",
      "\n",
      "Episode 5460:\n",
      "\tsteps done = 407176 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5470:\n",
      "\tsteps done = 407240 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5480:\n",
      "\tsteps done = 407306 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5490:\n",
      "\tsteps done = 407371 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5500:\n",
      "\tsteps done = 407432 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.443636363636365\n",
      "\t\n",
      "\n",
      "Episode 5510:\n",
      "\tsteps done = 407504 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5520:\n",
      "\tsteps done = 407569 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5530:\n",
      "\tsteps done = 407631 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5540:\n",
      "\tsteps done = 407698 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5550:\n",
      "\tsteps done = 407763 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -36.94414414414415\n",
      "\t\n",
      "\n",
      "Episode 5560:\n",
      "\tsteps done = 407830 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5570:\n",
      "\tsteps done = 407904 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5580:\n",
      "\tsteps done = 407972 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5590:\n",
      "\tsteps done = 408046 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5600:\n",
      "\tsteps done = 408118 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -36.4625\n",
      "\t\n",
      "\n",
      "Episode 5610:\n",
      "\tsteps done = 408187 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5620:\n",
      "\tsteps done = 408266 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5630:\n",
      "\tsteps done = 408329 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5640:\n",
      "\tsteps done = 408395 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5650:\n",
      "\tsteps done = 408459 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.9858407079646\n",
      "\t\n",
      "\n",
      "Episode 5660:\n",
      "\tsteps done = 408521 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5670:\n",
      "\tsteps done = 408581 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5680:\n",
      "\tsteps done = 408642 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5690:\n",
      "\tsteps done = 408704 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5700:\n",
      "\tsteps done = 408767 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.51929824561404\n",
      "\t\n",
      "\n",
      "Episode 5710:\n",
      "\tsteps done = 408834 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5720:\n",
      "\tsteps done = 408905 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5730:\n",
      "\tsteps done = 408978 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5740:\n",
      "\tsteps done = 409041 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5750:\n",
      "\tsteps done = 409115 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.06260869565217\n",
      "\t\n",
      "\n",
      "Episode 5760:\n",
      "\tsteps done = 409185 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5770:\n",
      "\tsteps done = 409252 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5780:\n",
      "\tsteps done = 409315 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5790:\n",
      "\tsteps done = 409383 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5800:\n",
      "\tsteps done = 409444 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -34.61379310344827\n",
      "\t\n",
      "\n",
      "Episode 5810:\n",
      "\tsteps done = 409511 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5820:\n",
      "\tsteps done = 409572 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5830:\n",
      "\tsteps done = 409639 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5840:\n",
      "\tsteps done = 409701 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5850:\n",
      "\tsteps done = 409763 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -34.16581196581197\n",
      "\t\n",
      "\n",
      "Episode 5860:\n",
      "\tsteps done = 409841 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5870:\n",
      "\tsteps done = 409908 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5880:\n",
      "\tsteps done = 409981 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5890:\n",
      "\tsteps done = 410047 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5900:\n",
      "\tsteps done = 410112 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -33.72542372881356\n",
      "\t\n",
      "\n",
      "Episode 5910:\n",
      "\tsteps done = 410179 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5920:\n",
      "\tsteps done = 410242 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5930:\n",
      "\tsteps done = 410312 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5940:\n",
      "\tsteps done = 410375 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5950:\n",
      "\tsteps done = 410450 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -33.294117647058826\n",
      "\t\n",
      "\n",
      "Episode 5960:\n",
      "\tsteps done = 410532 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5970:\n",
      "\tsteps done = 411008 / 500000\n",
      "\treturn = -374.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5980:\n",
      "\tsteps done = 411093 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 5990:\n",
      "\tsteps done = 411185 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6000:\n",
      "\tsteps done = 411268 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -33.53333333333333\n",
      "\t\n",
      "\n",
      "Episode 6010:\n",
      "\tsteps done = 411359 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6020:\n",
      "\tsteps done = 411448 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6030:\n",
      "\tsteps done = 411531 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6040:\n",
      "\tsteps done = 411620 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6050:\n",
      "\tsteps done = 411706 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -33.13388429752066\n",
      "\t\n",
      "\n",
      "Episode 6060:\n",
      "\tsteps done = 411792 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6070:\n",
      "\tsteps done = 411878 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6080:\n",
      "\tsteps done = 411963 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6090:\n",
      "\tsteps done = 418697 / 500000\n",
      "\treturn = -1443.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6100:\n",
      "\tsteps done = 429111 / 500000\n",
      "\treturn = -1738.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.998360655737706\n",
      "\t\n",
      "\n",
      "Episode 6110:\n",
      "\tsteps done = 435785 / 500000\n",
      "\treturn = -86.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6120:\n",
      "\tsteps done = 445858 / 500000\n",
      "\treturn = -131.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6130:\n",
      "\tsteps done = 447419 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6140:\n",
      "\tsteps done = 447758 / 500000\n",
      "\treturn = 11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6150:\n",
      "\tsteps done = 447907 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.97560975609756\n",
      "\t\n",
      "\n",
      "Episode 6160:\n",
      "\tsteps done = 448364 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6170:\n",
      "\tsteps done = 448506 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6180:\n",
      "\tsteps done = 448619 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6190:\n",
      "\tsteps done = 448729 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6200:\n",
      "\tsteps done = 448823 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.55483870967742\n",
      "\t\n",
      "\n",
      "Episode 6210:\n",
      "\tsteps done = 448988 / 500000\n",
      "\treturn = 14.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6220:\n",
      "\tsteps done = 449447 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6230:\n",
      "\tsteps done = 449574 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6240:\n",
      "\tsteps done = 449642 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6250:\n",
      "\tsteps done = 449727 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.1168\n",
      "\t\n",
      "\n",
      "Episode 6260:\n",
      "\tsteps done = 449787 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6270:\n",
      "\tsteps done = 449849 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6280:\n",
      "\tsteps done = 449915 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6290:\n",
      "\tsteps done = 449983 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6300:\n",
      "\tsteps done = 450052 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -36.67936507936508\n",
      "\t\n",
      "\n",
      "Episode 6310:\n",
      "\tsteps done = 450177 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6320:\n",
      "\tsteps done = 450244 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6330:\n",
      "\tsteps done = 450331 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6340:\n",
      "\tsteps done = 450396 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6350:\n",
      "\tsteps done = 450464 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -36.25196850393701\n",
      "\t\n",
      "\n",
      "Episode 6360:\n",
      "\tsteps done = 450529 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6370:\n",
      "\tsteps done = 450596 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6380:\n",
      "\tsteps done = 450661 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6390:\n",
      "\tsteps done = 450732 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6400:\n",
      "\tsteps done = 450803 / 500000\n",
      "\treturn = 10.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.840625\n",
      "\t\n",
      "\n",
      "Episode 6410:\n",
      "\tsteps done = 450865 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6420:\n",
      "\tsteps done = 450937 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6430:\n",
      "\tsteps done = 450998 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6440:\n",
      "\tsteps done = 451061 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6450:\n",
      "\tsteps done = 451218 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.42945736434108\n",
      "\t\n",
      "\n",
      "Episode 6460:\n",
      "\tsteps done = 451293 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6470:\n",
      "\tsteps done = 451363 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6480:\n",
      "\tsteps done = 451432 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6490:\n",
      "\tsteps done = 451498 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6500:\n",
      "\tsteps done = 451564 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -35.03230769230769\n",
      "\t\n",
      "\n",
      "Episode 6510:\n",
      "\tsteps done = 451650 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6520:\n",
      "\tsteps done = 451821 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6530:\n",
      "\tsteps done = 454156 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6540:\n",
      "\tsteps done = 454227 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6550:\n",
      "\tsteps done = 457022 / 500000\n",
      "\treturn = -2503.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.48091603053435\n",
      "\t\n",
      "\n",
      "Episode 6560:\n",
      "\tsteps done = 464329 / 500000\n",
      "\treturn = -259.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6570:\n",
      "\tsteps done = 465069 / 500000\n",
      "\treturn = -44.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6580:\n",
      "\tsteps done = 465700 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6590:\n",
      "\tsteps done = 465807 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6600:\n",
      "\tsteps done = 465904 / 500000\n",
      "\treturn = 11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.58030303030303\n",
      "\t\n",
      "\n",
      "Episode 6610:\n",
      "\tsteps done = 465993 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6620:\n",
      "\tsteps done = 466096 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6630:\n",
      "\tsteps done = 466158 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6640:\n",
      "\tsteps done = 466218 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6650:\n",
      "\tsteps done = 466284 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.15639097744361\n",
      "\t\n",
      "\n",
      "Episode 6660:\n",
      "\tsteps done = 466348 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6670:\n",
      "\tsteps done = 466409 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6680:\n",
      "\tsteps done = 466476 / 500000\n",
      "\treturn = 17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6690:\n",
      "\tsteps done = 466538 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6700:\n",
      "\tsteps done = 466628 / 500000\n",
      "\treturn = 11.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.74925373134328\n",
      "\t\n",
      "\n",
      "Episode 6710:\n",
      "\tsteps done = 466691 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6720:\n",
      "\tsteps done = 466781 / 500000\n",
      "\treturn = -6.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6730:\n",
      "\tsteps done = 466859 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6740:\n",
      "\tsteps done = 466932 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6750:\n",
      "\tsteps done = 467004 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.37481481481481\n",
      "\t\n",
      "\n",
      "Episode 6760:\n",
      "\tsteps done = 471911 / 500000\n",
      "\treturn = -17.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6770:\n",
      "\tsteps done = 477918 / 500000\n",
      "\treturn = -242.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6780:\n",
      "\tsteps done = 485791 / 500000\n",
      "\treturn = -675.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6790:\n",
      "\tsteps done = 486410 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6800:\n",
      "\tsteps done = 486539 / 500000\n",
      "\treturn = -2.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.45\n",
      "\t\n",
      "\n",
      "Episode 6810:\n",
      "\tsteps done = 486607 / 500000\n",
      "\treturn = 12.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6820:\n",
      "\tsteps done = 486678 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6830:\n",
      "\tsteps done = 486751 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6840:\n",
      "\tsteps done = 486832 / 500000\n",
      "\treturn = 15.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6850:\n",
      "\tsteps done = 486940 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -38.051094890510946\n",
      "\t\n",
      "\n",
      "Episode 6860:\n",
      "\tsteps done = 487007 / 500000\n",
      "\treturn = 13.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6870:\n",
      "\tsteps done = 487130 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6880:\n",
      "\tsteps done = 487191 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6890:\n",
      "\tsteps done = 487258 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6900:\n",
      "\tsteps done = 487318 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.65217391304348\n",
      "\t\n",
      "\n",
      "Episode 6910:\n",
      "\tsteps done = 487387 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6920:\n",
      "\tsteps done = 487458 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6930:\n",
      "\tsteps done = 487524 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6940:\n",
      "\tsteps done = 487591 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6950:\n",
      "\tsteps done = 487653 / 500000\n",
      "\treturn = 16.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -37.257553956834535\n",
      "\t\n",
      "\n",
      "Episode 6960:\n",
      "\tsteps done = 487719 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6970:\n",
      "\tsteps done = 487783 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6980:\n",
      "\tsteps done = 487848 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 6990:\n",
      "\tsteps done = 487912 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 7000:\n",
      "\tsteps done = 487976 / 500000\n",
      "\treturn = 18.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\t\n",
      "\tRunning_Average = -36.862857142857145\n",
      "\t\n",
      "\n",
      "Episode 7010:\n",
      "\tsteps done = 490303 / 500000\n",
      "\treturn = -2240.0\n",
      "\tgoal = True\n",
      "\t\n",
      "\n",
      "Episode 7020:\n",
      "\tsteps done = 496787 / 500000\n",
      "\treturn = -54.0\n",
      "\tgoal = True\n",
      "\t\n",
      "Training complete\n",
      "\n",
      "Episode 7026:\n",
      "\tsteps done = 500000 / 500000\n",
      "\treturn = -890.0\n",
      "\tgoal = False\n",
      "\t\n",
      "Running_Average List:\n",
      "\t\n",
      "Episode 50: -235.4\n",
      "Episode 100: -203.7\n",
      "Episode 150: -129.8\n",
      "Episode 200: -93.15\n",
      "Episode 250: -71.2\n",
      "Episode 300: -56.4\n",
      "Episode 350: -84.97142857142858\n",
      "Episode 400: -76.075\n",
      "Episode 450: -65.64444444444445\n",
      "Episode 500: -57.28\n",
      "Episode 550: -50.54545454545455\n",
      "Episode 600: -87.33333333333333\n",
      "Episode 650: -79.23076923076923\n",
      "Episode 700: -77.72857142857143\n",
      "Episode 750: -71.37333333333333\n",
      "Episode 800: -65.7875\n",
      "Episode 850: -62.44705882352941\n",
      "Episode 900: -89.86666666666666\n",
      "Episode 950: -84.2421052631579\n",
      "Episode 1000: -106.44\n",
      "Episode 1050: -102.11428571428571\n",
      "Episode 1100: -96.77272727272727\n",
      "Episode 1150: -91.89565217391305\n",
      "Episode 1200: -95.11666666666666\n",
      "Episode 1250: -90.704\n",
      "Episode 1300: -86.85384615384615\n",
      "Episode 1350: -83.0\n",
      "Episode 1400: -91.15714285714286\n",
      "Episode 1450: -89.81379310344828\n",
      "Episode 1500: -88.84666666666666\n",
      "Episode 1550: -93.09032258064516\n",
      "Episode 1600: -89.69375\n",
      "Episode 1650: -86.4969696969697\n",
      "Episode 1700: -83.4235294117647\n",
      "Episode 1750: -80.56\n",
      "Episode 1800: -77.83333333333333\n",
      "Episode 1850: -82.17837837837838\n",
      "Episode 1900: -79.5421052631579\n",
      "Episode 1950: -77.04615384615384\n",
      "Episode 2000: -75.97\n",
      "Episode 2050: -74.78536585365853\n",
      "Episode 2100: -72.5952380952381\n",
      "Episode 2150: -70.48837209302326\n",
      "Episode 2200: -68.5409090909091\n",
      "Episode 2250: -67.78222222222222\n",
      "Episode 2300: -73.71739130434783\n",
      "Episode 2350: -71.83829787234042\n",
      "Episode 2400: -70.04583333333333\n",
      "Episode 2450: -69.51020408163265\n",
      "Episode 2500: -72.564\n",
      "Episode 2550: -70.83921568627451\n",
      "Episode 2600: -69.53461538461538\n",
      "Episode 2650: -67.90943396226415\n",
      "Episode 2700: -66.32222222222222\n",
      "Episode 2750: -64.78909090909092\n",
      "Episode 2800: -63.31785714285714\n",
      "Episode 2850: -61.93684210526316\n",
      "Episode 2900: -61.59310344827586\n",
      "Episode 2950: -60.26101694915254\n",
      "Episode 3000: -58.96333333333333\n",
      "Episode 3050: -57.71147540983606\n",
      "Episode 3100: -56.49032258064516\n",
      "Episode 3150: -55.317460317460316\n",
      "Episode 3200: -54.190625\n",
      "Episode 3250: -53.08307692307692\n",
      "Episode 3300: -55.81212121212121\n",
      "Episode 3350: -54.961194029850745\n",
      "Episode 3400: -55.720588235294116\n",
      "Episode 3450: -54.666666666666664\n",
      "Episode 3500: -53.64857142857143\n",
      "Episode 3550: -52.653521126760566\n",
      "Episode 3600: -51.68888888888889\n",
      "Episode 3650: -50.74794520547945\n",
      "Episode 3700: -52.891891891891895\n",
      "Episode 3750: -52.536\n",
      "Episode 3800: -51.66842105263158\n",
      "Episode 3850: -50.763636363636365\n",
      "Episode 3900: -49.88974358974359\n",
      "Episode 3950: -49.03037974683544\n",
      "Episode 4000: -48.4075\n",
      "Episode 4050: -47.58765432098765\n",
      "Episode 4100: -46.90731707317073\n",
      "Episode 4150: -48.15421686746988\n",
      "Episode 4200: -48.07142857142857\n",
      "Episode 4250: -47.29882352941176\n",
      "Episode 4300: -46.54883720930233\n",
      "Episode 4350: -45.81609195402299\n",
      "Episode 4400: -45.095454545454544\n",
      "Episode 4450: -44.46067415730337\n",
      "Episode 4500: -43.78888888888889\n",
      "Episode 4550: -43.63076923076923\n",
      "Episode 4600: -42.99782608695652\n",
      "Episode 4650: -42.348387096774196\n",
      "Episode 4700: -41.706382978723404\n",
      "Episode 4750: -41.090526315789475\n",
      "Episode 4800: -41.3125\n",
      "Episode 4850: -40.70721649484536\n",
      "Episode 4900: -40.138775510204084\n",
      "Episode 4950: -42.385858585858585\n",
      "Episode 5000: -41.836\n",
      "Episode 5050: -41.25148514851485\n",
      "Episode 5100: -41.654901960784315\n",
      "Episode 5150: -41.12427184466019\n",
      "Episode 5200: -40.56346153846154\n",
      "Episode 5250: -40.011428571428574\n",
      "Episode 5300: -39.50566037735849\n",
      "Episode 5350: -38.97943925233645\n",
      "Episode 5400: -38.455555555555556\n",
      "Episode 5450: -37.944954128440365\n",
      "Episode 5500: -37.443636363636365\n",
      "Episode 5550: -36.94414414414415\n",
      "Episode 5600: -36.4625\n",
      "Episode 5650: -35.9858407079646\n",
      "Episode 5700: -35.51929824561404\n",
      "Episode 5750: -35.06260869565217\n",
      "Episode 5800: -34.61379310344827\n",
      "Episode 5850: -34.16581196581197\n",
      "Episode 5900: -33.72542372881356\n",
      "Episode 5950: -33.294117647058826\n",
      "Episode 6000: -33.53333333333333\n",
      "Episode 6050: -33.13388429752066\n",
      "Episode 6100: -37.998360655737706\n",
      "Episode 6150: -37.97560975609756\n",
      "Episode 6200: -37.55483870967742\n",
      "Episode 6250: -37.1168\n",
      "Episode 6300: -36.67936507936508\n",
      "Episode 6350: -36.25196850393701\n",
      "Episode 6400: -35.840625\n",
      "Episode 6450: -35.42945736434108\n",
      "Episode 6500: -35.03230769230769\n",
      "Episode 6550: -38.48091603053435\n",
      "Episode 6600: -38.58030303030303\n",
      "Episode 6650: -38.15639097744361\n",
      "Episode 6700: -37.74925373134328\n",
      "Episode 6750: -37.37481481481481\n",
      "Episode 6800: -38.45\n",
      "Episode 6850: -38.051094890510946\n",
      "Episode 6900: -37.65217391304348\n",
      "Episode 6950: -37.257553956834535\n",
      "Episode 7000: -36.862857142857145\n",
      "\t\n",
      "Episode 10: -301.0\n",
      "Episode 20: -33.0\n",
      "Episode 30: -124.0\n",
      "Episode 40: -650.0\n",
      "Episode 50: -69.0\n",
      "Episode 60: -927.0\n",
      "Episode 70: 16.0\n",
      "Episode 80: 18.0\n",
      "Episode 90: 18.0\n",
      "Episode 100: 15.0\n",
      "Episode 110: 18.0\n",
      "Episode 120: 18.0\n",
      "Episode 130: 18.0\n",
      "Episode 140: 18.0\n",
      "Episode 150: 18.0\n",
      "Episode 160: 18.0\n",
      "Episode 170: 12.0\n",
      "Episode 180: 18.0\n",
      "Episode 190: 18.0\n",
      "Episode 200: 18.0\n",
      "Episode 210: 18.0\n",
      "Episode 220: 18.0\n",
      "Episode 230: 18.0\n",
      "Episode 240: 16.0\n",
      "Episode 250: 13.0\n",
      "Episode 260: 18.0\n",
      "Episode 270: 18.0\n",
      "Episode 280: 18.0\n",
      "Episode 290: 18.0\n",
      "Episode 300: 16.0\n",
      "Episode 310: 16.0\n",
      "Episode 320: 18.0\n",
      "Episode 330: 18.0\n",
      "Episode 340: -697.0\n",
      "Episode 350: -637.0\n",
      "Episode 360: -141.0\n",
      "Episode 370: 18.0\n",
      "Episode 380: 18.0\n",
      "Episode 390: 18.0\n",
      "Episode 400: 18.0\n",
      "Episode 410: 18.0\n",
      "Episode 420: 18.0\n",
      "Episode 430: 18.0\n",
      "Episode 440: 17.0\n",
      "Episode 450: 18.0\n",
      "Episode 460: 18.0\n",
      "Episode 470: 18.0\n",
      "Episode 480: 18.0\n",
      "Episode 490: 18.0\n",
      "Episode 500: 18.0\n",
      "Episode 510: 17.0\n",
      "Episode 520: 16.0\n",
      "Episode 530: 17.0\n",
      "Episode 540: 17.0\n",
      "Episode 550: 17.0\n",
      "Episode 560: -4.0\n",
      "Episode 570: 17.0\n",
      "Episode 580: -2295.0\n",
      "Episode 590: -175.0\n",
      "Episode 600: -3.0\n",
      "Episode 610: 18.0\n",
      "Episode 620: 18.0\n",
      "Episode 630: 18.0\n",
      "Episode 640: 18.0\n",
      "Episode 650: 18.0\n",
      "Episode 660: 17.0\n",
      "Episode 670: 4.0\n",
      "Episode 680: -348.0\n",
      "Episode 690: 18.0\n",
      "Episode 700: 18.0\n",
      "Episode 710: 18.0\n",
      "Episode 720: 18.0\n",
      "Episode 730: 16.0\n",
      "Episode 740: 18.0\n",
      "Episode 750: 18.0\n",
      "Episode 760: 18.0\n",
      "Episode 770: 18.0\n",
      "Episode 780: 18.0\n",
      "Episode 790: 18.0\n",
      "Episode 800: 18.0\n",
      "Episode 810: 18.0\n",
      "Episode 820: 18.0\n",
      "Episode 830: 16.0\n",
      "Episode 840: 18.0\n",
      "Episode 850: -115.0\n",
      "Episode 860: -929.0\n",
      "Episode 870: -277.0\n",
      "Episode 880: -22.0\n",
      "Episode 890: -1077.0\n",
      "Episode 900: -475.0\n",
      "Episode 910: 18.0\n",
      "Episode 920: 18.0\n",
      "Episode 930: 16.0\n",
      "Episode 940: 17.0\n",
      "Episode 950: 16.0\n",
      "Episode 960: 16.0\n",
      "Episode 970: 17.0\n",
      "Episode 980: 12.0\n",
      "Episode 990: -2639.0\n",
      "Episode 1000: -47.0\n",
      "Episode 1010: -81.0\n",
      "Episode 1020: -12.0\n",
      "Episode 1030: 17.0\n",
      "Episode 1040: 9.0\n",
      "Episode 1050: -11.0\n",
      "Episode 1060: 17.0\n",
      "Episode 1070: 10.0\n",
      "Episode 1080: 17.0\n",
      "Episode 1090: 17.0\n",
      "Episode 1100: 16.0\n",
      "Episode 1110: 17.0\n",
      "Episode 1120: 17.0\n",
      "Episode 1130: 17.0\n",
      "Episode 1140: 13.0\n",
      "Episode 1150: 13.0\n",
      "Episode 1160: -603.0\n",
      "Episode 1170: -230.0\n",
      "Episode 1180: -32.0\n",
      "Episode 1190: 2.0\n",
      "Episode 1200: 17.0\n",
      "Episode 1210: 13.0\n",
      "Episode 1220: 11.0\n",
      "Episode 1230: 18.0\n",
      "Episode 1240: 18.0\n",
      "Episode 1250: 16.0\n",
      "Episode 1260: 18.0\n",
      "Episode 1270: 18.0\n",
      "Episode 1280: 18.0\n",
      "Episode 1290: 18.0\n",
      "Episode 1300: -25.0\n",
      "Episode 1310: 17.0\n",
      "Episode 1320: 16.0\n",
      "Episode 1330: 17.0\n",
      "Episode 1340: 18.0\n",
      "Episode 1350: 18.0\n",
      "Episode 1360: 18.0\n",
      "Episode 1370: 18.0\n",
      "Episode 1380: 16.0\n",
      "Episode 1390: 15.0\n",
      "Episode 1400: -1624.0\n",
      "Episode 1410: -113.0\n",
      "Episode 1420: -197.0\n",
      "Episode 1430: 15.0\n",
      "Episode 1440: 18.0\n",
      "Episode 1450: 16.0\n",
      "Episode 1460: 18.0\n",
      "Episode 1470: -203.0\n",
      "Episode 1480: -55.0\n",
      "Episode 1490: -13.0\n",
      "Episode 1500: -51.0\n",
      "Episode 1510: -1127.0\n",
      "Episode 1520: 17.0\n",
      "Episode 1530: 17.0\n",
      "Episode 1540: 16.0\n",
      "Episode 1550: -25.0\n",
      "Episode 1560: 18.0\n",
      "Episode 1570: 18.0\n",
      "Episode 1580: 18.0\n",
      "Episode 1590: 9.0\n",
      "Episode 1600: 15.0\n",
      "Episode 1610: 8.0\n",
      "Episode 1620: 18.0\n",
      "Episode 1630: 18.0\n",
      "Episode 1640: 17.0\n",
      "Episode 1650: 18.0\n",
      "Episode 1660: 18.0\n",
      "Episode 1670: 18.0\n",
      "Episode 1680: 18.0\n",
      "Episode 1690: 18.0\n",
      "Episode 1700: 18.0\n",
      "Episode 1710: 18.0\n",
      "Episode 1720: 14.0\n",
      "Episode 1730: 16.0\n",
      "Episode 1740: 18.0\n",
      "Episode 1750: 18.0\n",
      "Episode 1760: 18.0\n",
      "Episode 1770: 18.0\n",
      "Episode 1780: 18.0\n",
      "Episode 1790: 18.0\n",
      "Episode 1800: 16.0\n",
      "Episode 1810: -528.0\n",
      "Episode 1820: -67.0\n",
      "Episode 1830: -264.0\n",
      "Episode 1840: -352.0\n",
      "Episode 1850: 18.0\n",
      "Episode 1860: 18.0\n",
      "Episode 1870: 18.0\n",
      "Episode 1880: 18.0\n",
      "Episode 1890: 18.0\n",
      "Episode 1900: 18.0\n",
      "Episode 1910: 17.0\n",
      "Episode 1920: 18.0\n",
      "Episode 1930: 18.0\n",
      "Episode 1940: 18.0\n",
      "Episode 1950: 18.0\n",
      "Episode 1960: 18.0\n",
      "Episode 1970: 18.0\n",
      "Episode 1980: -213.0\n",
      "Episode 1990: -10.0\n",
      "Episode 2000: 17.0\n",
      "Episode 2010: -203.0\n",
      "Episode 2020: 18.0\n",
      "Episode 2030: 18.0\n",
      "Episode 2040: 16.0\n",
      "Episode 2050: 14.0\n",
      "Episode 2060: 18.0\n",
      "Episode 2070: 18.0\n",
      "Episode 2080: 18.0\n",
      "Episode 2090: 16.0\n",
      "Episode 2100: 16.0\n",
      "Episode 2110: 18.0\n",
      "Episode 2120: 18.0\n",
      "Episode 2130: 18.0\n",
      "Episode 2140: 18.0\n",
      "Episode 2150: 18.0\n",
      "Episode 2160: 13.0\n",
      "Episode 2170: 17.0\n",
      "Episode 2180: 17.0\n",
      "Episode 2190: 14.0\n",
      "Episode 2200: 15.0\n",
      "Episode 2210: 17.0\n",
      "Episode 2220: -75.0\n",
      "Episode 2230: 18.0\n",
      "Episode 2240: -7.0\n",
      "Episode 2250: -125.0\n",
      "Episode 2260: -1182.0\n",
      "Episode 2270: -19.0\n",
      "Episode 2280: -538.0\n",
      "Episode 2290: 17.0\n",
      "Episode 2300: 18.0\n",
      "Episode 2310: 16.0\n",
      "Episode 2320: 5.0\n",
      "Episode 2330: 18.0\n",
      "Episode 2340: 16.0\n",
      "Episode 2350: 18.0\n",
      "Episode 2360: 18.0\n",
      "Episode 2370: 4.0\n",
      "Episode 2380: 17.0\n",
      "Episode 2390: 15.0\n",
      "Episode 2400: 17.0\n",
      "Episode 2410: 15.0\n",
      "Episode 2420: -74.0\n",
      "Episode 2430: -179.0\n",
      "Episode 2440: 1.0\n",
      "Episode 2450: 18.0\n",
      "Episode 2460: -1133.0\n",
      "Episode 2470: 18.0\n",
      "Episode 2480: 18.0\n",
      "Episode 2490: 18.0\n",
      "Episode 2500: -32.0\n",
      "Episode 2510: 17.0\n",
      "Episode 2520: 14.0\n",
      "Episode 2530: 17.0\n",
      "Episode 2540: 12.0\n",
      "Episode 2550: 17.0\n",
      "Episode 2560: 17.0\n",
      "Episode 2570: -13.0\n",
      "Episode 2580: 10.0\n",
      "Episode 2590: -44.0\n",
      "Episode 2600: 15.0\n",
      "Episode 2610: 16.0\n",
      "Episode 2620: 15.0\n",
      "Episode 2630: 18.0\n",
      "Episode 2640: 18.0\n",
      "Episode 2650: 16.0\n",
      "Episode 2660: 18.0\n",
      "Episode 2670: 17.0\n",
      "Episode 2680: 18.0\n",
      "Episode 2690: 18.0\n",
      "Episode 2700: 18.0\n",
      "Episode 2710: 18.0\n",
      "Episode 2720: 18.0\n",
      "Episode 2730: 18.0\n",
      "Episode 2740: 18.0\n",
      "Episode 2750: 18.0\n",
      "Episode 2760: 18.0\n",
      "Episode 2770: 16.0\n",
      "Episode 2780: 18.0\n",
      "Episode 2790: 18.0\n",
      "Episode 2800: 18.0\n",
      "Episode 2810: 14.0\n",
      "Episode 2820: 16.0\n",
      "Episode 2830: 15.0\n",
      "Episode 2840: 16.0\n",
      "Episode 2850: 16.0\n",
      "Episode 2860: -171.0\n",
      "Episode 2870: -44.0\n",
      "Episode 2880: 16.0\n",
      "Episode 2890: -28.0\n",
      "Episode 2900: 17.0\n",
      "Episode 2910: 17.0\n",
      "Episode 2920: 17.0\n",
      "Episode 2930: 18.0\n",
      "Episode 2940: 18.0\n",
      "Episode 2950: 15.0\n",
      "Episode 2960: 18.0\n",
      "Episode 2970: 18.0\n",
      "Episode 2980: 16.0\n",
      "Episode 2990: 18.0\n",
      "Episode 3000: 18.0\n",
      "Episode 3010: 18.0\n",
      "Episode 3020: 18.0\n",
      "Episode 3030: 18.0\n",
      "Episode 3040: 15.0\n",
      "Episode 3050: 18.0\n",
      "Episode 3060: 18.0\n",
      "Episode 3070: 18.0\n",
      "Episode 3080: 18.0\n",
      "Episode 3090: 18.0\n",
      "Episode 3100: 18.0\n",
      "Episode 3110: 18.0\n",
      "Episode 3120: 18.0\n",
      "Episode 3130: 18.0\n",
      "Episode 3140: 15.0\n",
      "Episode 3150: 18.0\n",
      "Episode 3160: 18.0\n",
      "Episode 3170: 14.0\n",
      "Episode 3180: 18.0\n",
      "Episode 3190: 18.0\n",
      "Episode 3200: 16.0\n",
      "Episode 3210: 18.0\n",
      "Episode 3220: 18.0\n",
      "Episode 3230: 18.0\n",
      "Episode 3240: 18.0\n",
      "Episode 3250: 17.0\n",
      "Episode 3260: 18.0\n",
      "Episode 3270: 18.0\n",
      "Episode 3280: 18.0\n",
      "Episode 3290: 18.0\n",
      "Episode 3300: -1238.0\n",
      "Episode 3310: -55.0\n",
      "Episode 3320: 13.0\n",
      "Episode 3330: 16.0\n",
      "Episode 3340: 15.0\n",
      "Episode 3350: 17.0\n",
      "Episode 3360: 14.0\n",
      "Episode 3370: -508.0\n",
      "Episode 3380: -73.0\n",
      "Episode 3390: 17.0\n",
      "Episode 3400: 17.0\n",
      "Episode 3410: 17.0\n",
      "Episode 3420: 17.0\n",
      "Episode 3430: 17.0\n",
      "Episode 3440: 17.0\n",
      "Episode 3450: 17.0\n",
      "Episode 3460: 17.0\n",
      "Episode 3470: 15.0\n",
      "Episode 3480: 17.0\n",
      "Episode 3490: 17.0\n",
      "Episode 3500: 17.0\n",
      "Episode 3510: 17.0\n",
      "Episode 3520: 17.0\n",
      "Episode 3530: 17.0\n",
      "Episode 3540: 16.0\n",
      "Episode 3550: 18.0\n",
      "Episode 3560: 17.0\n",
      "Episode 3570: 16.0\n",
      "Episode 3580: 18.0\n",
      "Episode 3590: 18.0\n",
      "Episode 3600: 15.0\n",
      "Episode 3610: 18.0\n",
      "Episode 3620: 18.0\n",
      "Episode 3630: 14.0\n",
      "Episode 3640: 18.0\n",
      "Episode 3650: 17.0\n",
      "Episode 3660: 18.0\n",
      "Episode 3670: 18.0\n",
      "Episode 3680: 14.0\n",
      "Episode 3690: 18.0\n",
      "Episode 3700: -1115.0\n",
      "Episode 3710: 18.0\n",
      "Episode 3720: 17.0\n",
      "Episode 3730: 17.0\n",
      "Episode 3740: -200.0\n",
      "Episode 3750: 17.0\n",
      "Episode 3760: 18.0\n",
      "Episode 3770: 1.0\n",
      "Episode 3780: 18.0\n",
      "Episode 3790: 12.0\n",
      "Episode 3800: 18.0\n",
      "Episode 3810: 18.0\n",
      "Episode 3820: 18.0\n",
      "Episode 3830: 18.0\n",
      "Episode 3840: 18.0\n",
      "Episode 3850: 18.0\n",
      "Episode 3860: 18.0\n",
      "Episode 3870: 16.0\n",
      "Episode 3880: 18.0\n",
      "Episode 3890: 17.0\n",
      "Episode 3900: 18.0\n",
      "Episode 3910: 18.0\n",
      "Episode 3920: 18.0\n",
      "Episode 3930: 18.0\n",
      "Episode 3940: 18.0\n",
      "Episode 3950: 18.0\n",
      "Episode 3960: 18.0\n",
      "Episode 3970: 18.0\n",
      "Episode 3980: 18.0\n",
      "Episode 3990: 18.0\n",
      "Episode 4000: -68.0\n",
      "Episode 4010: 18.0\n",
      "Episode 4020: 18.0\n",
      "Episode 4030: 18.0\n",
      "Episode 4040: 18.0\n",
      "Episode 4050: 18.0\n",
      "Episode 4060: 18.0\n",
      "Episode 4070: 18.0\n",
      "Episode 4080: -30.0\n",
      "Episode 4090: 17.0\n",
      "Episode 4100: 18.0\n",
      "Episode 4110: -187.0\n",
      "Episode 4120: -413.0\n",
      "Episode 4130: -186.0\n",
      "Episode 4140: 17.0\n",
      "Episode 4150: 17.0\n",
      "Episode 4160: -269.0\n",
      "Episode 4170: 15.0\n",
      "Episode 4180: 15.0\n",
      "Episode 4190: 15.0\n",
      "Episode 4200: 18.0\n",
      "Episode 4210: 18.0\n",
      "Episode 4220: 18.0\n",
      "Episode 4230: 16.0\n",
      "Episode 4240: 18.0\n",
      "Episode 4250: 18.0\n",
      "Episode 4260: 16.0\n",
      "Episode 4270: 18.0\n",
      "Episode 4280: 16.0\n",
      "Episode 4290: 18.0\n",
      "Episode 4300: 18.0\n",
      "Episode 4310: 16.0\n",
      "Episode 4320: 18.0\n",
      "Episode 4330: 16.0\n",
      "Episode 4340: 18.0\n",
      "Episode 4350: 18.0\n",
      "Episode 4360: 18.0\n",
      "Episode 4370: 18.0\n",
      "Episode 4380: 18.0\n",
      "Episode 4390: 18.0\n",
      "Episode 4400: 16.0\n",
      "Episode 4410: -15.0\n",
      "Episode 4420: 18.0\n",
      "Episode 4430: 18.0\n",
      "Episode 4440: 18.0\n",
      "Episode 4450: 18.0\n",
      "Episode 4460: 13.0\n",
      "Episode 4470: 18.0\n",
      "Episode 4480: 18.0\n",
      "Episode 4490: 14.0\n",
      "Episode 4500: 17.0\n",
      "Episode 4510: 18.0\n",
      "Episode 4520: 18.0\n",
      "Episode 4530: 18.0\n",
      "Episode 4540: -217.0\n",
      "Episode 4550: 16.0\n",
      "Episode 4560: 16.0\n",
      "Episode 4570: 16.0\n",
      "Episode 4580: 16.0\n",
      "Episode 4590: 7.0\n",
      "Episode 4600: 18.0\n",
      "Episode 4610: 17.0\n",
      "Episode 4620: 18.0\n",
      "Episode 4630: 18.0\n",
      "Episode 4640: 16.0\n",
      "Episode 4650: 18.0\n",
      "Episode 4660: 18.0\n",
      "Episode 4670: 18.0\n",
      "Episode 4680: 18.0\n",
      "Episode 4690: 18.0\n",
      "Episode 4700: 18.0\n",
      "Episode 4710: 18.0\n",
      "Episode 4720: 12.0\n",
      "Episode 4730: 18.0\n",
      "Episode 4740: 18.0\n",
      "Episode 4750: 18.0\n",
      "Episode 4760: -34.0\n",
      "Episode 4770: -48.0\n",
      "Episode 4780: -264.0\n",
      "Episode 4790: 16.0\n",
      "Episode 4800: 18.0\n",
      "Episode 4810: 15.0\n",
      "Episode 4820: 18.0\n",
      "Episode 4830: 18.0\n",
      "Episode 4840: 18.0\n",
      "Episode 4850: 18.0\n",
      "Episode 4860: 18.0\n",
      "Episode 4870: 17.0\n",
      "Episode 4880: 12.0\n",
      "Episode 4890: 11.0\n",
      "Episode 4900: 17.0\n",
      "Episode 4910: 14.0\n",
      "Episode 4920: 17.0\n",
      "Episode 4930: 14.0\n",
      "Episode 4940: -705.0\n",
      "Episode 4950: -653.0\n",
      "Episode 4960: 17.0\n",
      "Episode 4970: 17.0\n",
      "Episode 4980: 17.0\n",
      "Episode 4990: -5.0\n",
      "Episode 5000: 17.0\n",
      "Episode 5010: 17.0\n",
      "Episode 5020: 16.0\n",
      "Episode 5030: 17.0\n",
      "Episode 5040: 18.0\n",
      "Episode 5050: 18.0\n",
      "Episode 5060: 15.0\n",
      "Episode 5070: 18.0\n",
      "Episode 5080: 16.0\n",
      "Episode 5090: -382.0\n",
      "Episode 5100: -79.0\n",
      "Episode 5110: 17.0\n",
      "Episode 5120: 12.0\n",
      "Episode 5130: 1.0\n",
      "Episode 5140: 18.0\n",
      "Episode 5150: 17.0\n",
      "Episode 5160: 14.0\n",
      "Episode 5170: 18.0\n",
      "Episode 5180: 18.0\n",
      "Episode 5190: 18.0\n",
      "Episode 5200: 18.0\n",
      "Episode 5210: 18.0\n",
      "Episode 5220: 15.0\n",
      "Episode 5230: 18.0\n",
      "Episode 5240: 18.0\n",
      "Episode 5250: 18.0\n",
      "Episode 5260: 18.0\n",
      "Episode 5270: 18.0\n",
      "Episode 5280: 2.0\n",
      "Episode 5290: 12.0\n",
      "Episode 5300: 18.0\n",
      "Episode 5310: 18.0\n",
      "Episode 5320: 15.0\n",
      "Episode 5330: 18.0\n",
      "Episode 5340: 15.0\n",
      "Episode 5350: 18.0\n",
      "Episode 5360: 16.0\n",
      "Episode 5370: 18.0\n",
      "Episode 5380: 18.0\n",
      "Episode 5390: 18.0\n",
      "Episode 5400: 18.0\n",
      "Episode 5410: 15.0\n",
      "Episode 5420: 17.0\n",
      "Episode 5430: 18.0\n",
      "Episode 5440: 18.0\n",
      "Episode 5450: 18.0\n",
      "Episode 5460: 17.0\n",
      "Episode 5470: 16.0\n",
      "Episode 5480: 18.0\n",
      "Episode 5490: 17.0\n",
      "Episode 5500: 18.0\n",
      "Episode 5510: 18.0\n",
      "Episode 5520: 18.0\n",
      "Episode 5530: 18.0\n",
      "Episode 5540: 18.0\n",
      "Episode 5550: 18.0\n",
      "Episode 5560: 16.0\n",
      "Episode 5570: 18.0\n",
      "Episode 5580: 15.0\n",
      "Episode 5590: 18.0\n",
      "Episode 5600: 18.0\n",
      "Episode 5610: 18.0\n",
      "Episode 5620: 16.0\n",
      "Episode 5630: 18.0\n",
      "Episode 5640: 17.0\n",
      "Episode 5650: 18.0\n",
      "Episode 5660: 16.0\n",
      "Episode 5670: 18.0\n",
      "Episode 5680: 18.0\n",
      "Episode 5690: 16.0\n",
      "Episode 5700: 18.0\n",
      "Episode 5710: 17.0\n",
      "Episode 5720: 18.0\n",
      "Episode 5730: 16.0\n",
      "Episode 5740: 16.0\n",
      "Episode 5750: 18.0\n",
      "Episode 5760: 18.0\n",
      "Episode 5770: 16.0\n",
      "Episode 5780: 18.0\n",
      "Episode 5790: 15.0\n",
      "Episode 5800: 18.0\n",
      "Episode 5810: 18.0\n",
      "Episode 5820: 18.0\n",
      "Episode 5830: 18.0\n",
      "Episode 5840: 18.0\n",
      "Episode 5850: 17.0\n",
      "Episode 5860: 17.0\n",
      "Episode 5870: 18.0\n",
      "Episode 5880: 18.0\n",
      "Episode 5890: 18.0\n",
      "Episode 5900: 18.0\n",
      "Episode 5910: 18.0\n",
      "Episode 5920: 18.0\n",
      "Episode 5930: 18.0\n",
      "Episode 5940: 18.0\n",
      "Episode 5950: 16.0\n",
      "Episode 5960: 16.0\n",
      "Episode 5970: -374.0\n",
      "Episode 5980: 16.0\n",
      "Episode 5990: 16.0\n",
      "Episode 6000: 16.0\n",
      "Episode 6010: 12.0\n",
      "Episode 6020: 16.0\n",
      "Episode 6030: 15.0\n",
      "Episode 6040: 16.0\n",
      "Episode 6050: 15.0\n",
      "Episode 6060: 16.0\n",
      "Episode 6070: 16.0\n",
      "Episode 6080: 16.0\n",
      "Episode 6090: -1443.0\n",
      "Episode 6100: -1738.0\n",
      "Episode 6110: -86.0\n",
      "Episode 6120: -131.0\n",
      "Episode 6130: 16.0\n",
      "Episode 6140: 11.0\n",
      "Episode 6150: 14.0\n",
      "Episode 6160: 12.0\n",
      "Episode 6170: 16.0\n",
      "Episode 6180: 14.0\n",
      "Episode 6190: 15.0\n",
      "Episode 6200: 14.0\n",
      "Episode 6210: 14.0\n",
      "Episode 6220: 18.0\n",
      "Episode 6230: 18.0\n",
      "Episode 6240: 18.0\n",
      "Episode 6250: 18.0\n",
      "Episode 6260: 18.0\n",
      "Episode 6270: 18.0\n",
      "Episode 6280: 18.0\n",
      "Episode 6290: 18.0\n",
      "Episode 6300: 18.0\n",
      "Episode 6310: 18.0\n",
      "Episode 6320: 18.0\n",
      "Episode 6330: 18.0\n",
      "Episode 6340: 16.0\n",
      "Episode 6350: 18.0\n",
      "Episode 6360: 18.0\n",
      "Episode 6370: 18.0\n",
      "Episode 6380: 18.0\n",
      "Episode 6390: 18.0\n",
      "Episode 6400: 10.0\n",
      "Episode 6410: 17.0\n",
      "Episode 6420: 18.0\n",
      "Episode 6430: 18.0\n",
      "Episode 6440: 17.0\n",
      "Episode 6450: 16.0\n",
      "Episode 6460: 12.0\n",
      "Episode 6470: 18.0\n",
      "Episode 6480: 18.0\n",
      "Episode 6490: 15.0\n",
      "Episode 6500: 18.0\n",
      "Episode 6510: 18.0\n",
      "Episode 6520: 18.0\n",
      "Episode 6530: 17.0\n",
      "Episode 6540: 16.0\n",
      "Episode 6550: -2503.0\n",
      "Episode 6560: -259.0\n",
      "Episode 6570: -44.0\n",
      "Episode 6580: 17.0\n",
      "Episode 6590: 17.0\n",
      "Episode 6600: 11.0\n",
      "Episode 6610: 17.0\n",
      "Episode 6620: 18.0\n",
      "Episode 6630: 18.0\n",
      "Episode 6640: 18.0\n",
      "Episode 6650: 18.0\n",
      "Episode 6660: 18.0\n",
      "Episode 6670: 18.0\n",
      "Episode 6680: 17.0\n",
      "Episode 6690: 18.0\n",
      "Episode 6700: 11.0\n",
      "Episode 6710: 18.0\n",
      "Episode 6720: -6.0\n",
      "Episode 6730: 18.0\n",
      "Episode 6740: 18.0\n",
      "Episode 6750: 16.0\n",
      "Episode 6760: -17.0\n",
      "Episode 6770: -242.0\n",
      "Episode 6780: -675.0\n",
      "Episode 6790: 18.0\n",
      "Episode 6800: -2.0\n",
      "Episode 6810: 12.0\n",
      "Episode 6820: 18.0\n",
      "Episode 6830: 18.0\n",
      "Episode 6840: 15.0\n",
      "Episode 6850: 18.0\n",
      "Episode 6860: 13.0\n",
      "Episode 6870: 18.0\n",
      "Episode 6880: 18.0\n",
      "Episode 6890: 18.0\n",
      "Episode 6900: 18.0\n",
      "Episode 6910: 18.0\n",
      "Episode 6920: 18.0\n",
      "Episode 6930: 18.0\n",
      "Episode 6940: 16.0\n",
      "Episode 6950: 16.0\n",
      "Episode 6960: 18.0\n",
      "Episode 6970: 18.0\n",
      "Episode 6980: 18.0\n",
      "Episode 6990: 18.0\n",
      "Episode 7000: 18.0\n",
      "Episode 7010: -2240.0\n",
      "Episode 7020: -54.0\n",
      "\t\n",
      "-301.0\n",
      "-33.0\n",
      "-124.0\n",
      "-650.0\n",
      "-69.0\n",
      "-927.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "13.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "-697.0\n",
      "-637.0\n",
      "-141.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "16.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "-4.0\n",
      "17.0\n",
      "-2295.0\n",
      "-175.0\n",
      "-3.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "4.0\n",
      "-348.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "-115.0\n",
      "-929.0\n",
      "-277.0\n",
      "-22.0\n",
      "-1077.0\n",
      "-475.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "17.0\n",
      "16.0\n",
      "16.0\n",
      "17.0\n",
      "12.0\n",
      "-2639.0\n",
      "-47.0\n",
      "-81.0\n",
      "-12.0\n",
      "17.0\n",
      "9.0\n",
      "-11.0\n",
      "17.0\n",
      "10.0\n",
      "17.0\n",
      "17.0\n",
      "16.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "13.0\n",
      "13.0\n",
      "-603.0\n",
      "-230.0\n",
      "-32.0\n",
      "2.0\n",
      "17.0\n",
      "13.0\n",
      "11.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-25.0\n",
      "17.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "15.0\n",
      "-1624.0\n",
      "-113.0\n",
      "-197.0\n",
      "15.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "-203.0\n",
      "-55.0\n",
      "-13.0\n",
      "-51.0\n",
      "-1127.0\n",
      "17.0\n",
      "17.0\n",
      "16.0\n",
      "-25.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "9.0\n",
      "15.0\n",
      "8.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "-528.0\n",
      "-67.0\n",
      "-264.0\n",
      "-352.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-213.0\n",
      "-10.0\n",
      "17.0\n",
      "-203.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "14.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "13.0\n",
      "17.0\n",
      "17.0\n",
      "14.0\n",
      "15.0\n",
      "17.0\n",
      "-75.0\n",
      "18.0\n",
      "-7.0\n",
      "-125.0\n",
      "-1182.0\n",
      "-19.0\n",
      "-538.0\n",
      "17.0\n",
      "18.0\n",
      "16.0\n",
      "5.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "4.0\n",
      "17.0\n",
      "15.0\n",
      "17.0\n",
      "15.0\n",
      "-74.0\n",
      "-179.0\n",
      "1.0\n",
      "18.0\n",
      "-1133.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-32.0\n",
      "17.0\n",
      "14.0\n",
      "17.0\n",
      "12.0\n",
      "17.0\n",
      "17.0\n",
      "-13.0\n",
      "10.0\n",
      "-44.0\n",
      "15.0\n",
      "16.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "16.0\n",
      "15.0\n",
      "16.0\n",
      "16.0\n",
      "-171.0\n",
      "-44.0\n",
      "16.0\n",
      "-28.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-1238.0\n",
      "-55.0\n",
      "13.0\n",
      "16.0\n",
      "15.0\n",
      "17.0\n",
      "14.0\n",
      "-508.0\n",
      "-73.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "15.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "18.0\n",
      "-1115.0\n",
      "18.0\n",
      "17.0\n",
      "17.0\n",
      "-200.0\n",
      "17.0\n",
      "18.0\n",
      "1.0\n",
      "18.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-68.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-30.0\n",
      "17.0\n",
      "18.0\n",
      "-187.0\n",
      "-413.0\n",
      "-186.0\n",
      "17.0\n",
      "17.0\n",
      "-269.0\n",
      "15.0\n",
      "15.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "-15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "13.0\n",
      "18.0\n",
      "18.0\n",
      "14.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-217.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "7.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-34.0\n",
      "-48.0\n",
      "-264.0\n",
      "16.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "12.0\n",
      "11.0\n",
      "17.0\n",
      "14.0\n",
      "17.0\n",
      "14.0\n",
      "-705.0\n",
      "-653.0\n",
      "17.0\n",
      "17.0\n",
      "17.0\n",
      "-5.0\n",
      "17.0\n",
      "17.0\n",
      "16.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "16.0\n",
      "-382.0\n",
      "-79.0\n",
      "17.0\n",
      "12.0\n",
      "1.0\n",
      "18.0\n",
      "17.0\n",
      "14.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "2.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "16.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "16.0\n",
      "-374.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "12.0\n",
      "16.0\n",
      "15.0\n",
      "16.0\n",
      "15.0\n",
      "16.0\n",
      "16.0\n",
      "16.0\n",
      "-1443.0\n",
      "-1738.0\n",
      "-86.0\n",
      "-131.0\n",
      "16.0\n",
      "11.0\n",
      "14.0\n",
      "12.0\n",
      "16.0\n",
      "14.0\n",
      "15.0\n",
      "14.0\n",
      "14.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "10.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "16.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "16.0\n",
      "-2503.0\n",
      "-259.0\n",
      "-44.0\n",
      "17.0\n",
      "17.0\n",
      "11.0\n",
      "17.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "17.0\n",
      "18.0\n",
      "11.0\n",
      "18.0\n",
      "-6.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "-17.0\n",
      "-242.0\n",
      "-675.0\n",
      "18.0\n",
      "-2.0\n",
      "12.0\n",
      "18.0\n",
      "18.0\n",
      "15.0\n",
      "18.0\n",
      "13.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "16.0\n",
      "16.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "18.0\n",
      "-2240.0\n",
      "-54.0\n",
      "\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-620.0, 645, True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env3 = nasim.generate(**scenario_args2)\n",
    "baseline_dqn_agent = DQNAgent(env3, verbose=1, training_steps=500000) #10-20k steps, 10k episodes\n",
    "baseline_dqn_agent.train()\n",
    "baseline_dqn_agent.run_eval_episode(render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae6c2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1014.0, 1000, False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dqn_agent.run_eval_episode(render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d07e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DQN with config:\n",
      "{'batch_size': 32,\n",
      " 'env': <nasim.envs.environment.NASimEnv object at 0x7fb48a1bdd50>,\n",
      " 'exploration_steps': 10000,\n",
      " 'final_epsilon': 0.05,\n",
      " 'gamma': 0.99,\n",
      " 'hidden_sizes': [64, 64],\n",
      " 'kwargs': {},\n",
      " 'lr': 0.001,\n",
      " 'replay_size': 10000,\n",
      " 'seed': None,\n",
      " 'self': <nasim.agents.dqn_agent.DQNAgent object at 0x7fb3bfd09ea0>,\n",
      " 'target_update_freq': 1000,\n",
      " 'training_steps': 5000000,\n",
      " 'verbose': 1}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 176\u001b[0m\n\u001b[1;32m    173\u001b[0m env \u001b[38;5;241m=\u001b[39m nasim\u001b[38;5;241m.\u001b[39mmake_benchmark(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#Liam does it this way: env = nasim.load(\"small.yaml\")\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# Initializing and training agent\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m dqn_agent \u001b[38;5;241m=\u001b[39m \u001b[43mDQNAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m dqn_agent\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/nasim/agents/dqn_agent.py:164\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[0;34m(self, env, seed, lr, training_steps, batch_size, replay_size, final_epsilon, exploration_steps, gamma, hidden_sizes, target_update_freq, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Neural Network related attributes\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m                            \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[1;32m    161\u001b[0m                            \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdqn \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m               \u001b[49m\u001b[43mhidden_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 164\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUsing Neural Network running on device=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/envs/nasim/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries, including which methods will be redefined\n",
    "import nasim\n",
    "import random\n",
    "from nasim.envs.action import Action\n",
    "from nasim.agents.dqn_agent import DQNAgent\n",
    "from nasim.envs.environment import NASimEnv\n",
    "\n",
    "# User-defined Python method to check whether the selected blocked_host is valid to select\n",
    "def check_host_valid(self, blocked_host):\n",
    "    if blocked_host == -1:\n",
    "        return\n",
    "    elif self.env.network.address_space[blocked_host] in self.env.network.get_sensitive_hosts():\n",
    "        raise SensitiveHostRemovalException\n",
    "    elif blocked_host == 0:\n",
    "        raise PublicHostRemovalException\n",
    "    else:\n",
    "        return\n",
    "\n",
    "# Setting the method\n",
    "DQNAgent.check_host_valid = check_host_valid\n",
    "    \n",
    "# Redefining the DQNAgent run_train_episode method\n",
    "def run_train_episode(self, step_limit):\n",
    "        done = False\n",
    "        env_step_limit_reached = False #Unnecessary now with loop below using steps < step_limit\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "        max_host_index = len(self.env.network.host_num_map) - 1\n",
    "        \n",
    "        # Choosing random host index to be invalid... try/catch loop until valid host selected to block. Note: If -1, no host will be marked invalid\n",
    "        blocked_host = -1\n",
    "        if self.steps_done > 0:\n",
    "            while True:\n",
    "                try:\n",
    "                    blocked_host = random.randint(-1,max_host_index)\n",
    "                    self.check_host_valid(blocked_host)\n",
    "                    break\n",
    "                except SensitiveHostRemovalException:\n",
    "                    pass\n",
    "                except PublicHostRemovalException:\n",
    "                    pass\n",
    "                \n",
    "        o, _ = self.env.reset()\n",
    "        \n",
    "        # If you wanted to see which host was blocked... used for the logging\n",
    "        print(\"Blocked host index:  \" + str(blocked_host))\n",
    "        \n",
    "        while not done and not env_step_limit_reached: #steps < step_limit: #J: changed from env_step_limit_reached:     \n",
    "            #J: steps continuously updated at the bottom and will break as soon as step limit is reached\n",
    "            # Keep generating an action in the action space until it does not involve a blocked host\n",
    "            while True:\n",
    "                a = self.get_egreedy_action(o, self.get_epsilon())\n",
    "                \n",
    "                if blocked_host == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    action = self.env.action_space.get_action(a)\n",
    "                    target_host_index = self.env.network.host_num_map[action.target]\n",
    "                    if target_host_index != blocked_host:\n",
    "                        break\n",
    "                \n",
    "            next_o, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.replay.store(o, a, next_o, r, done)\n",
    "            self.steps_done += 1\n",
    "            loss, mean_v = self.optimize()\n",
    "            \n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "\n",
    "# Setting the method\n",
    "DQNAgent.run_train_episode = run_train_episode\n",
    "\n",
    "# Training function... redefined because it wasn't converging originally\n",
    "def train(self):\n",
    "    if self.verbose:\n",
    "        print(\"\\nStarting training\")\n",
    "\n",
    "    num_episodes = 0\n",
    "    training_steps_remaining = self.training_steps\n",
    "    og_env = self.env\n",
    "    \n",
    "    elems_to_avg = []\n",
    "    all_avgs = []\n",
    "    \n",
    "    while self.steps_done < self.training_steps:\n",
    "        self.env = og_env\n",
    "        ep_results = self.run_train_episode(training_steps_remaining)\n",
    "        ep_return, ep_steps, goal = ep_results\n",
    "        num_episodes += 1\n",
    "        training_steps_remaining -= ep_steps\n",
    "\n",
    "        self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "        self.logger.add_scalar(\n",
    "            \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_return\", ep_return, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_steps\", ep_steps, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_goal_reached\", int(goal), self.steps_done\n",
    "        )\n",
    "\n",
    "        if num_episodes % 10 == 0 and self.verbose:\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                f\"{self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            elems_to_avg.append(ep_return) #Jacob edit\n",
    "        \n",
    "        if num_episodes % 50 == 0 and self.verbose:\n",
    "            avg = (sum(elems_to_avg) / len(elems_to_avg))\n",
    "            all_avgs.append(avg)\n",
    "            \n",
    "            print(f\"\\t\")\n",
    "            print(f\"\\tRunning_Average = {avg}\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            print(\"Running_Average List:\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(all_avgs)):\n",
    "                print(\"Episode \" + str((i+1)*50), end=\": \")\n",
    "                print(all_avgs[i])\n",
    "            print(f\"\\t\")\n",
    "                \n",
    "\n",
    "    self.logger.close()\n",
    "    if self.verbose:\n",
    "            print(\"Training complete\")\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "            \n",
    "            print(f\"\\t\")\n",
    "            print(\"Running_Average List:\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            \n",
    "            print(\"Running_Average List:\")\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(all_avgs)):\n",
    "                print(\"Episode \" + str((i+1)*50), end=\": \")\n",
    "                print(all_avgs[i])\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(elems_to_avg)):\n",
    "                print(\"Episode \" + str((i+1)*10), end=\": \")\n",
    "                print(elems_to_avg[i])\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            for i in range(len(elems_to_avg)):\n",
    "                print(elems_to_avg[i])\n",
    "            print(f\"\\t\")\n",
    "            \n",
    "            \n",
    "            #plot_average_bar_chart(elems_to_avg)\n",
    "\n",
    "# Set the method        \n",
    "DQNAgent.train = train\n",
    "\n",
    "# You can switch to a different benchmark if you want... like the scenario args posted or your own\n",
    "env = nasim.make_benchmark(\"small\")\n",
    "#Liam does it this way: env = nasim.load(\"small.yaml\")\n",
    "# Initializing and training agent\n",
    "dqn_agent = DQNAgent(env, verbose=1, training_steps=5000000)\n",
    "dqn_agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_agent.run_eval_episode(render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3c846",
   "metadata": {},
   "source": [
    "## Past Attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0a258",
   "metadata": {},
   "source": [
    "This was some code that didn't end up working if you wanted to see a previous attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a233e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "capacity = 10\n",
    "s_dims = (5,)\n",
    "s_buf = np.zeros((capacity, *s_dims), dtype=np.float32)\n",
    "#test_tuple.resize(test_tuple, [3,2])\n",
    "\n",
    "print(s_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50882f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nasim\n",
    "import random\n",
    "from nasim.agents.dqn_agent import DQNAgent\n",
    "\n",
    "def run_train_episode(self, step_limit):\n",
    "        done = False\n",
    "        env_step_limit_reached = False\n",
    "        steps = 0\n",
    "        episode_return = 0\n",
    "        \n",
    "        o = self.env.reset()\n",
    "        \n",
    "        while not done and not env_step_limit_reached: #and steps < step_limit:\n",
    "            a = self.get_egreedy_action(o, self.get_epsilon())\n",
    "        \n",
    "            next_o, r, done, env_step_limit_reached, _ = self.env.step(a)\n",
    "            self.replay.store(o, a, next_o, r, done)\n",
    "            self.steps_done += 1\n",
    "            loss, mean_v = self.optimize()\n",
    "            \n",
    "            o = next_o\n",
    "            episode_return += r\n",
    "            steps += 1\n",
    "\n",
    "        return episode_return, steps, self.env.goal_reached()\n",
    "    \n",
    "DQNAgent.run_train_episode = run_train_episode\n",
    "\n",
    "def train(self):\n",
    "    if self.verbose:\n",
    "        print(\"\\nStarting training\")\n",
    "\n",
    "    num_episodes = 0\n",
    "    training_steps_remaining = self.training_steps\n",
    "    max_hosts = (self.env.scenario.get_description())['Hosts']\n",
    "    max_obs_dim = self.env.observation_space.shape\n",
    "    \n",
    "    while self.steps_done < self.training_steps:\n",
    "        if self.steps_done > 0:\n",
    "            print(self.env.network.address_space)\n",
    "            print(self.env.network.host_num_map)\n",
    "            print(self.env.network.subnets)\n",
    "            print(self.env.network.topology)\n",
    "            print(self.env.network.firewall)\n",
    "            print(self.env.network.address_space)\n",
    "            print(self.env.network.address_space_bounds)\n",
    "            print(self.env.network.sensitive_addresses)\n",
    "            print(self.env.network.sensitive_hosts)\n",
    "\n",
    "            self.env.observation_space = prev_observation_space\n",
    "            self.num_actions = prev_num_actions\n",
    "            self.obs_dim = prev_obs_dim\n",
    "            self.replay = ReplayMemory(prev_replay_size,\n",
    "                                   #self.obs_dim,\n",
    "                                   #self.device)\n",
    "            \n",
    "            prev_observation_space = self.env.observation_space\n",
    "            prev_num_actions = self.num_actions\n",
    "            prev_obs_dim = self.obs_dim\n",
    "            prev_replay = self.replay\n",
    "            \n",
    "            scenario_args.update(num_hosts=random.randint(3,max_hosts))\n",
    "            \n",
    "            self.env =  nasim.generate(**scenario_args)\n",
    "            self.env.observation_space = prev_observation_space\n",
    "            self.num_actions = prev_num_actions\n",
    "            self.obs_dim = prev_obs_dim\n",
    "            self.replay = prev_replay\n",
    "            \n",
    "        ep_results = self.run_train_episode(training_steps_remaining)\n",
    "        ep_return, ep_steps, goal = ep_results\n",
    "        num_episodes += 1\n",
    "        training_steps_remaining -= ep_steps\n",
    "\n",
    "        self.logger.add_scalar(\"episode\", num_episodes, self.steps_done)\n",
    "        self.logger.add_scalar(\n",
    "            \"epsilon\", self.get_epsilon(), self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_return\", ep_return, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_steps\", ep_steps, self.steps_done\n",
    "        )\n",
    "        self.logger.add_scalar(\n",
    "            \"episode_goal_reached\", int(goal), self.steps_done\n",
    "        )\n",
    "\n",
    "        if num_episodes % 10 == 0 and self.verbose:\n",
    "            print(f\"\\nEpisode {num_episodes}:\")\n",
    "            print(f\"\\tsteps done = {self.steps_done} / \"\n",
    "                    f\"{self.training_steps}\")\n",
    "            print(f\"\\treturn = {ep_return}\")\n",
    "            print(f\"\\tgoal = {goal}\")\n",
    "\n",
    "    self.logger.close()\n",
    "    if self.verbose:\n",
    "        print(\"Training complete\")\n",
    "        print(f\"\\nEpisode {num_episodes}:\")\n",
    "        print(f\"\\tsteps done = {self.steps_done} / {self.training_steps}\")\n",
    "        print(f\"\\treturn = {ep_return}\")\n",
    "        print(f\"\\tgoal = {goal}\")\n",
    "            \n",
    "DQNAgent.train = train\n",
    "\n",
    "print(scenario_args)\n",
    "env = nasim.generate(**scenario_args)\n",
    "dqn_agent = DQNAgent(env, verbose=1, training_steps=100000)\n",
    "dqn_agent.train()\n",
    "dqn_agent.run_eval_episode(render=args.render_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f482cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasim",
   "language": "python",
   "name": "nasim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
